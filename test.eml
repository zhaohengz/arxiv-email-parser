------------------------------------------------------------------------------
------------------------------------------------------------------------------
Send any comments regarding submissions directly to submitter.
------------------------------------------------------------------------------
Archives at http://arxiv.org/
To unsubscribe, e-mail To: cs@arXiv.org, Subject: cancel
------------------------------------------------------------------------------
 Submissions to:
Computation and Language
Computer Vision and Pattern Recognition
Machine Learning
 received from  Fri 12 Jul 19 18:00:00 GMT  to  Mon 15 Jul 19 18:00:00 GMT
------------------------------------------------------------------------------
------------------------------------------------------------------------------
\\
arXiv:1907.05955
Date: Fri, 12 Jul 2019 20:54:59 GMT   (37kb,D)

Title: Pykaldi2: Yet another speech toolkit based on Kaldi and Pytorch
Authors: Liang Lu, Xiong Xiao, Zhuo Chen, Yifan Gong
Categories: cs.CL eess.AS
Comments: 5 pages, 2 figures
\\
  We introduce PyKaldi2 speech recognition toolkit implemented based on Kaldi
and PyTorch. While similar toolkits are available built on top of the two, a
key feature of PyKaldi2 is sequence training with criteria such as MMI, sMBR
and MPE. In particular, we implemented the sequence training module with
on-the-fly lattice generation during model training in order to simplify the
training pipeline. To address the challenging acoustic environments in real
applications, PyKaldi2 also supports on-the-fly noise and reverberation
simulation to improve the model robustness. With this feature, it is possible
to backpropogate the gradients from the sequence-level loss to the front-end
feature extraction module, which, hopefully, can foster more research in the
direction of joint front-end and backend learning. We performed benchmark
experiments on Librispeech, and show that PyKaldi2 can achieve reasonable
recognition accuracy. The toolkit is released under the MIT license.
\\ ( https://arxiv.org/abs/1907.05955 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06042
Date: Sat, 13 Jul 2019 10:04:37 GMT   (498kb,D)

Title: Cross-Lingual Transfer Learning for Question Answering
Authors: Chia-Hsuan Lee, Hung-Yi Lee
Categories: cs.CL
\\
  Deep learning based question answering (QA) on English documents has achieved
success because there is a large amount of English training examples. However,
for most languages, training examples for high-quality QA models are not
available. In this paper, we explore the problem of cross-lingual transfer
learning for QA, where a source language task with plentiful annotations is
utilized to improve the performance of a QA model on a target language task
with limited available annotations. We examine two different approaches. A
machine translation (MT) based approach translates the source language into the
target language, or vice versa. Although the MT-based approach brings
improvement, it assumes the availability of a sentence-level translation
system. A GAN-based approach incorporates a language discriminator to learn
language-universal feature representations, and consequentially transfer
knowledge from the source language. The GAN-based approach rivals the
performance of the MT-based approach with fewer linguistic resources. Applying
both approaches simultaneously yield the best results. We use two English
benchmark datasets, SQuAD and NewsQA, as source language data, and show
significant improvements over a number of established baselines on a Chinese QA
task. We achieve the new state-of-the-art on the Chinese QA dataset.
\\ ( https://arxiv.org/abs/1907.06042 ,  498kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06080
Date: Sat, 13 Jul 2019 14:01:27 GMT   (112kb,D)

Title: Relational Memory-based Knowledge Graph Embedding
Authors: Dai Quoc Nguyen and Tu Dinh Nguyen and Dinh Phung
Categories: cs.CL
\\
  Knowledge graph embedding models often suffer from a limitation of
remembering existing triples to predict new triples. To overcome this issue, we
introduce a novel embedding model, named R-MeN, that explores a relational
memory network to model relationship triples. In R-MeN, we simply represent
each triple as a sequence of 3 input vectors which recurrently interact with a
relational memory. This memory network is constructed to incorporate new
information using a self-attention mechanism over the memory and input vectors
to return a corresponding output vector for every timestep. Consequently, we
obtain 3 output vectors which are then multiplied element-wisely into a single
one; and finally, we feed this vector to a linear neural layer to produce a
scalar score for the triple. Experimental results show that our proposed R-MeN
obtains state-of-the-art results on two well-known benchmark datasets WN11 and
FB13 for triple classification task.
\\ ( https://arxiv.org/abs/1907.06080 ,  112kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06142
Date: Sat, 13 Jul 2019 22:48:31 GMT   (616kb,D)

Title: Tackling Graphical NLP problems with Graph Recurrent Networks
Authors: Linfeng Song
Categories: cs.CL cs.LG
Comments: Ph.D. thesis
\\
  How to properly model graphs is a long-existing and important problem in NLP
area, where several popular types of graphs are knowledge graphs, semantic
graphs and dependency graphs. Comparing with other data structures, such as
sequences and trees, graphs are generally more powerful in representing complex
correlations among entities. For example, a knowledge graph stores real-word
entities (such as "Barack_Obama" and "U.S.") and their relations (such as
"live_in" and "lead_by"). Properly encoding a knowledge graph is beneficial to
user applications, such as question answering and knowledge discovery. Modeling
graphs is also very challenging, probably because graphs usually contain
massive and cyclic relations.
  Recent years have witnessed the success of deep learning, especially
RNN-based models, on many NLP problems. Besides, RNNs and their variations have
been extensively studied on several graph problems and showed preliminary
successes. Despite the successes that have been achieved, RNN-based models
suffer from several major drawbacks on graphs. First, they can only consume
sequential data, thus linearization is required to serialize input graphs,
resulting in the loss of important structural information. Second, the
serialization results are usually very long, so it takes a long time for RNNs
to encode them.
  In this thesis, we propose a novel graph neural network, named graph
recurrent network (GRN). We study our GRN model on 4 very different tasks, such
as machine reading comprehension, relation extraction and machine translation.
Some take undirected graphs without edge labels, while the others have directed
ones with edge labels. To consider these important differences, we gradually
enhance our GRN model, such as further considering edge labels and adding an
RNN decoder. Carefully designed experiments show the effectiveness of GRN on
all these tasks.
\\ ( https://arxiv.org/abs/1907.06142 ,  616kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06170
Date: Sun, 14 Jul 2019 05:47:53 GMT   (161kb,D)

Title: Microsoft Translator at WMT 2019: Towards Large-Scale Document-Level
  Neural Machine Translation
Authors: Marcin Junczys-Dowmunt
Categories: cs.CL
Comments: WMT 2019 Shared Task submission
\\
  This paper describes the Microsoft Translator submissions to the WMT19 news
translation shared task for English-German. Our main focus is document-level
neural machine translation with deep transformer models.
  We start with strong sentence-level baselines, trained on large-scale data
created via data-filtering and noisy back-translation and find that
back-translation seems to mainly help with translationese input. We explore
fine-tuning techniques, deeper models and different ensembling strategies to
counter these effects.
  Using document boundaries present in the authentic and synthetic parallel
data, we create sequences of up to 1000 subword segments and train transformer
translation models. We experiment with data augmentation techniques for the
smaller authentic data with document-boundaries and for larger authentic data
without boundaries.
  We further explore multi-task training for the incorporation of
document-level source language monolingual data via the BERT-objective on the
encoder and two-pass decoding for combinations of sentence-level and
document-level systems.
  Based on preliminary human evaluation results, evaluators strongly prefer the
document-level systems over our comparable sentence-level system. The
document-level systems also seem to score higher than the human references in
source-based direct assessment.
\\ ( https://arxiv.org/abs/1907.06170 ,  161kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06210
Date: Sun, 14 Jul 2019 11:56:20 GMT   (33kb)

Title: Simple Automatic Post-editing for Arabic-Japanese Machine Translation
Authors: Ella Noll, Mai Oudah, Nizar Habash
Categories: cs.CL
Comments: Machine translation, Automatic Post editing, Arabic, Japanese
\\
  A common bottleneck for developing machine translation (MT) systems for some
language pairs is the lack of direct parallel translation data sets, in general
and in certain domains. Alternative solutions such as zero-shot models or
pivoting techniques are successful in getting a strong baseline, but are often
below the more supported language-pair systems. In this paper, we focus on
Arabic-Japanese machine translation, a less studied language pair; and we work
with a unique parallel corpus of Arabic news articles that were manually
translated to Japanese. We use this parallel corpus to adapt a state-of-the-art
domain/genre agnostic neural MT system via a simple automatic post-editing
technique. Our results and detailed analysis suggest that this approach is
quite viable for less supported language pairs in specific domains.
\\ ( https://arxiv.org/abs/1907.06210 ,  33kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06226
Date: Sun, 14 Jul 2019 14:19:22 GMT   (113kb,D)

Title: A Simple BERT-Based Approach for Lexical Simplification
Authors: Jipeng Qiang and Yun Li and Yi Zhu and Yunhao Yuan
Categories: cs.CL cs.AI cs.IR
\\
  Lexical simplification (LS) aims to replace complex words in a given sentence
with their simpler alternatives of equivalent meaning. Recently unsupervised
lexical simplification approaches only rely on the complex word itself
regardless of the given sentence to generate candidate substitutions, which
will inevitably produce a large number of spurious candidates. We present a
simple BERT-based LS approach that makes use of the pre-trained unsupervised
deep bidirectional representations BERT. We feed the given sentence masked the
complex word into the masking language model of BERT to generate candidate
substitutions. By considering the whole sentence, the generated simpler
alternatives are easier to hold cohesion and coherence of a sentence.
Experimental results show that our approach obtains obvious improvement on
standard LS benchmark.
\\ ( https://arxiv.org/abs/1907.06226 ,  113kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06292
Date: Sun, 14 Jul 2019 22:20:59 GMT   (1844kb,D)

Title: TWEETQA: A Social Media Focused Question Answering Dataset
Authors: Wenhan Xiong, Jiawei Wu, Hong Wang, Vivek Kulkarni, Mo Yu, Shiyu
  Chang, Xiaoxiao Guo, William Yang Wang
Categories: cs.CL
Comments: ACL 2019
\\
  With social media becoming increasingly pop-ular on which lots of news and
real-time eventsare reported, developing automated questionanswering systems is
critical to the effective-ness of many applications that rely on real-time
knowledge. While previous datasets haveconcentrated on question answering (QA)
forformal text like news and Wikipedia, wepresent the first large-scale dataset
for QA oversocial media data. To ensure that the tweetswe collected are useful,
we only gather tweetsused by journalists to write news articles. Wethen ask
human annotators to write questionsand answers upon these tweets. Unlike
otherQA datasets like SQuAD in which the answersare extractive, we allow the
answers to be ab-stractive. We show that two recently proposedneural models
that perform well on formaltexts are limited in their performance when ap-plied
to our dataset. In addition, even the fine-tuned BERT model is still lagging
behind hu-man performance with a large margin. Our re-sults thus point to the
need of improved QAsystems targeting social media text.
\\ ( https://arxiv.org/abs/1907.06292 ,  1844kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06342
Date: Mon, 15 Jul 2019 06:30:15 GMT   (5082kb,D)

Title: Joint Language Identification of Code-Switching Speech using Attention
  based E2E Network
Authors: Sreeram Ganji, Kunal Dhawan, Kumar Priyadarshi and Rohit Sinha
Categories: cs.CL cs.SD eess.AS
\\
  Language identification (LID) has relevance in many speech processing
applications. For the automatic recognition of code-switching speech, the
conventional approaches often employ an LID system for detecting the languages
present within an utterance. In the existing works, the LID on code-switching
speech involves modelling of the underlying languages separately. In this work,
we propose a joint modelling based LID system for code-switching speech. To
achieve the same, an attention-based end-to-end (E2E) network has been
explored. For the development and evaluation of the proposed approach, a
recently created Hindi-English code-switching corpus has been used. For the
contrast purpose, an LID system employing the connectionist temporal
classification-based E2E network is also developed. On comparing both the LID
systems, the attention based approach is noted to result in better LID
accuracy. The effective location of code-switching boundaries within the
utterance by the proposed approach has been demonstrated by plotting the
attention weights of E2E network.
\\ ( https://arxiv.org/abs/1907.06342 ,  5082kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06385
Date: Mon, 15 Jul 2019 09:23:49 GMT   (105kb,D)

Title: GLOSS: Generative Latent Optimization of Sentence Representations
Authors: Sidak Pal Singh, Angela Fan, Michael Auli
Categories: cs.CL
\\
  We propose a method to learn unsupervised sentence representations in a
non-compositional manner based on Generative Latent Optimization. Our approach
does not impose any assumptions on how words are to be combined into a sentence
representation. We discuss a simple Bag of Words model as well as a variant
that models word positions. Both are trained to reconstruct the sentence based
on a latent code and our model can be used to generate text. Experiments show
large improvements over the related Paragraph Vectors. Compared to uSIF, we
achieve a relative improvement of 5% when trained on the same data and our
method performs competitively to Sent2vec while trained on 30 times less data.
\\ ( https://arxiv.org/abs/1907.06385 ,  105kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06407
Date: Mon, 15 Jul 2019 10:07:07 GMT   (80kb,D)

Title: Investigation on N-gram Approximated RNNLMs for Recognition of
  Morphologically Rich Speech
Authors: Bal\'azs Tarj\'an, Gy\"orgy Szasz\'ak, Tibor Fegy\'o, P\'eter Mihajlik
Categories: cs.CL
Comments: 12 pages, 2 figures, accepted for publication at SLSP 2019
\\
  Recognition of Hungarian conversational telephone speech is challenging due
to the informal style and morphological richness of the language. Recurrent
Neural Network Language Model (RNNLM) can provide remedy for the high
perplexity of the task; however, two-pass decoding introduces a considerable
processing delay. In order to eliminate this delay we investigate approaches
aiming at the complexity reduction of RNNLM, while preserving its accuracy. We
compare the performance of conventional back-off n-gram language models (BNLM),
BNLM approximation of RNNLMs (RNN-BNLM) and RNN n-grams in terms of perplexity
and word error rate (WER). Morphological richness is often addressed by using
statistically derived subwords - morphs - in the language models, hence our
investigations are extended to morph-based models, as well. We found that using
RNN-BNLMs 40% of the RNNLM perplexity reduction can be recovered, which is
roughly equal to the performance of a RNN 4-gram model. Combining morph-based
modeling and approximation of RNNLM, we were able to achieve 8% relative WER
reduction and preserve real-time operation of our conversational telephone
speech recognition system.
\\ ( https://arxiv.org/abs/1907.06407 ,  80kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06458
Date: Mon, 15 Jul 2019 12:10:24 GMT   (2950kb,D)

Title: RaKUn: Rank-based Keyword extraction via Unsupervised learning and Meta
  vertex aggregation
Authors: Bla\v{z} \v{S}krlj, Andra\v{z} Repar and Senja Pollak
Categories: cs.CL cs.IR cs.LG
\\
  Keyword extraction is used for summarizing the content of a document and
supports efficient document retrieval, and is as such an indispensable part of
modern text-based systems. We explore how load centrality, a graph-theoretic
measure applied to graphs derived from a given text can be used to efficiently
identify and rank keywords. Introducing meta vertices (aggregates of existing
vertices) and systematic redundancy filters, the proposed method performs on
par with state-of-the-art for the keyword extraction task on 14 diverse
datasets. The proposed method is unsupervised, interpretable and can also be
used for document visualization.
\\ ( https://arxiv.org/abs/1907.06458 ,  2950kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06488
Date: Mon, 15 Jul 2019 13:19:44 GMT   (45kb,D)

Title: Naver Labs Europe's Systems for the WMT19 Machine Translation Robustness
  Task
Authors: Alexandre B\'erard, Ioan Calapodescu, Claude Roux
Categories: cs.CL
Comments: WMT 2019 - Shared Task Paper
\\
  This paper describes the systems that we submitted to the WMT19 Machine
Translation robustness task. This task aims to improve MT's robustness to noise
found on social media, like informal language, spelling mistakes and other
orthographic variations. The organizers provide parallel data extracted from a
social media website in two language pairs: French-English and Japanese-English
(in both translation directions). The goal is to obtain the best scores on
unseen test sets from the same source, according to automatic metrics (BLEU)
and human evaluation. We proposed one single and one ensemble system for each
translation direction. Our ensemble models ranked first in all language pairs,
according to BLEU evaluation. We discuss the pre-processing choices that we
made, and present our solutions for robustness to noise and domain adaptation.
\\ ( https://arxiv.org/abs/1907.06488 ,  45kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06554
Date: Mon, 15 Jul 2019 15:45:37 GMT   (2940kb,D)

Title: Asking Clarifying Questions in Open-Domain Information-Seeking
  Conversations
Authors: Mohammad Aliannejadi and Hamed Zamani and Fabio Crestani and W. Bruce
  Croft
Categories: cs.CL cs.AI cs.IR
Comments: To appear in SIGIR 2019
DOI: 10.1145/3331184.3331265
\\
  Users often fail to formulate their complex information needs in a single
query. As a consequence, they may need to scan multiple result pages or
reformulate their queries, which may be a frustrating experience.
Alternatively, systems can improve user satisfaction by proactively asking
questions of the users to clarify their information needs. Asking clarifying
questions is especially important in conversational systems since they can only
return a limited number of (often only one) result(s). In this paper, we
formulate the task of asking clarifying questions in open-domain
information-seeking conversational systems. To this end, we propose an offline
evaluation methodology for the task and collect a dataset, called Qulac,
through crowdsourcing. Our dataset is built on top of the TREC Web Track
2009-2012 data and consists of over 10K question-answer pairs for 198 TREC
topics with 762 facets. Our experiments on an oracle model demonstrate that
asking only one good question leads to over 170% retrieval performance
improvement in terms of P@1, which clearly demonstrates the potential impact of
the task. We further propose a retrieval framework consisting of three
components: question retrieval, question selection, and document retrieval. In
particular, our question selection model takes into account the original query
and previous question-answer interactions while selecting the next question.
Our model significantly outperforms competitive baselines. To foster research
in this area, we have made Qulac publicly available.
\\ ( https://arxiv.org/abs/1907.06554 ,  2940kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06616
Date: Mon, 15 Jul 2019 17:22:54 GMT   (29kb)

Title: Facebook FAIR's WMT19 News Translation Task Submission
Authors: Nathan Ng, Kyra Yee, Alexei Baevski, Myle Ott, Michael Auli, Sergey
  Edunov
Categories: cs.CL
Comments: 7 pages; WMT
\\
  This paper describes Facebook FAIR's submission to the WMT19 shared news
translation task. We participate in two language pairs and four language
directions, English <-> German and English <-> Russian. Following our
submission from last year, our baseline systems are large BPE-based transformer
models trained with the Fairseq sequence modeling toolkit which rely on sampled
back-translations. This year we experiment with different bitext data filtering
schemes, as well as with adding filtered back-translated data. We also ensemble
and fine-tune our models on domain-specific data, then decode using noisy
channel model reranking. Our submissions are ranked first in all four
directions of the human evaluation campaign. On En->De, our system
significantly outperforms other systems as well as human translations. This
system improves upon our WMT'18 submission by 4.5 BLEU points.
\\ ( https://arxiv.org/abs/1907.06616 ,  29kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05916
Date: Fri, 12 Jul 2019 18:39:27 GMT   (7210kb,D)

Title: Gesture-to-Gesture Translation in the Wild via Category-Independent
  Conditional Maps
Authors: Yahui Liu, Marco De Nadai, Gloria Zen, Nicu Sebe, Bruno Lepri
Categories: cs.CV cs.MM
Comments: 15 pages, 12 figures
\\
  Recent works have shown Generative Adversarial Networks (GANs) to be
particularly effective in image-to-image translations. However, in tasks such
as body pose and hand gesture translation, existing methods usually require
precise annotations, e.g. key-points or skeletons, which are time-consuming to
draw. In this work, we propose a novel GAN architecture that decouples the
required annotations into a category label - that specifies the gesture type -
and a simple-to-draw category-independent conditional map - that expresses the
location, rotation and size of the hand gesture. Our architecture synthesizes
the target gesture while preserving the background context, thus effectively
dealing with gesture translation in the wild. To this aim, we use an attention
module and a rolling guidance approach, which loops the generated images back
into the network and produces higher quality images compared to competing
works. Thus, our GAN learns to generate new images from simple annotations
without requiring key-points or skeleton labels. Results on two public datasets
show that our method outperforms state of the art approaches both
quantitatively and qualitatively. To the best of our knowledge, no work so far
has addressed the gesture-to-gesture translation in the wild by requiring
user-friendly annotations.
\\ ( https://arxiv.org/abs/1907.05916 ,  7210kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06007
Date: Sat, 13 Jul 2019 04:18:04 GMT   (4808kb,D)

Title: SynthText3D: Synthesizing Scene Text Images from 3D Virtual Worlds
Authors: Minghui Liao, Boyu Song, Minghang He, Shangbang Long, Cong Yao, Xiang
  Bai
Categories: cs.CV
\\
  With the development of deep neural networks, the demand for a significant
amount of annotated training data becomes the performance bottlenecks in many
fields of research and applications. Image synthesis can generate annotated
images automatically and freely, which gains increasing attention recently. In
this paper, we propose to synthesize scene text images from the 3D virtual
worlds, where the precise descriptions of scenes, editable
illumination/visibility, and realistic physics are provided. Different from the
previous methods which paste the rendered text on static 2D images, our method
can render the 3D virtual scene and text instances as an entirety. In this way,
complex perspective transforms, various illuminations, and occlusions can be
realized in our synthesized scene text images. Moreover, the same text
instances with various viewpoints can be produced by randomly moving and
rotating the virtual camera, which acts as human eyes. The experiments on the
standard scene text detection benchmarks using the generated synthetic data
demonstrate the effectiveness and superiority of the proposed method. The code
and synthetic data will be made available at
https://github.com/MhLiao/SynthText3D
\\ ( https://arxiv.org/abs/1907.06007 ,  4808kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06014
Date: Sat, 13 Jul 2019 05:43:06 GMT   (3489kb)

Title: A Conditional Wasserstein Generative Adversarial Network for Pixel-level
  Crack Detection using Video Extracted Images
Authors: Qipei Mei and Mustafa G\"ul
Categories: cs.CV cs.LG eess.IV
\\
  Automatic crack detection on pavement surfaces is an important research field
in the scope of developing an intelligent transportation infrastructure system.
In this paper, a novel method on the basis of conditional Wasserstein
generative adversarial network (cWGAN) is proposed for road crack detection. A
121-layer densely connected neural network with deconvolution layers for
multi-level feature fusion is used as generator, and a 5-layer fully
convolutional network is used as discriminator. To overcome the scattered
output issue related deconvolution layers, connectivity maps are introduced to
represent the crack information within the proposed cWGAN. The proposed method
is tested on a dataset collected from a moving vehicle equipped with a
commercial grade high speed camera. This dataset is challenging because the
images containing cracks also include the disturbance of other objects. The
results show that the proposed method achieves state-of-the-art performance
compared with other existing methods in terms of precision, recall and F1
score.
\\ ( https://arxiv.org/abs/1907.06014 ,  3489kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06023
Date: Sat, 13 Jul 2019 07:31:24 GMT   (6575kb,D)

Title: Structure-Aware Residual Pyramid Network for Monocular Depth Estimation
Authors: Xiaotian Chen, Xuejin Chen, Zheng-Jun Zha
Categories: cs.CV
Comments: 7pages, 7figures, Accepted by the 28th International Joint Conference
  on Artificial Intelligence (IJCAI-2019)
\\
  Monocular depth estimation is an essential task for scene understanding. The
underlying structure of objects and stuff in a complex scene is critical to
recovering accurate and visually-pleasing depth maps. Global structure conveys
scene layouts, while local structure reflects shape details. Recently developed
approaches based on convolutional neural networks (CNNs) significantly improve
the performance of depth estimation. However, few of them take into account
multi-scale structures in complex scenes. In this paper, we propose a
Structure-Aware Residual Pyramid Network (SARPN) to exploit multi-scale
structures for accurate depth prediction. We propose a Residual Pyramid Decoder
(RPD) which expresses global scene structure in upper levels to represent
layouts, and local structure in lower levels to present shape details. At each
level, we propose Residual Refinement Modules (RRM) that predict residual maps
to progressively add finer structures on the coarser structure predicted at the
upper level. In order to fully exploit multi-scale image features, an Adaptive
Dense Feature Fusion (ADFF) module, which adaptively fuses effective features
from all scales for inferring structures of each scale, is introduced.
Experiment results on the challenging NYU-Depth v2 dataset demonstrate that our
proposed approach achieves state-of-the-art performance in both qualitative and
quantitative evaluation. The code is available at
https://github.com/Xt-Chen/SARPN.
\\ ( https://arxiv.org/abs/1907.06023 ,  6575kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06038
Date: Sat, 13 Jul 2019 09:40:22 GMT   (6301kb,D)

Title: M3D-RPN: Monocular 3D Region Proposal Network for Object Detection
Authors: Garrick Brazil, Xiaoming Liu
Categories: cs.CV
\\
  Understanding the world in 3D is a critical component of urban autonomous
driving. Generally, the combination of expensive LiDAR sensors and stereo RGB
imaging has been paramount for successful 3D object detection algorithms,
whereas monocular image-only methods experience drastically reduced
performance. We propose to reduce the gap by reformulating the monocular 3D
detection problem as a standalone 3D region proposal network. We leverage the
geometric relationship of 2D and 3D perspectives, allowing 3D boxes to utilize
well-known and powerful convolutional features generated in the image-space. To
help address the strenuous 3D parameter estimations, we further design
depth-aware convolutional layers which enable location specific feature
development and in consequence improved 3D scene understanding. Compared to
prior work in monocular 3D detection, our method consists of only the proposed
3D region proposal network rather than relying on external networks, data, or
multiple stages. M3D-RPN is able to significantly improve the performance of
both monocular 3D Object Detection and Bird's Eye View tasks within the KITTI
urban autonomous driving dataset, while efficiently using a shared multi-class
model.
\\ ( https://arxiv.org/abs/1907.06038 ,  6301kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06062
Date: Sat, 13 Jul 2019 12:12:36 GMT   (545kb,D)

Title: Using dynamic routing to extract intermediate features for developing
  scalable capsule networks
Authors: Bodhisatwa Mandal, Swarnendu Ghosh, Ritesh Sarkhel, Nibaran Das, Mita
  Nasipuri
Categories: cs.CV cs.LG cs.NE
Comments: Second International Conference on Advanced Computational and
  Communication Paradigms held at Sikkim Manipal Institute of Technology,
  Sikkim, India during February 25 - 28 , 2019
\\
  Capsule networks have gained a lot of popularity in short time due to its
unique approach to model equivariant class specific properties as capsules from
images. However the dynamic routing algorithm comes with a steep computational
complexity. In the proposed approach we aim to create scalable versions of the
capsule networks that are much faster and provide better accuracy in problems
with higher number of classes. By using dynamic routing to extract intermediate
features instead of generating output class specific capsules, a large increase
in the computational speed has been observed. Moreover, by extracting
equivariant feature capsules instead of class specific capsules, the
generalization capability of the network has also increased as a result of
which there is a boost in accuracy.
\\ ( https://arxiv.org/abs/1907.06062 ,  545kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06067
Date: Sat, 13 Jul 2019 12:30:37 GMT   (658kb,D)

Title: ALFA: Agglomerative Late Fusion Algorithm for Object Detection
Authors: Evgenii Razinkov, Iuliia Saveleva, Ji\v{r}i Matas
Categories: cs.CV
Comments: E. Razinkov, I. Saveleva and J. Matas, "ALFA: Agglomerative Late
  Fusion Algorithm for Object Detection," 2018 24th International Conference on
  Pattern Recognition (ICPR), Beijing, 2018, pp. 2594-2599
DOI: 10.1109/ICPR.2018.8545182
\\
  We propose ALFA - a novel late fusion algorithm for object detection. ALFA is
based on agglomerative clustering of object detector predictions taking into
consideration both the bounding box locations and the class scores. Each
cluster represents a single object hypothesis whose location is a weighted
combination of the clustered bounding boxes.
  ALFA was evaluated using combinations of a pair (SSD and DeNet) and a triplet
(SSD, DeNet and Faster R-CNN) of recent object detectors that are close to the
state-of-the-art. ALFA achieves state of the art results on PASCAL VOC 2007 and
PASCAL VOC 2012, outperforming the individual detectors as well as baseline
combination strategies, achieving up to 32% lower error than the best
individual detectors and up to 6% lower error than the reference fusion
algorithm DBF - Dynamic Belief Fusion.
\\ ( https://arxiv.org/abs/1907.06067 ,  658kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06082
Date: Sat, 13 Jul 2019 14:02:21 GMT   (853kb,D)

Title: Adaptive Context Encoding Module for Semantic Segmentation
Authors: Congcong Wang, Faouzi Alaya Cheikh, Azeddine Beghdadi, Ole Jakob Elle
Categories: cs.CV
\\
  The object sizes in images are diverse, therefore, capturing multiple scale
context information is essential for semantic segmentation. Existing context
aggregation methods such as pyramid pooling module (PPM) and atrous spatial
pyramid pooling (ASPP) design different pooling size or atrous rate, such that
multiple scale information is captured. However, the pooling sizes and atrous
rates are chosen manually and empirically. In order to capture object context
information adaptively, in this paper, we propose an adaptive context encoding
(ACE) module based on deformable convolution operation to argument multiple
scale information. Our ACE module can be embedded into other Convolutional
Neural Networks (CNN) easily for context aggregation. The effectiveness of the
proposed module is demonstrated on Pascal-Context and ADE20K datasets. Although
our proposed ACE only consists of three deformable convolution blocks, it
outperforms PPM and ASPP in terms of mean Intersection of Union (mIoU) on both
datasets. All the experiment study confirms that our proposed module is
effective as compared to the state-of-the-art methods.
\\ ( https://arxiv.org/abs/1907.06082 ,  853kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06091
Date: Sat, 13 Jul 2019 14:55:32 GMT   (4913kb,D)

Title: Motion Segmentation Using Locally Affine Atom Voting
Authors: Erez Posner, Rami Hagege
Categories: cs.CV
Comments: 10 pages, 4 figures
\\
  We present a novel method for motion segmentation called LAAV (Locally Affine
Atom Voting). Our model's main novelty is using sets of features to segment
motion for all features in the scene. LAAV acts as a pre-processing pipeline
stage for features in the image, followed by a fine-tuned version of the
state-of-the-art Random Voting (RV) method. Unlike standard approaches, LAAV
segments motion using feature-set affinities instead of pair-wise affinities
between all features; therefore, it significantly simplifies complex scenarios
and reduces the computational cost without a loss of accuracy. We describe how
the challenges encountered by using previously suggested approaches are
addressed using our model. We then compare our algorithm with several
state-of-the-art methods. Experiments shows that our approach achieves the most
accurate motion segmentation results and, in the presence of measurement noise,
achieves comparable results to the other algorithms.
\\ ( https://arxiv.org/abs/1907.06091 ,  4913kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06099
Date: Sat, 13 Jul 2019 15:49:00 GMT   (2685kb,D)

Title: Multi-Task Recurrent Convolutional Network with Correlation Loss for
  Surgical Video Analysis
Authors: Yueming Jin, Huaxia Li, Qi Dou, Hao Chen, Jing Qin, Chi-Wing Fu,
  Pheng-Ann Heng
Categories: cs.CV cs.LG eess.IV
Comments: Minor Revision at Medical Image Analysis
\\
  Surgical tool presence detection and surgical phase recognition are two
fundamental yet challenging tasks in surgical video analysis and also very
essential components in various applications in modern operating rooms. While
these two analysis tasks are highly correlated in clinical practice as the
surgical process is well-defined, most previous methods tackled them
separately, without making full use of their relatedness. In this paper, we
present a novel method by developing a multi-task recurrent convolutional
network with correlation loss (MTRCNet-CL) to exploit their relatedness to
simultaneously boost the performance of both tasks. Specifically, our proposed
MTRCNet-CL model has an end-to-end architecture with two branches, which share
earlier feature encoders to extract general visual features while holding
respective higher layers targeting for specific tasks. Given that temporal
information is crucial for phase recognition, long-short term memory (LSTM) is
explored to model the sequential dependencies in the phase recognition branch.
More importantly, a novel and effective correlation loss is designed to model
the relatedness between tool presence and phase identification of each video
frame, by minimizing the divergence of predictions from the two branches.
Mutually leveraging both low-level feature sharing and high-level prediction
correlating, our MTRCNet-CL method can encourage the interactions between the
two tasks to a large extent, and hence can bring about benefits to each other.
Extensive experiments on a large surgical video dataset (Cholec80) demonstrate
outstanding performance of our proposed method, consistently exceeding the
state-of-the-art methods by a large margin (e.g., 89.1% v.s. 81.0% for the mAP
in tool presence detection and 87.4% v.s. 84.5% for F1 score in phase
recognition). The code can be found on our project website.
\\ ( https://arxiv.org/abs/1907.06099 ,  2685kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06119
Date: Sat, 13 Jul 2019 19:23:42 GMT   (2322kb,D)

Title: Understanding Deep Learning Techniques for Image Segmentation
Authors: Swarnendu Ghosh, Nibaran Das, Ishita Das, Ujjwal Maulik
Categories: cs.CV cs.LG cs.NE
\\
  The machine learning community has been overwhelmed by a plethora of deep
learning based approaches. Many challenging computer vision tasks such as
detection, localization, recognition and segmentation of objects in
unconstrained environment are being efficiently addressed by various types of
deep neural networks like convolutional neural networks, recurrent networks,
adversarial networks, autoencoders and so on. While there have been plenty of
analytical studies regarding the object detection or recognition domain, many
new deep learning techniques have surfaced with respect to image segmentation
techniques. This paper approaches these various deep learning techniques of
image segmentation from an analytical perspective. The main goal of this work
is to provide an intuitive understanding of the major techniques that has made
significant contribution to the image segmentation domain. Starting from some
of the traditional image segmentation approaches, the paper progresses
describing the effect deep learning had on the image segmentation domain.
Thereafter, most of the major segmentation algorithms have been logically
categorized with paragraphs dedicated to their unique contribution. With an
ample amount of intuitive explanations, the reader is expected to have an
improved ability to visualize the internal dynamics of these processes.
\\ ( https://arxiv.org/abs/1907.06119 ,  2322kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06134
Date: Sat, 13 Jul 2019 21:30:41 GMT   (9201kb,D)

Title: FMRI data augmentation via synthesis
Authors: Peiye Zhuang, Alexander G. Schwing, Sanmi Koyejo
Categories: cs.CV cs.LG eess.IV
\\
  We present an empirical evaluation of fMRI data augmentation via synthesis.
For synthesis we use generative mod-els trained on real neuroimaging data to
produce novel task-dependent functional brain images. Analyzed generative
mod-els include classic approaches such as the Gaussian mixture model (GMM),
and modern implicit generative models such as the generative adversarial
network (GAN) and the variational auto-encoder (VAE). In particular, the
proposed GAN and VAE models utilize 3-dimensional convolutions, which enables
modeling of high-dimensional brain image tensors with structured spatial
correlations. The synthesized datasets are then used to augment classifiers
designed to predict cognitive and behavioural outcomes. Our results suggest
that the proposed models are able to generate high-quality synthetic brain
images which are diverse and task-dependent. Perhaps most importantly, the
performance improvements of data aug-mentation via synthesis are shown to be
complementary to the choice of the predictive model. Thus, our results suggest
that data augmentation via synthesis is a promising approach to address the
limited availability of fMRI data, and to improve the quality of predictive
fMRI models.
\\ ( https://arxiv.org/abs/1907.06134 ,  9201kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06147
Date: Sat, 13 Jul 2019 23:27:24 GMT   (632kb,D)

Title: ThirdEye: Triplet Based Iris Recognition without Normalization
Authors: Sohaib Ahmad, Benjamin Fuller
Categories: cs.CV
\\
  Most iris recognition pipelines involve three stages: segmenting into
iris/non-iris pixels, normalization the iris region to a fixed area, and
extracting relevant features for comparison. Given recent advances in deep
learning it is prudent to ask which stages are required for accurate iris
recognition. Lojez et al. (IWBF 2019) recently concluded that the segmentation
stage is still crucial for good accuracy.We ask if normalization is beneficial?
Towards answering this question, we develop a new iris recognition system
called ThirdEye based on triplet convolutional neural networks (Schroff et al.,
ICCV 2015). ThirdEye directly uses segmented images without normalization. We
observe equal error rates of 1.32%, 9.20%, and 0.59% on the ND-0405, UbirisV2,
and IITD datasets respectively. For IITD, the most constrained dataset, this
improves on the best prior work. However, for ND-0405 and UbirisV2,our equal
error rate is slightly worse than prior systems. Our concluding hypothesis is
that normalization is more important for less constrained environments.
\\ ( https://arxiv.org/abs/1907.06147 ,  632kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06160
Date: Sun, 14 Jul 2019 03:29:02 GMT   (5228kb,D)

Title: Smile, be Happy :) Emoji Embedding for Visual Sentiment Analysis
Authors: Ziad Al-Halah, Andrew Aitken, Wenzhe Shi, Jose Caballero
Categories: cs.CV
\\
  Due to the lack of large-scale datasets, the prevailing approach in visual
sentiment analysis is to leverage models trained for object classification in
large datasets like ImageNet. However, objects are sentiment neutral which
hinders the expected gain of transfer learning for such tasks. In this work, we
propose to overcome this problem by learning a novel sentiment-aligned image
embedding that is better suited for subsequent visual sentiment analysis. Our
embedding leverages the intricate relation between emojis and images in
large-scale and readily available data from social media. Emojis are
language-agnostic, consistent, and carry a clear sentiment signal which make
them an excellent proxy to learn a sentiment aligned embedding. Hence, we
construct a novel dataset of $4$ million images collected from Twitter with
their associated emojis. We train a deep neural model for image embedding using
emoji prediction task as a proxy. Our evaluation demonstrates that the proposed
embedding outperforms the popular object-based counterpart consistently across
several sentiment analysis benchmarks. Furthermore, without bell and whistles,
our compact, effective and simple embedding outperforms the more elaborate and
customized state-of-the-art deep models on these public benchmarks.
Additionally, we introduce a novel emoji representation based on their visual
emotional response which support a deeper understanding of the emoji modality
and their usage on social media.
\\ ( https://arxiv.org/abs/1907.06160 ,  5228kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06167
Date: Sun, 14 Jul 2019 05:01:31 GMT   (6423kb,D)

Title: FoodX-251: A Dataset for Fine-grained Food Classification
Authors: Parneet Kaur, Karan Sikka, Weijun Wang, Serge Belongie, Ajay Divakaran
Categories: cs.CV
Comments: Published at Fine-Grained Visual Categorization Workshop, CVPR19
\\
  Food classification is a challenging problem due to the large number of
categories, high visual similarity between different foods, as well as the lack
of datasets for training state-of-the-art deep models. Solving this problem
will require advances in both computer vision models as well as datasets for
evaluating these models. In this paper we focus on the second aspect and
introduce FoodX-251, a dataset of 251 fine-grained food categories with 158k
images collected from the web. We use 118k images as a training set and provide
human verified labels for 40k images that can be used for validation and
testing. In this work, we outline the procedure of creating this dataset and
provide relevant baselines with deep learning models. The FoodX-251 dataset has
been used for organizing iFood-2019 challenge in the Fine-Grained Visual
Categorization workshop (FGVC6 at CVPR 2019) and is available for download.
\\ ( https://arxiv.org/abs/1907.06167 ,  6423kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06206
Date: Sun, 14 Jul 2019 11:18:56 GMT   (6146kb,D)

Title: Unsupervised Automatic Building Extraction Using Active Contour Model on
  Unregistered Optical Imagery and Airborne LiDAR Data
Authors: Thanh Huy Nguyen, Sylvie Daniel, Didier Gueriot, Christophe Sintes,
  Jean-Marc Le Caillec
Categories: cs.CV eess.IV
Comments: PIA19 - Photogrammetric Image Analysis 2019 which will be held in
  conjunction with MRSS19 - Munich Remote Sensing Symposium 2019 on September
  18th-20th, 2019 in Munich, Germany. Proceeding: The International Archives of
  the Photogrammetry, Remote Sensing and Spatial Information Sciences
\\
  Automatic extraction of buildings in urban scenes has become a subject of
growing interest in the domain of photogrammetry and remote sensing,
particularly with the emergence of LiDAR systems since mid-1990s. However, in
reality, this task is still very challenging due to the complexity of building
size and shapes, as well as its surrounding environment. Active contour model,
colloquially called snake model, which has been extensively used in many
applications in computer vision and image processing, is also applied to
extract buildings from aerial/satellite imagery. Motivated by the limitations
of existing snake models addressing to the building extraction, this paper
presents an unsupervised and fully automatic snake model to extract buildings
using optical imagery and an unregistered airborne LiDAR dataset, without
manual initial points or training data. The proposed method is shown to be
capable of extracting buildings with varying color from complex environments,
and yielding high overall accuracy.
\\ ( https://arxiv.org/abs/1907.06206 ,  6146kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06247
Date: Sun, 14 Jul 2019 17:01:50 GMT   (410kb)

Title: State Estimation in Visual Inertial Autonomous Helicopter Landing Using
  Optimisation on Manifold
Authors: Thinh Hoang Dinh, Hieu Le Thi Hong, Tri Ngo Dinh
Categories: cs.CV cs.RO
\\
  Autonomous helicopter landing is a challenging task that requires precise
information about the aircraft states regarding the helicopters position,
attitude, as well as position of the helipad. To this end, we propose a
solution that fuses data from an Inertial Measurement Unit (IMU) and a
monocular camera which is capable of detecting helipads position in the image
plane. The algorithm utilises manifold based nonlinear optimisation over
preintegrated IMU measurements and reprojection error in temporally uniformly
distributed keyframes, exhibiting good performance in terms of accuracy and
being computationally feasible. Our contributions of this paper are the formal
address of the landmarks Jacobian expressions and the adaptation of equality
constrained Gauss-Newton method to this specific problem. Numerical simulations
on MATLAB/Simulink confirm the validity of given claims.
\\ ( https://arxiv.org/abs/1907.06247 ,  410kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06296
Date: Sun, 14 Jul 2019 23:50:42 GMT   (4893kb,D)

Title: Perceptually Motivated Method for Image Inpainting Comparison
Authors: Ivan Molodetskikh, Mikhail Erofeev, Dmitry Vatolin
Categories: cs.CV
Comments: 8 pages, 9 figures
\\
  The field of automatic image inpainting has progressed rapidly in recent
years, but no one has yet proposed a standard method of evaluating algorithms.
This absence is due to the problem's challenging nature: image-inpainting
algorithms strive for realism in the resulting images, but realism is a
subjective concept intrinsic to human perception. Existing objective
image-quality metrics provide a poor approximation of what humans consider more
or less realistic.
  To improve the situation and to better organize both prior and future
research in this field, we conducted a subjective comparison of nine
state-of-the-art inpainting algorithms and propose objective quality metrics
that exhibit high correlation with the results of our comparison.
\\ ( https://arxiv.org/abs/1907.06296 ,  4893kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06319
Date: Mon, 15 Jul 2019 03:05:00 GMT   (519kb)

Title: Enabling Multi-Shell b-Value Generalizability of Data-Driven Diffusion
  Models with Deep SHORE
Authors: Vishwesh Nath, Ilwoo Lyu, Kurt G. Schilling, Prasanna Parvathaneni,
  Colin B. Hansen, Yucheng Tang, Yuankai Huo, Vaibhav A. Janve, Yurui Gao,
  Iwona Stepniewska, Adam W. Anderson, Bennett A. Landman
Categories: cs.CV
\\
  Abstract. Intra-voxel models of the diffusion signal are essential for
interpreting organization of the tissue environment at micrometer level with
data at millimeter resolution. Recent advances in data driven methods have
enabled direct compari-son and optimization of methods for in-vivo data with
externally validated histological sections with both 2-D and 3-D histology.
Yet, all existing methods make limiting assumptions of either (1) model-based
linkages between b-values or (2) limited associations with single shell data.
We generalize prior deep learning models that used single shell spherical
harmonic transforms to integrate the re-cently developed simple harmonic
oscillator reconstruction (SHORE) basis. To enable learning on the SHORE
manifold, we present an alternative formulation of the fiber orientation
distribution (FOD) object using the SHORE basis while rep-resenting the
observed diffusion weighted data in the SHORE basis. To ensure consistency of
hyper-parameter optimization for SHORE, we present our Deep SHORE approach to
learn on a data-optimized manifold. Deep SHORE is evalu-ated with eight-fold
cross-validation of a preclinical MRI-histology data with four b-values.
Generalizability of in-vivo human data is evaluated on two separate 3T MRI
scanners. Specificity in terms of angular correlation (ACC) with the
preclinical data improved on single shell: 0.78 relative to 0.73 and 0.73,
multi-shell: 0.80 relative to 0.74 (p < 0.001). In the in-vivo human data, Deep
SHORE was more consistent across scanners with 0.63 relative to other
multi-shell methods 0.39, 0.52 and 0.57 in terms of ACC. In conclusion, Deep
SHORE is a promising method to enable data driven learning with DW-MRI under
conditions with varying b-values, number of diffusion shells, and gradient
directions per shell.
\\ ( https://arxiv.org/abs/1907.06319 ,  519kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06327
Date: Mon, 15 Jul 2019 04:04:01 GMT   (482kb)

Title: FastV2C-HandNet: Fast Voxel to Coordinate Hand Pose Estimation with 3D
  Convolutional Neural Networks
Authors: Rohan Lekhwani
Categories: cs.CV cs.HC cs.LG eess.IV
Comments: 7 pages, 5 figures, 2 tables. Submitted to WACV 2020
\\
  Hand pose estimation from monocular depth images has been an important and
challenging problem in the Computer Vision community. In this paper, we present
a novel approach to estimate 3D hand joint locations from 2D depth images.
Unlike most of the previous methods, our model captures the 3D spatial
information from a depth image thereby giving it a greater understanding of the
input. We voxelize the input depth map to capture the 3D features of the input
and perform 3D data augmentations to make our network robust to real-world
images. Our network is trained in an end-to-end manner which reduces time and
space complexity significantly when compared to other methods. Through
extensive experiments, we show that our model outperforms state-of-the-art
methods with respect to the time it takes to train and predict 3D hand joint
locations. This makes our method more suitable for real-world hand pose
estimation scenarios.
\\ ( https://arxiv.org/abs/1907.06327 ,  482kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06358
Date: Mon, 15 Jul 2019 08:15:48 GMT   (1837kb,D)

Title: CA-RefineNet:A Dual Input WSI Image Segmentation Algorithm Based on
  Attention
Authors: Ziqiang Li, Rentuo Tao, Qianrun Wu, Bin Li
Categories: cs.CV eess.IV
\\
  Due to the high resolution of pathological images, the automated semantic
segmentation in the medical pathological images has shown greater challenges
than that in natural images. Sliding Window method has shown its effect on
solving problem caused by the high resolution of whole slide images (WSI).
However, owing to its localization, Sliding Window method also suffers from
being lack of global information. In this paper, a dual input semantic
segmentation network based on attention is proposed, in which, one input
provides small-scale fine information, the other input provides large-scale
coarse information. Compared with single input methods, our method CA-RefineNet
exhibits a dramatic performance improvement on ICIAR2018 breast cancer
segmentation task.
\\ ( https://arxiv.org/abs/1907.06358 ,  1837kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06370
Date: Mon, 15 Jul 2019 08:43:49 GMT   (334kb,D)

Title: Multimodal deep networks for text and image-based document
  classification
Authors: Nicolas Audebert, Catherine Herold, Kuider Slimani and C\'edric Vidal
Categories: cs.CV
\\
  Classification of document images is a critical step for archival of old
manuscripts, online subscription and administrative procedures. Computer vision
and deep learning have been suggested as a first solution to classify documents
based on their visual appearance. However, achieving the fine-grained
classification that is required in real-world setting cannot be achieved by
visual analysis alone. Often, the relevant information is in the actual text
content of the document. We design a multimodal neural network that is able to
learn from word embeddings, computed on text extracted by OCR, and from the
image. We show that this approach boosts pure image accuracy by 3% on
Tobacco3482 and RVL-CDIP augmented by our new QS-OCR text dataset
(https://github.com/Quicksign/ocrized-text-dataset), even without clean text
information.
\\ ( https://arxiv.org/abs/1907.06370 ,  334kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06371
Date: Mon, 15 Jul 2019 08:47:14 GMT   (2614kb,D)

Title: Mitigating the Hubness Problem for Zero-Shot Learning of 3D Objects
Authors: Ali Cheraghian, Shafin Rahman, Dylan Campbell, Lars Petersson
Categories: cs.CV
Comments: BMVC 2019
\\
  The development of advanced 3D sensors has enabled many objects to be
captured in the wild at a large scale, and a 3D object recognition system may
therefore encounter many objects for which the system has received no training.
Zero-Shot Learning (ZSL) approaches can assist such systems in recognizing
previously unseen objects. Applying ZSL to 3D point cloud objects is an
emerging topic in the area of 3D vision, however, a significant problem that
ZSL often suffers from is the so-called hubness problem, which is when a model
is biased to predict only a few particular labels for most of the test
instances. We observe that this hubness problem is even more severe for 3D
recognition than for 2D recognition. One reason for this is that in 2D one can
use pre-trained networks trained on large datasets like ImageNet, which
produces high-quality features. However, in the 3D case there are no such
large-scale, labelled datasets available for pre-training which means that the
extracted 3D features are of poorer quality which, in turn, exacerbates the
hubness problem. In this paper, we therefore propose a loss to specifically
address the hubness problem. Our proposed method is effective for both
Zero-Shot and Generalized Zero-Shot Learning, and we perform extensive
evaluations on the challenging datasets ModelNet40, ModelNet10, McGill and
SHREC2015. A new state-of-the-art result for both zero-shot tasks in the 3D
case is established.
\\ ( https://arxiv.org/abs/1907.06371 ,  2614kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06390
Date: Mon, 15 Jul 2019 09:37:40 GMT   (6122kb,D)

Title: Sequence Level Semantics Aggregation for Video Object Detection
Authors: Haiping Wu, Yuntao Chen, Naiyan Wang, Zhaoxiang Zhang
Categories: cs.CV
\\
  Video objection detection (VID) has been a rising research direction in
recent years. A central issue of VID is the appearance degradation of video
frames caused by fast motion. This problem is essentially ill-posed for a
single frame. Therefore, aggregating useful features from other frames becomes
a natural choice. Existing methods heavily rely on optical flow or recurrent
neural networks for feature aggregation. However, these methods emphasize more
on the temporal nearby frames. In this work, we argue that aggregating features
in the whole sequence level will lead to more discriminative and robust
features for video object detection. To achieve this goal, we devise a novel
Sequence Level Semantics Aggregation (SELSA) module. We further demonstrate
that the proposed method has a close relationship with the classical spectral
clustering methods, thus providing a novel view to understand the VID problem.
Lastly, we test our proposed method on the large-scale ImageNet VID dataset and
EPIC KITCHENS dataset and archive new state-of-the-art results compared with
previous works. Moreover, to achieve such superior performance, we do not need
other complicated post-processing methods such as Seq-NMS or Tubelet rescoring
as in previous works, which keeps our pipeline simple and clean.
\\ ( https://arxiv.org/abs/1907.06390 ,  6122kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06406
Date: Mon, 15 Jul 2019 10:06:42 GMT   (7410kb,D)

Title: Improving the Harmony of the Composite Image by Spatial-Separated
  Attention Module
Authors: Cun Xiaodong and Pun Chi-Man
Categories: cs.CV
Comments: Submitted to journal
\\
  Image composition is one of the most important applications in image
processing. However, the inharmonious appearance between the spliced region and
background degrade the quality of the image. Thus, we address the problem of
Image Harmonization: Given a spliced image and the mask of the spliced region,
we try to harmonize the "style'' of the pasted region with the background
(non-spliced region). Previous approaches have been focusing on learning
directly by the neural network. In this work, we start from an empirical
observation: the differences can only be found in the spliced region between
the spliced image and the harmonized result while they share the same semantic
information and the appearance in the non-spliced region. Thus, in order to
learn the feature map in the masked region and the others individually, we
propose a novel attention module named Spatial-Separated Attention Module
(S2AM). Furthermore, we design a novel image harmonization framework by
inserting the S2AM in the coarser low-level features of the Unet structure in
two different ways. Besides image harmonization, we make a big step for
harmonizing the composite image without the specific mask under previous
observation. The experiments show that the proposed S2AM performs better than
other state-of-the-art attention modules in our task. Moreover, we demonstrate
the advantages of our model against other state-of-the-art image harmonization
methods via criteria from multiple points of view. Code is available at
https://github.com/vinthony/s2am
\\ ( https://arxiv.org/abs/1907.06406 ,  7410kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06417
Date: Mon, 15 Jul 2019 10:28:34 GMT   (1375kb,D)

Title: Quick, Stat!: A Statistical Analysis of the Quick, Draw! Dataset
Authors: Raul Fernandez-Fernandez, Juan G. Victores, David Estevez and Carlos
  Balaguer
Categories: cs.CV cs.DB eess.IV
Comments: 12 pages, Eurosim 2019
MSC-class: 68T30
ACM-class: I.2.6; I.5.1; I.3.4
DOI: 10.11128/arep.58
\\
  The Quick, Draw! Dataset is a Google dataset with a collection of 50 million
drawings, divided in 345 categories, collected from the users of the game
Quick, Draw!. In contrast with most of the existing image datasets, in the
Quick, Draw! Dataset, drawings are stored as time series of pencil positions
instead of a bitmap matrix composed by pixels. This aspect makes this dataset
the largest doodle dataset available at the time. The Quick, Draw! Dataset is
presented as a great opportunity to researchers for developing and studying
machine learning techniques. Due to the size of this dataset and the nature of
its source, there is a scarce of information about the quality of the drawings
contained. In this paper, a statistical analysis of three of the classes
contained in the Quick, Draw! Dataset is depicted: mountain, book and whale.
The goal is to give to the reader a first impression of the data collected in
this dataset. For the analysis of the quality of the drawings, a Classification
Neural Network was trained to obtain a classification score. Using this
classification score and the parameters provided by the dataset, a statistical
analysis of the quality and nature of the drawings contained in this dataset is
provided.
\\ ( https://arxiv.org/abs/1907.06417 ,  1375kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06483
Date: Mon, 15 Jul 2019 13:04:31 GMT   (296kb,D)

Title: Color Cerberus
Authors: A.~Savchik, E.~Ershov, S.~Karpenko
Categories: cs.CV cs.LG eess.IV
\\
  Simple convolutional neural network was able to win ISISPA color constancy
competition. Partial reimplementation of (Bianco, 2017) neural architecture
would have shown even better results in this setup.
\\ ( https://arxiv.org/abs/1907.06483 ,  296kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06498
Date: Mon, 15 Jul 2019 13:32:15 GMT   (4456kb,D)

Title: An Efficient Framework for Visible-Infrared Cross Modality Person
  Re-Identification
Authors: Emrah Basaran, Muhittin Gokmen, Mustafa E. Kamasak
Categories: cs.CV
\\
  Visible-infrared cross modality person re-identification (VI-ReId) is an
important task for video surveillance in poorly illuminated or dark
environments. Despite many recent studies on person re-identification in
visible domain (ReId), there are few studies dealing with VI-ReId. Besides
challenges that are common for both ReId and VI-ReId such as pose/illumination
variations, background clutter and occlusion, VI-ReId has additional challenges
as color information is not available in infrared images. As a result, the
performance of VI-ReId systems is typically lower than ReId systems. In this
work, we propose a 4-stream framework to improve VI-ReId performance. We train
a separate deep convolutional neural network in each stream using different
representations of input images. We expect that different and complementary
features can be learned from each stream. In our framework, grayscale and
infrared input images are used to train the ResNet in the first stream. In the
second stream, RGB and 3-channel infrared images (created by repeating infrared
channel) are used. In the remaining two streams, we use local pattern maps as
input images. These maps are generated utilizing local Zernike moments
transformation. Local pattern maps are obtained from grayscale and infrared
images in the 3rd stream and from RGB and 3-channel infrared images in the last
stream. We improve the performance of the proposed framework by employing a
re-ranking algorithm for post processing. Our results indicate that the
proposed framework outperforms current state-of-the-art on SYSU-MM01 dataset
with large margin by improving Rank-1/mAP by 34.2%/37.9% and 37.4%/34.8% under
all-search and indoor-search modes, respectively.
\\ ( https://arxiv.org/abs/1907.06498 ,  4456kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06515
Date: Mon, 15 Jul 2019 14:22:34 GMT   (4867kb,D)

Title: Detecting and Simulating Artifacts in GAN Fake Images
Authors: Xu Zhang, Svebor Karaman, Shih-Fu Chang
Categories: cs.CV eess.IV
Comments: 7 pages, 7 figures
\\
  To detect GAN generated images, conventional supervised machine learning
algorithms require collection of a number of real and fake images from the
targeted GAN model. However, the specific model used by the attacker is often
unavailable. To address this, we propose a GAN simulator, AutoGAN, which can
simulate the artifacts produced by the common pipeline shared by several
popular GAN models. Additionally, we identify a unique artifact caused by the
up-sampling component included in the common GAN pipeline. We show
theoretically such artifacts are manifested as replications of spectra in the
frequency domain and thus propose a classifier model based on the spectrum
input, rather than the pixel input. By using the simulated images to train a
spectrum based classifier, even without seeing the fake images produced by the
targeted GAN model during training, our approach achieves state-of-the-art
performances on detecting fake images generated by popular GAN models such as
CycleGAN.
\\ ( https://arxiv.org/abs/1907.06515 ,  4867kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06565
Date: Mon, 15 Jul 2019 16:15:12 GMT   (1120kb,D)

Title: Recovery Guarantees for Compressible Signals with Adversarial Noise
Authors: Jasjeet Dhaliwal, Kyle Hambrook
Categories: cs.CV cs.CR cs.DS cs.LG eess.SP stat.ML
\\
  We provide recovery guarantees for compressible signals that have been
corrupted with noise and extend the framework introduced in [1] to defend
neural networks against $\ell_0$-norm and $\ell_2$-norm attacks. Concretely,
for a signal that is approximately sparse in some transform domain and has been
perturbed with noise, we provide guarantees for accurately recovering the
signal in the transform domain. We can then use the recovered signal to
reconstruct the signal in its original domain while largely removing the noise.
Our results are general as they can be directly applied to most unitary
transforms used in practice and hold for both $\ell_0$-norm bounded noise and
$\ell_2$-norm bounded noise. In the case of $\ell_0$-norm bounded noise, we
prove recovery guarantees for Iterative Hard Thresholding (IHT) and Basis
Pursuit (BP). For the case of $\ell_2$-norm bounded noise, we provide recovery
guarantees for BP. These guarantees theoretically bolster the defense framework
introduced in [1] for defending neural networks against adversarial inputs.
Finally, we experimentally demonstrate this defense framework using both IHT
and BP against the One Pixel Attack [21], Carlini-Wagner $\ell_0$ and $\ell_2$
attacks [3], Jacobian Saliency Based attack [18], and the DeepFool attack [17]
on CIFAR-10 [12], MNIST [13], and Fashion-MNIST [27] datasets. This expands
beyond the experimental demonstrations of [1].
\\ ( https://arxiv.org/abs/1907.06565 ,  1120kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06571
Date: Mon, 15 Jul 2019 16:27:04 GMT   (9611kb,D)

Title: Efficient Video Generation on Complex Datasets
Authors: Aidan Clark, Jeff Donahue, Karen Simonyan
Categories: cs.CV cs.LG stat.ML
\\
  Generative models of natural images have progressed towards high fidelity
samples by the strong leveraging of scale. We attempt to carry this success to
the field of video modeling by showing that large Generative Adversarial
Networks trained on the complex Kinetics-600 dataset are able to produce video
samples of substantially higher complexity than previous work. Our proposed
network, Dual Video Discriminator GAN (DVD-GAN), scales to longer and higher
resolution videos by leveraging a computationally efficient decomposition of
its discriminator. We evaluate on the related tasks of video synthesis and
video prediction, and achieve new state of the art Frechet Inception Distance
on prediction for Kinetics-600, as well as state of the art Inception Score for
synthesis on the UCF-101 dataset, alongside establishing a number of strong
baselines on Kinetics-600.
\\ ( https://arxiv.org/abs/1907.06571 ,  9611kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06625
Date: Mon, 15 Jul 2019 17:57:17 GMT   (2995kb,D)

Title: Multi-scale Graph-based Grading for Alzheimer's Disease Prediction
Authors: Kilian Hett, Vinh-Thong Ta, Jos\'e V. Manj\'on, Pierrick Coup\'e
Categories: cs.CV
\\
  The prediction of subjects with mild cognitive impairment (MCI) who will
progress to Alzheimer's disease (AD) is clinically relevant, and may above all
have a significant impact on accelerate the development of new treatments. In
this paper, we present a new MRI-based biomarker that enables us to predict
conversion of MCI subjects to AD accurately. In order to better capture the AD
signature, we introduce two main contributions. First, we present a new
graph-based grading framework to combine inter-subject similarity features and
intra-subject variability features. This framework involves patch-based grading
of anatomical structures and graph-based modeling of structure alteration
relationships. Second, we propose an innovative multiscale brain analysis to
capture alterations caused by AD at different anatomical levels. Based on a
cascade of classifiers, this multiscale approach enables the analysis of
alterations of whole brain structures and hippocampus subfields at the same
time. During our experiments using the ADNI-1 dataset, the proposed multiscale
graph-based grading method obtained an area under the curve (AUC) of 81% to
predict conversion of MCI subjects to AD within three years. Moreover, when
combined with cognitive scores, the proposed method obtained 85% of AUC. These
results are competitive in comparison to state-of-the-art methods evaluated on
the same dataset.
\\ ( https://arxiv.org/abs/1907.06625 ,  2995kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05888
Date: Fri, 12 Jul 2019 11:11:02 GMT   (734kb,D)

Title: Regularized HessELM and Inclined Entropy Measurement for Congestive
  Heart Failure Prediction
Authors: Apdullah Yay{\i}k, Yakup Kutlu, G\"okhan Altan
Categories: cs.LG cs.HC cs.NA eess.SP math.NA physics.med-ph
Comments: 9 pages, 3 figures, neuroprocessing letter
\\
  Our study concerns with automated predicting of congestive heart failure
(CHF) through the analysis of electrocardiography (ECG) signals. A novel
machine learning approach, regularized hessenberg decomposition based extreme
learning machine (R-HessELM), and feature models; squared, circled, inclined
and grid entropy measurement were introduced and used for prediction of CHF.
This study proved that inclined entropy measurements features well represent
characteristics of ECG signals and together with R-HessELM approach overall
accuracy of 98.49% was achieved.
\\ ( https://arxiv.org/abs/1907.05888 ,  734kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05911
Date: Fri, 12 Jul 2019 18:15:56 GMT   (1107kb,D)

Title: Differentiable Bayesian Neural Network Inference for Data Streams
Authors: Namuk Park, Taekyu Lee, Songkuk Kim
Categories: cs.LG stat.ML
\\
  While deep neural networks (NNs) do not provide the confidence of its
prediction, Bayesian neural network (BNN) can estimate the uncertainty of the
prediction. However, BNNs have not been widely used in practice due to the
computational cost of inference. This prohibitive computational cost is a
hindrance especially when processing stream data with low-latency. To address
this problem, we propose a novel model which approximate BNNs for data streams.
Instead of generating separate prediction for each data sample independently,
this model estimates the increments of prediction for a new data sample from
the previous predictions. The computational cost of this model is almost the
same as that of non-Bayesian NNs. Experiments with semantic segmentation on
real-world data show that this model performs significantly faster than BNNs,
estimating uncertainty comparable to the results of BNNs.
\\ ( https://arxiv.org/abs/1907.05911 ,  1107kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05912
Date: Fri, 12 Jul 2019 18:22:09 GMT   (117kb,D)

Title: MIPaaL: Mixed Integer Program as a Layer
Authors: Aaron Ferber, Bryan Wilder, Bistra Dilina, Milind Tambe
Categories: cs.LG cs.AI
\\
  Machine learning components commonly appear in larger decision-making
pipelines; however, the model training process typically focuses only on a loss
that measures accuracy between predicted values and ground truth values.
Decision-focused learning explicitly integrates the downstream decision problem
when training the predictive model, in order to optimize the quality of
decisions induced by the predictions. It has been successfully applied to
several limited combinatorial problem classes, such as those that can be
expressed as linear programs (LP), and submodular optimization. However, these
previous applications have uniformly focused on problems from specific classes
with simple constraints. Here, we enable decision-focused learning for the
broad class of problems that can be encoded as a Mixed Integer Linear Program
(MIP), hence supporting arbitrary linear constraints over discrete and
continuous variables. We show how to differentiate through a MIP by employing a
cutting planes solution approach, which is an exact algorithm that iteratively
adds constraints to a continuous relaxation of the problem until an integral
solution is found. We evaluate our new end-to-end approach on several real
world domains and show that it outperforms the standard two phase approaches
that treat prediction and prescription separately, as well as a baseline
approach of simply applying decision-focused learning to the LP relaxation of
the MIP.
\\ ( https://arxiv.org/abs/1907.05912 ,  117kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05943
Date: Sat, 13 Jul 2019 05:27:57 GMT   (621kb)

Title: A Study and Analysis of a Feature Subset Selection Technique using
  Penguin Search Optimization Algorithm (FS-PeSOA)
Authors: Agnip Dasgupta, Ardhendu Banerjee, Aniket Ghosh Dastidar, Antara
  Barman, Sanjay Chakraborty
Categories: cs.LG stat.ML
\\
  In today world of enormous amounts of data, it is very important to extract
useful knowledge from it. This can be accomplished by feature subset selection.
Feature subset selection is a method of selecting a minimum number of features
with the help of which our machine can learn and predict which class a
particular data belongs to. We will introduce a new adaptive algorithm called
Feature selection Penguin Search optimization algorithm which is a
metaheuristic approach. It is adapted from the natural hunting strategy of
penguins in which a group of penguins take jumps at random depths and come back
and share the status of food availability with other penguins and in this way,
the global optimum solution is found. In order to explore the feature subset
candidates, the bioinspired approach Penguin Search optimization algorithm
generates during the process a trial feature subset and estimates its fitness
value by using three different classifiers for each case: Random Forest,
Nearest Neighbour and Support Vector Machines. However, we are planning to
implement our proposed approach Feature selection Penguin Search optimization
algorithm on some well known benchmark datasets collected from the UCI
repository and also try to evaluate and compare its classification accuracy
with some state of art algorithms.
\\ ( https://arxiv.org/abs/1907.05943 ,  621kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06010
Date: Sat, 13 Jul 2019 05:16:39 GMT   (37kb)

Title: The Futility of Bias-Free Learning and Search
Authors: George D. Montanez, Jonathan Hayase, Julius Lauw, Dominique Macias,
  Akshay Trikha, Julia Vendemiatti
Categories: cs.LG stat.ML
\\
  Building on the view of machine learning as search, we demonstrate the
necessity of bias in learning, quantifying the role of bias (measured relative
to a collection of possible datasets, or more generally, information resources)
in increasing the probability of success. For a given degree of bias towards a
fixed target, we show that the proportion of favorable information resources is
strictly bounded from above. Furthermore, we demonstrate that bias is a
conserved quantity, such that no algorithm can be favorably biased towards many
distinct targets simultaneously. Thus bias encodes trade-offs. The probability
of success for a task can also be measured geometrically, as the angle of
agreement between what holds for the actual task and what is assumed by the
algorithm, represented in its bias. Lastly, finding a favorably biasing
distribution over a fixed set of information resources is provably difficult,
unless the set of resources itself is already favorable with respect to the
given task and algorithm.
\\ ( https://arxiv.org/abs/1907.06010 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06022
Date: Sat, 13 Jul 2019 07:29:42 GMT   (7374kb,D)

Title: Multiscale Principle of Relevant Information for Hyperspectral Image
  Classification
Authors: Yantao Wei, Shujian Yu, Jose C. Principe
Categories: cs.LG eess.IV stat.ML
\\
  This paper proposes a novel architecture, termed multiscale principle of
relevant information (MPRI), to learn discriminative spectral-spatial features
for hyperspectral image (HSI) classification. MPRI inherits the merits of the
principle of relevant information (PRI) to effectively extract multiscale
information embedded in the given data, and also takes advantage of the
multilayer structure to learn representations in a coarse-to-fine manner.
Specifically, MPRI performs spectral-spatial pixel characterization (using PRI)
and feature dimensionality reduction (using regularized linear discriminant
analysis) iteratively and successively. Extensive experiments on four benchmark
data sets demonstrate that MPRI outperforms existing state-of-the-art HSI
classification methods (including deep learning based ones) qualitatively and
quantitatively, especially in the scenario of limited training samples.
\\ ( https://arxiv.org/abs/1907.06022 ,  7374kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06032
Date: Sat, 13 Jul 2019 09:15:02 GMT   (123kb)

Title: Minimal Sample Subspace Learning: Theory and Algorithms
Authors: Zhenyue Zhang and Yuqing Xia
Categories: cs.LG stat.ML
\\
  Subspace segmentation or subspace learning is a challenging and complicated
task in machine learning. This paper builds a primary frame and solid
theoretical bases for the minimal subspace segmentation (MSS) of finite
samples. Existence and conditional uniqueness of MSS are discussed with
conditions generally satisfied in applications. Utilizing weak prior
information of MSS, the minimality inspection of segments is further simplified
to the prior detection of partitions. The MSS problem is then modeled as a
computable optimization problem via self-expressiveness of samples. A closed
form of representation matrices is first given for the self-expressiveness, and
the connection of diagonal blocks is then addressed. The MSS model uses a rank
restriction on the sum of segment ranks. Theoretically, it can retrieve the
minimal sample subspaces that could be heavily intersected. The optimization
problem is solved via a basic manifold conjugate gradient algorithm,
alternative optimization and hybrid optimization, taking into account of
solving both the primal MSS problem and its pseudo-dual problem. The MSS model
is further modified for handling noisy data, and solved by an ADMM algorithm.
The reported experiments show the strong ability of the MSS method on
retrieving minimal sample subspaces that are heavily intersected.
\\ ( https://arxiv.org/abs/1907.06032 ,  123kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06048
Date: Sat, 13 Jul 2019 11:27:13 GMT   (792kb,D)

Title: Multi-Element Long Distance Dependencies: Using SPk Languages to Explore
  the Characteristics of Long-Distance Dependencies
Authors: Abhijit Mahalunkar and John D. Kelleher
Categories: cs.LG cs.FL stat.ML
Comments: To appear in ACL 2019 workshop on Deep Learning and Formal Languages:
  Building Bridges
\\
  In order to successfully model Long Distance Dependencies (LDDs) it is
necessary to understand the full-range of the characteristics of the LDDs
exhibited in a target dataset. In this paper, we use Strictly k-Piecewise
languages to generate datasets with various properties. We then compute the
characteristics of the LDDs in these datasets using mutual information and
analyze the impact of factors such as (i) k, (ii) length of LDDs, (iii)
vocabulary size, (iv) forbidden subsequences, and (v) dataset size. This
analysis reveal that the number of interacting elements in a dependency is an
important characteristic of LDDs. This leads us to the challenge of modelling
multi-element long-distance dependencies. Our results suggest that attention
mechanisms in neural networks may aide in modeling datasets with multi-element
long-distance dependencies. However, we conclude that there is a need to
develop more efficient attention mechanisms to address this issue.
\\ ( https://arxiv.org/abs/1907.06048 ,  792kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06058
Date: Sat, 13 Jul 2019 11:46:19 GMT   (83kb,D)

Title: Aggregate-Eliminate-Predict: Detecting Adverse Drug Events from
  Heterogeneous Electronic Health Records
Authors: Maria Bampa and Panagiotis Papapetrou
Categories: cs.LG cs.CY stat.ML
Comments: 4 pages
\\
  We study the problem of detecting adverse drug events in electronic
healthcare records. The challenge in this work is to aggregate heterogeneous
data types involving diagnosis codes, drug codes, as well as lab measurements.
An earlier framework proposed for the same problem demonstrated promising
predictive performance for the random forest classifier by using only lab
measurements as data features. We extend this framework, by additionally
including diagnosis and drug prescription codes, concurrently. In addition, we
employ a recursive feature selection mechanism on top, that extracts the top-k
most important features. Our experimental evaluation on five medical datasets
of adverse drug events and six different classifiers, suggests that the
integration of these additional features provides substantial and statistically
significant improvements in terms of AUC, while employing medically relevant
features.
\\ ( https://arxiv.org/abs/1907.06058 ,  83kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06064
Date: Sat, 13 Jul 2019 12:17:00 GMT   (3054kb,D)

Title: Image Evolution Trajectory Prediction and Classification from Baseline
  using Learning-based Patch Atlas Selection for Early Diagnosis
Authors: Can Gafuroglu and Islem Rekik
Categories: cs.LG cs.CV stat.ML
\\
  Patients initially diagnosed with early mild cognitive impairment (eMCI) are
known to be a clinically heterogeneous group with very subtle patterns of brain
atrophy. To examine the boarders between normal controls (NC) and eMCI,
Magnetic Resonance Imaging (MRI) was extensively used as a non-invasive imaging
modality to pin-down subtle changes in brain images of MCI patients. However,
eMCI research remains limited by the number of available MRI acquisition
timepoints. Ideally, one would learn how to diagnose MCI patients in an early
stage from MRI data acquired at a single timepoint, while leveraging
'non-existing' follow-up observations. To this aim, we propose novel supervised
and unsupervised frameworks that learn how to jointly predict and label the
evolution trajectory of intensity patches, each seeded at a specific brain
landmark, from a baseline intensity patch. Specifically, both strategies aim to
identify the best training atlas patches at baseline timepoint to predict and
classify the evolution trajectory of a given testing baseline patch. The
supervised technique learns how to select the best atlas patches by training
bidirectional mappings from the space of pairwise patch similarities to their
corresponding prediction errors -when one patch was used to predict the other.
On the other hand, the unsupervised technique learns a manifold of baseline
atlas and testing patches using multiple kernels to well capture patch
distributions at multiple scales. Once the best baseline atlas patches are
selected, we retrieve their evolution trajectories and average them to predict
the evolution trajectory of the testing baseline patch. Next, we input the
predicted trajectories to an ensemble of linear classifiers, each trained at a
specific landmark. Our classification accuracy increased by up to 10% points in
comparison to single timepoint-based classification methods.
\\ ( https://arxiv.org/abs/1907.06064 ,  3054kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06065
Date: Sat, 13 Jul 2019 12:24:37 GMT   (6315kb,D)

Title: Bringing Giant Neural Networks Down to Earth with Unlabeled Data
Authors: Yehui Tang, Shan You, Chang Xu, Boxin Shi and Chao Xu
Categories: cs.LG stat.ML
\\
  Compressing giant neural networks has gained much attention for their
extensive applications on edge devices such as cellphones. During the
compressing process, one of the most important procedures is to retrain the
pre-trained models using the original training dataset. However, due to the
consideration of security, privacy or commercial profits, in practice, only a
fraction of sample training data are made available, which makes the retraining
infeasible. To solve this issue, this paper proposes to resort to unlabeled
data in hand that can be cheaper to acquire. Specifically, we exploit the
unlabeled data to mimic the classification characteristics of giant networks,
so that the original capacity can be preserved nicely. Nevertheless, there
exists a dataset bias between the labeled and unlabeled data, disturbing the
mimicking to some extent. We thus fix this bias by an adversarial loss to make
an alignment on the distributions of their low-level feature representations.
We further provide theoretical discussions about how the unlabeled data help
compressed networks to generalize better. Experimental results demonstrate that
the unlabeled data can significantly improve the performance of the compressed
networks.
\\ ( https://arxiv.org/abs/1907.06065 ,  6315kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06090
Date: Sat, 13 Jul 2019 14:55:11 GMT   (37kb)

Title: Parameterized Exploration
Authors: Jesse Clifton, Lili Wu, Eric Laber
Categories: cs.LG cs.AI stat.ML
\\
  We introduce Parameterized Exploration (PE), a simple family of methods for
model-based tuning of the exploration schedule in sequential decision problems.
Unlike common heuristics for exploration, our method accounts for the time
horizon of the decision problem as well as the agent's current state of
knowledge of the dynamics of the decision problem. We show our method as
applied to several common exploration techniques has superior performance
relative to un-tuned counterparts in Bernoulli and Gaussian multi-armed
bandits, contextual bandits, and a Markov decision process based on a mobile
health (mHealth) study. We also examine the effects of the accuracy of the
estimated dynamics model on the performance of PE.
\\ ( https://arxiv.org/abs/1907.06090 ,  37kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06123
Date: Sat, 13 Jul 2019 20:27:15 GMT   (450kb,D)

Title: Preselection Bandits under the Plackett-Luce Model
Authors: Viktor Bengs and Eyke H\"ullermeier
Categories: cs.LG stat.ML
\\
  In this paper, we introduce the Preselection Bandit problem, in which the
learner preselects a subset of arms (choice alternatives) for a user, which
then chooses the final arm from this subset. The learner is not aware of the
user's preferences, but can learn them from observed choices. In our concrete
setting, we allow these choices to be stochastic and model the user's actions
by means of the Plackett-Luce model. The learner's main task is to preselect
subsets that eventually lead to highly preferred choices. To formalize this
goal, we introduce a reasonable notion of regret and derive lower bounds on the
expected regret. Moreover, we propose algorithms for which the upper bound on
expected regret matches the lower bound up to a logarithmic term of the time
horizon.
\\ ( https://arxiv.org/abs/1907.06123 ,  450kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06138
Date: Sat, 13 Jul 2019 21:58:06 GMT   (216kb,D)

Title: Stochastic Convergence Results for Regularized Actor-Critic Methods
Authors: Wesley Suttle, Zhuoran Yang, Kaiqing Zhang, Ji Liu
Categories: cs.LG stat.ML
\\
  In this paper, we present a stochastic convergence proof, under suitable
conditions, of a certain class of actor-critic algorithms for finding
approximate solutions to entropy-regularized MDPs using the machinery of
stochastic approximation. To obtain this overall result, we provide three
fundamental results that are all of both practical and theoretical interest: we
prove the convergence of policy evaluation with general regularizers when using
linear approximation architectures, we derive an entropy-regularized policy
gradient theorem, and we show convergence of entropy-regularized policy
improvement. We also provide a simple, illustrative empirical study
corroborating our theoretical results. To the best of our knowledge, this is
the first time such results have been provided for approximate solution methods
for regularized MDPs.
\\ ( https://arxiv.org/abs/1907.06138 ,  216kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06143
Date: Sat, 13 Jul 2019 22:57:23 GMT   (7289kb,D)

Title: Neural Embedding for Physical Manipulations
Authors: Lingzhi Zhang, Andong Cao, Rui Li, Jianbo Shi
Categories: cs.LG cs.CV
\\
  In common real-world robotic operations, action and state spaces can be vast
and sometimes unknown, and observations are often relatively sparse. How do we
learn the full topology of action and state spaces when given only few and
sparse observations? Inspired by the properties of grid cells in mammalian
brains, we build a generative model that enforces a normalized pairwise
distance constraint between the latent space and output space to achieve
data-efficient discovery of output spaces. This method achieves substantially
better results than prior generative models, such as Generative Adversarial
Networks (GANs) and Variational Auto-Encoders (VAEs). Prior models have the
common issue of mode collapse and thus fail to explore the full topology of
output space. We demonstrate the effectiveness of our model on various datasets
both qualitatively and quantitatively.
\\ ( https://arxiv.org/abs/1907.06143 ,  7289kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06162
Date: Sun, 14 Jul 2019 03:50:38 GMT   (1372kb,D)

Title: Modeling the Uncertainty in Electronic Health Records: a Bayesian Deep
  Learning Approach
Authors: Riyi Qiu, Yugang Jia, Mirsad Hadzikadic, Michael Dulin, Xi Niu, and
  Xin Wang
Categories: cs.LG stat.ML
Comments: 4 pages, 3 figures, 2 tables. 2019 KDD Workshop on Applied Data
  Science for Healthcare. Anchorage, AK, USA, August 5, 2019
\\
  Deep learning models have exhibited superior performance in predictive tasks
with the explosively increasing Electronic Health Records (EHR). However, due
to the lack of transparency, behaviors of deep learning models are difficult to
interpret. Without trustworthiness, deep learning models will not be able to
assist in the real-world decision-making process of healthcare issues. We
propose a deep learning model based on Bayesian Neural Networks (BNN) to
predict uncertainty induced by data noise. The uncertainty is introduced to
provide model predictions with an extra level of confidence. Our experiments
verify that instances with high uncertainty are harmful to model performance.
Moreover, by investigating the distributions of model prediction and
uncertainty, we show that it is possible to identify a group of patients for
timely intervention, such that decreasing data noise will benefit more on the
prediction accuracy for these patients.
\\ ( https://arxiv.org/abs/1907.06162 ,  1372kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06166
Date: Sun, 14 Jul 2019 05:01:05 GMT   (1456kb,D)

Title: Compressed Subspace Learning Based on Canonical Angle Preserving
  Property
Authors: Yuchen Jiao, Gen Li, and Yuantao Gu
Categories: cs.LG cs.IT math.IT stat.ML
Comments: 38 pages, 5 figures
\\
  A standard way to tackle the challenging task of learning from
high-dimensional data is to exploit its underlying low-dimensional structure.
Union of Subspaces (UoS) is a popular and powerful model to describe such
structure which assumes that the data lies in the union of a collection of
low-dimensional subspaces. Extracting useful information from UoS structure of
data has become the task of the newly-emerged field of subspace learning. In
this paper, we investigate how random projection, an efficient and
commonly-used method for dimensionality reduction, distorts the UoS structure
of data. Here the fine details of UoS structure are described in terms of
canonical angles (also known as principal angles) between subspaces, which is a
well-known characterization for relative subspace positions by a sequence of
angles. It is proved that random projection with the so-called
Johnson-Lindenstrauss (JL) property approximately preserves canonical angles
between subspaces. As canonical angles completely determine the relative
position of subspaces, our result indicates that random projection
approximately preserves structure of a union of subspaces. Inspired by this
result, we propose in this paper the framework of Compressed Subspace Learning
(CSL), which enables to extract useful information from the UoS structure of
data in a greatly reduced dimension and has the advantage of lower
computational cost and memory requirements. We demonstrate the effectiveness of
CSL in various subspace-related tasks such as subspace visualization, active
subspace detection, and subspace clustering.
\\ ( https://arxiv.org/abs/1907.06166 ,  1456kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06173
Date: Sun, 14 Jul 2019 06:37:24 GMT   (108kb,D)

Title: The FAST Algorithm for Submodular Maximization
Authors: Adam Breuer, Eric Balkanski, Yaron Singer
Categories: cs.LG cs.DS stat.ML
\\
  In this paper we describe a new algorithm called Fast Adaptive Sequencing
Technique (FAST) for maximizing a monotone submodular function under a
cardinality constraint $k$ whose approximation ratio is arbitrarily close to
$1-1/e$, is $O(\log(n) \log^2(\log k))$ adaptive, and uses a total of $O(n
\log\log(k))$ queries. Recent algorithms have comparable guarantees in terms of
asymptotic worst case analysis, but their actual number of rounds and query
complexity depend on very large constants and polynomials in terms of precision
and confidence, making them impractical for large data sets. Our main
contribution is a design that is extremely efficient both in terms of its
non-asymptotic worst case query complexity and number of rounds, and in terms
of its practical runtime. We show that this algorithm outperforms any algorithm
for submodular maximization we are aware of, including hyper-optimized parallel
versions of state-of-the-art serial algorithms, by running experiments on large
data sets. These experiments show FAST is orders of magnitude faster than the
state-of-the-art.
\\ ( https://arxiv.org/abs/1907.06173 ,  108kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06194
Date: Sun, 14 Jul 2019 09:50:45 GMT   (1572kb,D)

Title: A Divide-and-Conquer Approach towards Understanding Deep Networks
Authors: Weilin Fu, Katharina Breininger, Roman Schaffert, Nishant Ravikumar,
  Andreas Maier
Categories: cs.LG cs.CV eess.IV
Comments: This paper is accepted in MICCAI 2019
\\
  Deep neural networks have achieved tremendous success in various fields
including medical image segmentation. However, they have long been criticized
for being a black-box, in that interpretation, understanding and correcting
architectures is difficult as there is no general theory for deep neural
network design. Previously, precision learning was proposed to fuse deep
architectures and traditional approaches. Deep networks constructed in this way
benefit from the original known operator, have fewer parameters, and improved
interpretability. However, they do not yield state-of-the-art performance in
all applications. In this paper, we propose to analyze deep networks using
known operators, by adopting a divide-and-conquer strategy to replace network
components, whilst retaining its performance. The task of retinal vessel
segmentation is investigated for this purpose. We start with a high-performance
U-Net and show by step-by-step conversion that we are able to divide the
network into modules of known operators. The results indicate that a
combination of a trainable guided filter and a trainable version of the Frangi
filter yields a performance at the level of U-Net (AUC 0.974 vs. 0.972) with a
tremendous reduction in parameters (111,536 vs. 9,575). In addition, the
trained layers can be mapped back into their original algorithmic
interpretation and analyzed using standard tools of signal processing.
\\ ( https://arxiv.org/abs/1907.06194 ,  1572kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06198
Date: Sun, 14 Jul 2019 10:10:28 GMT   (17kb)

Title: On the Role of Time in Learning
Authors: Alessandro Betti, Marco Gori
Categories: cs.LG stat.ML
Comments: 7 pages
\\
  By and large the process of learning concepts that are embedded in time is
regarded as quite a mature research topic. Hidden Markov models, recurrent
neural networks are, amongst others, successful approaches to learning from
temporal data. In this paper, we claim that the dominant approach minimizing
appropriate risk functions defined over time by classic stochastic gradient
might miss the deep interpretation of time given in other fields like physics.
We show that a recent reformulation of learning according to the principle of
Least Cognitive Action is better suited whenever time is involved in learning.
The principle gives rise to a learning process that is driven by differential
equations, that can somehow descrive the process within the same framework as
other laws of nature.
\\ ( https://arxiv.org/abs/1907.06198 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06214
Date: Sun, 14 Jul 2019 12:22:57 GMT   (134kb,D)

Title: Task Selection Policies for Multitask Learning
Authors: John Glover and Chris Hokamp
Categories: cs.LG stat.ML
\\
  One of the questions that arises when designing models that learn to solve
multiple tasks simultaneously is how much of the available training budget
should be devoted to each individual task. We refer to any formalized approach
to addressing this problem (learned or otherwise) as a task selection policy.
In this work we provide an empirical evaluation of the performance of some
common task selection policies in a synthetic bandit-style setting, as well as
on the GLUE benchmark for natural language understanding. We connect task
selection policy learning to existing work on automated curriculum learning and
off-policy evaluation, and suggest a method based on counterfactual estimation
that leads to improved model performance in our experimental settings.
\\ ( https://arxiv.org/abs/1907.06214 ,  134kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06246
Date: Sun, 14 Jul 2019 16:50:26 GMT   (53kb)

Title: On the Global Convergence of Actor-Critic: A Case for Linear Quadratic
  Regulator with Ergodic Cost
Authors: Zhuoran Yang, Yongxin Chen, Mingyi Hong, Zhaoran Wang
Categories: cs.LG math.OC stat.ML
Comments: 41 pages
\\
  Despite the empirical success of the actor-critic algorithm, its theoretical
understanding lags behind. In a broader context, actor-critic can be viewed as
an online alternating update algorithm for bilevel optimization, whose
convergence is known to be fragile. To understand the instability of
actor-critic, we focus on its application to linear quadratic regulators, a
simple yet fundamental setting of reinforcement learning. We establish a
nonasymptotic convergence analysis of actor-critic in this setting. In
particular, we prove that actor-critic finds a globally optimal pair of actor
(policy) and critic (action-value function) at a linear rate of convergence.
Our analysis may serve as a preliminary step towards a complete theoretical
understanding of bilevel optimization with nonconvex subproblems, which is
NP-hard in the worst case and is often solved using heuristics.
\\ ( https://arxiv.org/abs/1907.06246 ,  53kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06257
Date: Sun, 14 Jul 2019 18:34:44 GMT   (1165kb,D)

Title: More Supervision, Less Computation: Statistical-Computational Tradeoffs
  in Weakly Supervised Learning
Authors: Xinyang Yi, Zhaoran Wang, Zhuoran Yang, Constantine Caramanis, Han Liu
Categories: cs.LG cs.CC stat.ML
Comments: This work has been published in NeurIPS 2016. The first three authors
  contribute equally
Journal-ref: Advances in Neural Information Processing Systems (2016):
  4482-4490
\\
  We consider the weakly supervised binary classification problem where the
labels are randomly flipped with probability $1- {\alpha}$. Although there
exist numerous algorithms for this problem, it remains theoretically unexplored
how the statistical accuracies and computational efficiency of these algorithms
depend on the degree of supervision, which is quantified by ${\alpha}$. In this
paper, we characterize the effect of ${\alpha}$ by establishing the
information-theoretic and computational boundaries, namely, the minimax-optimal
statistical accuracy that can be achieved by all algorithms, and
polynomial-time algorithms under an oracle computational model. For small
${\alpha}$, our result shows a gap between these two boundaries, which
represents the computational price of achieving the information-theoretic
boundary due to the lack of supervision. Interestingly, we also show that this
gap narrows as ${\alpha}$ increases. In other words, having more supervision,
i.e., more correct labels, not only improves the optimal statistical accuracy
as expected, but also enhances the computational efficiency for achieving such
accuracy.
\\ ( https://arxiv.org/abs/1907.06257 ,  1165kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06258
Date: Sun, 14 Jul 2019 18:35:58 GMT   (467kb,D)

Title: Feature space transformations and model selection to improve the
  performance of classifiers
Authors: Jose Ortiz-Bejar, Eric S. Tellez and Mario Graff
Categories: cs.LG stat.ML
\\
  Improving the performance of classifiers is the realm of prototype selection
and kernel transformations. Prototype selection has been used to reduce the
space complexity of k-Nearest Neighbors classifiers and to improve its
accuracy, and kernel transformations enhanced the performance of linear
classifiers by converting a non-linear separable problem into a linear one in
the transformed space. Our proposal combines, in a model selection scheme,
these transformations with classic algorithms such as Na\"ive Bayes and
k-Nearest Neighbors to produce a competitive classifier. We analyzed our
approach on different classification problems and compared it to
state-of-the-art classifiers. The results show that the methodology proposed is
competitive, obtaining the lowest rank among the classifiers being compared.
\\ ( https://arxiv.org/abs/1907.06258 ,  467kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06260
Date: Sun, 14 Jul 2019 18:44:09 GMT   (2713kb,D)

Title: Counterfactual Reasoning for Fair Clinical Risk Prediction
Authors: Stephen Pfohl, Tony Duan, Daisy Yi Ding, Nigam H. Shah
Categories: cs.LG cs.CY stat.ML
Comments: Machine Learning for Healthcare 2019
\\
  The use of machine learning systems to support decision making in healthcare
raises questions as to what extent these systems may introduce or exacerbate
disparities in care for historically underrepresented and mistreated groups,
due to biases implicitly embedded in observational data in electronic health
records. To address this problem in the context of clinical risk prediction
models, we develop an augmented counterfactual fairness criteria to extend the
group fairness criteria of equalized odds to an individual level. We do so by
requiring that the same prediction be made for a patient, and a counterfactual
patient resulting from changing a sensitive attribute, if the factual and
counterfactual outcomes do not differ. We investigate the extent to which the
augmented counterfactual fairness criteria may be applied to develop fair
models for prolonged inpatient length of stay and mortality with observational
electronic health records data. As the fairness criteria is ill-defined without
knowledge of the data generating process, we use a variational autoencoder to
perform counterfactual inference in the context of an assumed causal graph.
While our technique provides a means to trade off maintenance of fairness with
reduction in predictive performance in the context of a learned generative
model, further work is needed to assess the generality of this approach.
\\ ( https://arxiv.org/abs/1907.06260 ,  2713kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06288
Date: Sun, 14 Jul 2019 22:07:15 GMT   (1303kb,D)

Title: Learning Neural Networks with Adaptive Regularization
Authors: Han Zhao and Yao-Hung Hubert Tsai and Ruslan Salakhutdinov and
  Geoffrey J. Gordon
Categories: cs.LG stat.ML
\\
  Feed-forward neural networks can be understood as a combination of an
intermediate representation and a linear hypothesis. While most previous works
aim to diversify the representations, we explore the complementary direction by
performing an adaptive and data-dependent regularization motivated by the
empirical Bayes method. Specifically, we propose to construct a matrix-variate
normal prior (on weights) whose covariance matrix has a Kronecker product
structure. This structure is designed to capture the correlations in neurons
through backpropagation. Under the assumption of this Kronecker factorization,
the prior encourages neurons to borrow statistical strength from one another.
Hence, it leads to an adaptive and data-dependent regularization when training
networks on small datasets. To optimize the model, we present an efficient
block coordinate descent algorithm with analytical solutions. Empirically, we
demonstrate that the proposed method helps networks converge to local optima
with smaller stable ranks and spectral norms. These properties suggest better
generalizations and we present empirical results to support this expectation.
We also verify the effectiveness of the approach on multiclass classification
and multitask regression problems with various network structures.
\\ ( https://arxiv.org/abs/1907.06288 ,  1303kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06290
Date: Sun, 14 Jul 2019 22:20:46 GMT   (180kb,D)

Title: Finite-Time Performance Bounds and Adaptive Learning Rate Selection for
  Two Time-Scale Reinforcement Learning
Authors: Harsh Gupta, R. Srikant and Lei Ying
Categories: cs.LG cs.AI stat.ML
Comments: 17 pages, 3 figures, preprint
\\
  We study two time-scale linear stochastic approximation algorithms, which can
be used to model well-known reinforcement learning algorithms such as GTD,
GTD2, and TDC. We present finite-time performance bounds for the case where the
learning rate is fixed. The key idea in obtaining these bounds is to use a
Lyapunov function motivated by singular perturbation theory for linear
differential equations. We use the bound to design an adaptive learning rate
scheme which significantly improves the convergence rate over the known optimal
polynomial decay rule in our experiments, and can be used to potentially
improve the performance of any other schedule where the learning rate is
changed at pre-determined time instants.
\\ ( https://arxiv.org/abs/1907.06290 ,  180kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06291
Date: Sun, 14 Jul 2019 22:20:58 GMT   (15814kb,D)

Title: Measuring the Transferability of Adversarial Examples
Authors: Deyan Petrov, Timothy M. Hospedales
Categories: cs.LG cs.CR cs.CV stat.ML
\\
  Adversarial examples are of wide concern due to their impact on the
reliability of contemporary machine learning systems. Effective adversarial
examples are mostly found via white-box attacks. However, in some cases they
can be transferred across models, thus enabling them to attack black-box
models. In this work we evaluate the transferability of three adversarial
attacks - the Fast Gradient Sign Method, the Basic Iterative Method, and the
Carlini & Wagner method, across two classes of models - the VGG class(using
VGG16, VGG19 and an ensemble of VGG16 and VGG19), and the Inception
class(Inception V3, Xception, Inception Resnet V2, and an ensemble of the
three). We also outline the problems with the assessment of transferability in
the current body of research and attempt to amend them by picking specific
"strong" parameters for the attacks, and by using a L-Infinity clipping
technique and the SSIM metric for the final evaluation of the attack
transferability.
\\ ( https://arxiv.org/abs/1907.06291 ,  15814kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06312
Date: Mon, 15 Jul 2019 02:15:58 GMT   (367kb,D)

Title: Exploring Deep Anomaly Detection Methods Based on Capsule Net
Authors: Xiaoyan Li, Iluju Kiringa, Tet Yeap, Xiaodan Zhu, Yifeng Li
Categories: cs.LG cs.CV stat.ML
Comments: Presented in the "ICML 2019 Workshop on Uncertainty & Robustness in
  Deep Learning", June 14, Long Beach, California, USA
\\
  In this paper, we develop and explore deep anomaly detection techniques based
on the capsule network (CapsNet) for image data. Being able to encoding
intrinsic spatial relationship between parts and a whole, CapsNet has been
applied as both a classifier and deep autoencoder. This inspires us to design a
prediction-probability-based and a reconstruction-error-based normality score
functions for evaluating the "outlierness" of unseen images. Our results on
three datasets demonstrate that the prediction-probability-based method
performs consistently well, while the reconstruction-error-based approach is
relatively sensitive to the similarity between labeled and unlabeled images.
Furthermore, both of the CapsNet-based methods outperform the principled
benchmark methods in many cases.
\\ ( https://arxiv.org/abs/1907.06312 ,  367kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06333
Date: Mon, 15 Jul 2019 05:04:39 GMT   (17kb)

Title: Myers-Briggs Personality Classification and Personality-Specific
  Language Generation Using Pre-trained Language Models
Authors: Sedrick Scott Keh, I-Tsun Cheng
Categories: cs.LG stat.ML
\\
  The Myers-Briggs Type Indicator (MBTI) is a popular personality metric that
uses four dichotomies as indicators of personality traits. This paper examines
the use of pre-trained language models to predict MBTI personality types based
on scraped labeled texts. The proposed model reaches an accuracy of $0.47$ for
correctly predicting all 4 types and $0.86$ for correctly predicting at least 2
types. Furthermore, we investigate the possible uses of a fine-tuned BERT model
for personality-specific language generation. This is a task essential for both
modern psychology and for intelligent empathetic systems.
\\ ( https://arxiv.org/abs/1907.06333 ,  17kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06347
Date: Mon, 15 Jul 2019 06:47:58 GMT   (1875kb,D)

Title: Discriminative Active Learning
Authors: Daniel Gissin, Shai Shalev-Shwartz
Categories: cs.LG stat.ML
Comments: 11 pages, 3 figures
\\
  We propose a new batch mode active learning algorithm designed for neural
networks and large query batch sizes. The method, Discriminative Active
Learning (DAL), poses active learning as a binary classification task,
attempting to choose examples to label in such a way as to make the labeled set
and the unlabeled pool indistinguishable. Experimenting on image classification
tasks, we empirically show our method to be on par with state of the art
methods in medium and large query batch sizes, while being simple to implement
and also extend to other domains besides classification tasks. Our experiments
also show that none of the state of the art methods of today are clearly better
than uncertainty sampling when the batch size is relatively large, negating
some of the reported results in the recent literature.
\\ ( https://arxiv.org/abs/1907.06347 ,  1875kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06356
Date: Mon, 15 Jul 2019 08:05:08 GMT   (3039kb,D)

Title: Motorway Traffic Flow Prediction using Advanced Deep Learning
Authors: Adriana-Simona Mihaita, Haowen Li, Zongyang He, Marian-Andrei Rizoiu
Categories: cs.LG cs.AI stat.ML
\\
  Congestion prediction represents a major priority for traffic management
centres around the world to ensure timely incident response handling. The
increasing amounts of generated traffic data have been used to train machine
learning predictors for traffic, however this is a challenging task due to
inter-dependencies of traffic flow both in time and space. Recently, deep
learning techniques have shown significant prediction improvements over
traditional models, however open questions remain around their applicability,
accuracy and parameter tuning. This paper proposes an advanced deep learning
framework for simultaneously predicting the traffic flow on a large number of
monitoring stations along a highly circulated motorway in Sydney, Australia,
including exit and entry loop count stations, and over varying training and
prediction time horizons. The spatial and temporal features extracted from the
36.34 million data points are used in various deep learning architectures that
exploit their spatial structure (convolutional neuronal networks), their
temporal dynamics (recurrent neuronal networks), or both through a hybrid
spatio-temporal modelling (CNN-LSTM). We show that our deep learning models
consistently outperform traditional methods, and we conduct a comparative
analysis of the optimal time horizon of historical data required to predict
traffic flow at different time points in the future.
\\ ( https://arxiv.org/abs/1907.06356 ,  3039kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06374
Date: Mon, 15 Jul 2019 08:58:26 GMT   (470kb,D)

Title: What does it mean to understand a neural network?
Authors: Timothy P. Lillicrap and Konrad P. Kording
Categories: cs.LG q-bio.NC stat.ML
Comments: 9 pages, 2 figures
\\
  We can define a neural network that can learn to recognize objects in less
than 100 lines of code. However, after training, it is characterized by
millions of weights that contain the knowledge about many object types across
visual scenes. Such networks are thus dramatically easier to understand in
terms of the code that makes them than the resulting properties, such as tuning
or connections. In analogy, we conjecture that rules for development and
learning in brains may be far easier to understand than their resulting
properties. The analogy suggests that neuroscience would benefit from a focus
on learning and development.
\\ ( https://arxiv.org/abs/1907.06374 ,  470kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06377
Date: Mon, 15 Jul 2019 09:05:05 GMT   (2488kb)

Title: Sequential online prediction in the presence of outliers and change
  points: an instant temporal structure learning approach
Authors: Bin Liu, Yu Qi, Ke-Jia Chen
Categories: cs.LG stat.ML
Comments: 13 pages, 15 figures
\\
  In this paper, we consider sequential online prediction (SOP) for streaming
data in the presence of outliers and change points. We propose an INstant
TEmporal structure Learning (INTEL) algorithm to address this problem.Our INTEL
algorithm is developed based on a full consideration to the duality between
online prediction and anomaly detection. We first employ a mixture of weighted
GP models (WGPs) to cover the expected possible temporal structures of the
data. Then, on the basis of the rich modeling capacity of this WGP mixture, we
develop an efficient technique to instantly learn (capture) the temporal
structure of the data that follows a regime shift. This instant learning is
achieved only by adjusting one hyper-parameter value of the mixture model. A
weighted generalization of the product of experts (POE) model is used for
fusing predictions yielded from multiple GP models. An outlier is declared once
a real observation seriously deviates from the fused prediction. If a certain
number of outliers are consecutively declared, then a change point is declared.
Extensive experiments are performed using a diverse of real datasets. Results
show that the proposed algorithm is significantly better than benchmark methods
for SOP in the presence of outliers and change points.
\\ ( https://arxiv.org/abs/1907.06377 ,  2488kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06382
Date: Mon, 15 Jul 2019 09:19:56 GMT   (441kb)

Title: Dynamical Systems as Temporal Feature Spaces
Authors: Peter Tino
Categories: cs.LG stat.ML
Comments: 45 pages, 17 figures
\\
  Parameterized state space models in the form of recurrent networks are often
used in machine learning to learn from data streams exhibiting temporal
dependencies. To break the black box nature of such models it is important to
understand the dynamical features of the input driving time series that are
formed in the state space. We propose a framework for rigorous analysis of such
state representations in vanishing memory state space models such as echo state
networks (ESN). In particular, we consider the state space a temporal feature
space and the readout mapping from the state space a kernel machine operating
in that feature space. We show that: (1) The usual ESN strategy of randomly
generating input-to-state, as well as state coupling leads to shallow memory
time series representations, corresponding to cross-correlation operator with
fast exponentially decaying coefficients; (2) Imposing symmetry on dynamic
coupling yields a constrained dynamic kernel matching the input time series
with straightforward exponentially decaying motifs or exponentially decaying
motifs of the highest frequency; (3) Simple cycle high-dimensional reservoir
topology specified only through two free parameters can implement deep memory
dynamic kernels with a rich variety of matching motifs. We quantify richness of
feature representations imposed by dynamic kernels and demonstrate that for
dynamic kernel associated with cycle reservoir topology, the kernel richness
undergoes a phase transition close to the edge of stability.
\\ ( https://arxiv.org/abs/1907.06382 ,  441kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06396
Date: Mon, 15 Jul 2019 09:45:54 GMT   (768kb,D)

Title: A Dual Memory Structure for Efficient Use of Replay Memory in Deep
  Reinforcement Learning
Authors: Wonshick Ko, Dong Eui Chang
Categories: cs.LG stat.ML
Comments: 4 pages, 5 figures
\\
  In this paper, we propose a dual memory structure for reinforcement learning
algorithms with replay memory. The dual memory consists of a main memory that
stores various data and a cache memory that manages the data and trains the
reinforcement learning agent efficiently. Experimental results show that the
dual memory structure achieves higher training and test scores than the
conventional single memory structure in three selected environments of OpenAI
Gym. This implies that the dual memory structure enables better and more
efficient training than the single memory structure.
\\ ( https://arxiv.org/abs/1907.06396 ,  768kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06414
Date: Mon, 15 Jul 2019 10:21:54 GMT   (1518kb,D)

Title: Concept-Centric Visual Turing Tests for Method Validation
Authors: Tatiana Fountoukidou and Raphael Sznitman
Categories: cs.LG eess.IV stat.ML
Comments: 9 pages, 8 figures
\\
  Recent advances in machine learning for medical imaging have led to
impressive increases in model complexity and overall capabilities. However, the
ability to discern the precise information a machine learning method is using
to make decisions has lagged behind and it is often unclear how these
performances are in fact achieved. Conventional evaluation metrics that reduce
method performance to a single number or a curve only provide limited insights.
Yet, systems used in clinical practice demand thorough validation that such
crude characterizations miss. To this end, we present a framework to evaluate
classification methods based on a number of interpretable concepts that are
crucial for a clinical task. Our approach is inspired by the Turing Test
concept and how to devise a test that adaptively questions a method for its
ability to interpret medical images. To do this, we make use of a Twenty
Questions paradigm whereby we use a probabilistic model to characterize the
method's capacity to grasp task-specific concepts, and we introduce a strategy
to sequentially query the method according to its previous answers. The results
show that the probabilistic model is able to expose both the dataset's and the
method's biases, and can be used to reduced the number of queries needed for
confident performance evaluation.
\\ ( https://arxiv.org/abs/1907.06414 ,  1518kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06426
Date: Mon, 15 Jul 2019 10:54:18 GMT   (3817kb,D)

Title: Multi-hop Federated Private Data Augmentation with Sample Compression
Authors: Eunjeong Jeong, Seungeun Oh, Jihong Park, Hyesung Kim, Mehdi Bennis,
  Seong-Lyun Kim
Categories: cs.LG cs.AI cs.NI stat.ML
Comments: to be presented at the 28th International Joint Conference on
  Artificial Intelligence (IJCAI-19), 1st International Workshop on Federated
  Machine Learning for User Privacy and Data Confidentiality (FML'19), Macao,
  China
\\
  On-device machine learning (ML) has brought about the accessibility to a
tremendous amount of data from the users while keeping their local data private
instead of storing it in a central entity. However, for privacy guarantee, it
is inevitable at each device to compensate for the quality of data or learning
performance, especially when it has a non-IID training dataset. In this paper,
we propose a data augmentation framework using a generative model: multi-hop
federated augmentation with sample compression (MultFAug). A multi-hop protocol
speeds up the end-to-end over-the-air transmission of seed samples by enhancing
the transport capacity. The relaying devices guarantee stronger privacy
preservation as well since the origin of each seed sample is hidden in those
participants. For further privatization on the individual sample level, the
devices compress their data samples. The devices sparsify their data samples
prior to transmissions to reduce the sample size, which impacts the
communication payload. This preprocessing also strengthens the privacy of each
sample, which corresponds to the input perturbation for preserving sample
privacy. The numerical evaluations show that the proposed framework
significantly improves privacy guarantee, transmission delay, and local
training performance with adjustment to the number of hops and compression
rate.
\\ ( https://arxiv.org/abs/1907.06426 ,  3817kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06479
Date: Mon, 15 Jul 2019 12:56:38 GMT   (2435kb,D)

Title: Proximal Policy Optimization with Mixed Distributed Training
Authors: Zhenyu Zhang, Xiangfeng Luo, Shaorong Xie, Jianshu Wang, Wei Wang,
  Yang Li
Categories: cs.LG cs.AI
\\
  Instability and slowness are two main problems in deep reinforcement
learning. Even if proximal policy optimization is the state of the art, it
still suffers from these two problems. We introduce an improved algorithm based
on proximal policy optimization (PPO), mixed distributed proximal policy
optimization (MDPPO), and show that it can accelerate and stabilize the
training process. In our algorithm, multiple different policies train
simultaneously and each of them controls several identical agents that interact
with environments. Actions are sampled by each policy separately as usual but
the trajectories for training process are collected from all agents, instead of
only one policy. We find that if we choose some auxiliary trajectories
elaborately to train policies, the algorithm will be more stable and quicker to
converge especially in the environments with sparse rewards.
\\ ( https://arxiv.org/abs/1907.06479 ,  2435kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06496
Date: Mon, 15 Jul 2019 13:28:27 GMT   (5978kb,D)

Title: Robust Nonlinear Component Estimation with Tikhonov Regularization
Authors: Reuben Feinman, Nikhil Parthasarathy
Categories: cs.LG stat.ML
Comments: submitted to NeurIPS 2019
\\
  Learning reduced component representations of data using nonlinear
transformations is a central problem in unsupervised learning with a rich
history. Recently, a new family of algorithms based on maximum likelihood
optimization with change of variables has demonstrated an impressive ability to
model complex nonlinear data distributions. These algorithms learn to map from
arbitrary random variables to independent components using invertible nonlinear
function approximators. Despite the potential of this framework, the underlying
optimization objective is ill-posed for a large class of variables, inhibiting
accurate component estimates in many use cases. We present a new Tikhonov
regularization technique for nonlinear independent component estimation that
mediates the instability of the algorithm and facilitates robust component
estimates. In addition, we provide a theoretically grounded procedure for
feature extraction that produces PCA-like representations of nonlinear
distributions using the learned model. We apply our technique to a handful of
nonlinear data manifolds and show that the resulting representations possess
important consistencies lacked by unregularized models.
\\ ( https://arxiv.org/abs/1907.06496 ,  5978kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06536
Date: Mon, 15 Jul 2019 15:03:14 GMT   (316kb,D)

Title: Federated Reinforcement Distillation with Proxy Experience Memory
Authors: Han Cha, Jihong Park, Hyesung Kim, Seong-Lyun Kim, Mehdi Bennis
Categories: cs.LG cs.MA stat.ML
Comments: To be presented at the 28th International Joint Conference on
  Artificial Intelligence (IJCAI-19), 1st International Workshop on Federated
  Machine Learning for User Privacy and Data Confidentiality (FML'19), Macao,
  China
\\
  In distributed reinforcement learning, it is common to exchange the
experience memory of each agent and thereby collectively train their local
models. The experience memory, however, contains all the preceding state
observations and their corresponding policies of the host agent, which may
violate the privacy of the agent. To avoid this problem, in this work, we
propose a privacy-preserving distributed reinforcement learning (RL) framework,
termed federated reinforcement distillation (FRD). The key idea is to exchange
a proxy experience memory comprising a pre-arranged set of states and
time-averaged policies, thereby preserving the privacy of actual experiences.
Based on an advantage actor-critic RL architecture, we numerically evaluate the
effectiveness of FRD and investigate how the performance of FRD is affected by
the proxy memory structure and different memory exchanging rules.
\\ ( https://arxiv.org/abs/1907.06536 ,  316kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06572
Date: Fri, 12 Jul 2019 12:55:59 GMT   (432kb,D)

Title: Deep network as memory space: complexity, generalization, disentangled
  representation and interpretability
Authors: X. Dong and L. Zhou
Categories: cs.LG cs.AI
Comments: 11 pages, 2 figures
\\
  By bridging deep networks and physics, the programme of geometrization of
deep networks was proposed as a framework for the interpretability of deep
learning systems. Following this programme we can apply two key ideas of
physics, the geometrization of physics and the least action principle, on deep
networks and deliver a new picture of deep networks: deep networks as memory
space of information, where the capacity, robustness and efficiency of the
memory are closely related with the complexity, generalization and
disentanglement of deep networks. The key components of this understanding
include:(1) a Fisher metric based formulation of the network complexity; (2)the
least action (complexity=action) principle on deep networks and (3)the geometry
built on deep network configurations. We will show how this picture will bring
us a new understanding of the interpretability of deep learning systems.
\\ ( https://arxiv.org/abs/1907.06572 ,  432kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06582
Date: Fri, 12 Jul 2019 05:51:33 GMT   (298kb,D)

Title: AMAD: Adversarial Multiscale Anomaly Detection on High-Dimensional and
  Time-Evolving Categorical Data
Authors: Zheng Gao, Lin Guo, Chi Ma, Xiao Ma, Kai Sun, Hang Xiang, Xiaoqiang
  Zhu, Hongsong Li, Xiaozhong Liu
Categories: cs.LG stat.ML
Comments: Accepted by 2019 KDD Workshop on Deep Learning Practice for
  High-Dimensional Sparse Data
\\
  Anomaly detection is facing with emerging challenges in many important
industry domains, such as cyber security and online recommendation and
advertising. The recent trend in these areas calls for anomaly detection on
time-evolving data with high-dimensional categorical features without labeled
samples. Also, there is an increasing demand for identifying and monitoring
irregular patterns at multiple resolutions. In this work, we propose a unified
end-to-end approach to solve these challenges by combining the advantages of
Adversarial Autoencoder and Recurrent Neural Network. The model learns data
representations cross different scales with attention mechanisms, on which an
enhanced two-resolution anomaly detector is developed for both instances and
data blocks. Extensive experiments are performed over three types of datasets
to demonstrate the efficacy of our method and its superiority over the
state-of-art approaches.
\\ ( https://arxiv.org/abs/1907.06582 ,  298kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06584
Date: Fri, 12 Jul 2019 10:13:05 GMT   (3417kb,D)

Title: Environment Reconstruction with Hidden Confounders for Reinforcement
  Learning based Recommendation
Authors: Wenjie Shang, Yang Yu, Qingyang Li, Zhiwei Qin, Yiping Meng, Jieping
  Ye
Categories: cs.LG cs.AI stat.ML
Comments: Appears in KDD 2019
\\
  Reinforcement learning aims at searching the best policy model for decision
making, and has been shown powerful for sequential recommendations. The
training of the policy by reinforcement learning, however, is placed in an
environment. In many real-world applications, however, the policy training in
the real environment can cause an unbearable cost, due to the exploration in
the environment. Environment reconstruction from the past data is thus an
appealing way to release the power of reinforcement learning in these
applications. The reconstruction of the environment is, basically, to extract
the casual effect model from the data. However, real-world applications are
often too complex to offer fully observable environment information. Therefore,
quite possibly there are unobserved confounding variables lying behind the
data. The hidden confounder can obstruct an effective reconstruction of the
environment. In this paper, by treating the hidden confounder as a hidden
policy, we propose a deconfounded multi-agent environment reconstruction
(DEMER) approach in order to learn the environment together with the hidden
confounder. DEMER adopts a multi-agent generative adversarial imitation
learning framework. It proposes to introduce the confounder embedded policy,
and use the compatible discriminator for training the policies. We then apply
DEMER in an application of driver program recommendation. We firstly use an
artificial driver program recommendation environment, abstracted from the real
application, to verify and analyze the effectiveness of DEMER. We then test
DEMER in the real application of Didi Chuxing. Experiment results show that
DEMER can effectively reconstruct the hidden confounder, and thus can build the
environment better. DEMER also derives a recommendation policy with a
significantly improved performance in the test phase of the real application.
\\ ( https://arxiv.org/abs/1907.06584 ,  3417kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06592
Date: Fri, 12 Jul 2019 08:01:47 GMT   (5780kb,D)

Title: Sparsely Activated Networks
Authors: Paschalis Bizopoulos, and Dimitrios Koutsouris
Categories: cs.LG cs.CV stat.ML
Comments: 10 pages, 5 figures, 4 algorithms, 3 tables
\\
  Previous literature on unsupervised learning focused on designing structural
priors and optimization functions with the aim of learning meaningful features,
but without considering the description length of the representations. Here we
present Sparsely Activated Networks (SANs), which decompose their input as a
sum of sparsely reoccurring patterns of varying amplitude, and combined with a
newly proposed metric $\varphi$ they learn representations with minimal
description lengths. SANs consist of kernels with shared weights that during
encoding are convolved with the input and then passed through a ReLU and a
sparse activation function. During decoding, the same weights are convolved
with the sparse activation map and the individual reconstructions from each
weight are summed to reconstruct the input. We also propose a metric $\varphi$
for model selection that favors models which combine high compression ratio and
low reconstruction error and we justify its definition by exploring the
hyperparameter space of SANs. We compare four sparse activation functions
(Identity, Max-Activations, Max-Pool indices, Peaks) on a variety of datasets
and show that SANs learn interpretable kernels that combined with $\varphi$,
they minimize the description length of the representations.
\\ ( https://arxiv.org/abs/1907.06592 ,  5780kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06594
Date: Thu, 4 Jul 2019 08:50:04 GMT   (1327kb,D)

Title: Learning One-hidden-layer neural networks via Provable Gradient Descent
  with Random Initialization
Authors: Shuhao Xia and Yuanming Shi
Categories: cs.LG cs.IT math.IT stat.ML
Comments: arXiv admin note: substantial text overlap with arXiv:1803.07726 by
  other authors
\\
  Although deep learning has shown its powerful performance in many
applications, the mathematical principles behind neural networks are still
mysterious. In this paper, we consider the problem of learning a
one-hidden-layer neural network with quadratic activations. We focus on the
under-parameterized regime where the number of hidden units is smaller than the
dimension of the inputs. We shall propose to solve the problem via a provable
gradient-based method with random initialization. For the non-convex neural
networks training problem we reveal that the gradient descent iterates are able
to enter a local region that enjoys strong convexity and smoothness within a
few iterations, and then provably converges to a globally optimal model at a
linear rate with near-optimal sample complexity. We further corroborate our
theoretical findings via various experiments.
\\ ( https://arxiv.org/abs/1907.06594 ,  1327kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06600
Date: Mon, 15 Jul 2019 16:53:43 GMT   (35kb)

Title: Medical Concept Representation Learning from Claims Data and Application
  to Health Plan Payment Risk Adjustment
Authors: Qiu-Yue Zhong, Andrew H. Fairless, Jasmine M. McCammon, Farbod
  Rahmanian
Categories: cs.LG stat.ML
Comments: Accepted as a poster presentation at the 2019 KDD Workshop on Applied
  Data Science for Healthcare (KDD-DSHealth2019), Aug 5, 2019, Anchorage,
  Alaska USA
\\
  Risk adjustment has become an increasingly important tool in healthcare. It
has been extensively applied to payment adjustment for health plans to reflect
the expected cost of providing coverage for members. Risk adjustment models are
typically estimated using linear regression, which does not fully exploit the
information in claims data. Moreover, the development of such linear regression
models requires substantial domain expert knowledge and computational effort
for data preprocessing. In this paper, we propose a novel approach for risk
adjustment that uses semantic embeddings to represent patient medical
histories. Embeddings efficiently represent medical concepts learned from
diagnostic, procedure, and prescription codes in patients' medical histories.
This approach substantially reduces the need for feature engineering. Our
results show that models using embeddings had better performance than a
commercial risk adjustment model on the task of prospective risk score
prediction.
\\ ( https://arxiv.org/abs/1907.06600 ,  35kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06607
Date: Mon, 15 Jul 2019 17:11:05 GMT   (1225kb,AD)

Title: Agglomerative Attention
Authors: Matthew Spellings
Categories: cs.LG stat.ML
Comments: 7 pages, 3 figures
\\
  Neural networks using transformer-based architectures have recently
demonstrated great power and flexibility in modeling sequences of many types.
One of the core components of transformer networks is the attention layer,
which allows contextual information to be exchanged among sequence elements.
While many of the prevalent network structures thus far have utilized full
attention -- which operates on all pairs of sequence elements -- the quadratic
scaling of this attention mechanism significantly constrains the size of models
that can be trained. In this work, we present an attention model that has only
linear requirements in memory and computation time. We show that, despite the
simpler attention model, networks using this attention mechanism can attain
comparable performance to full attention networks on language modeling tasks.
\\ ( https://arxiv.org/abs/1907.06607 ,  1225kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06614
Date: Mon, 15 Jul 2019 17:21:13 GMT   (114kb,D)

Title: Revealing posturographic features associated with the risk of falling in
  patients with Parkinsonian syndromes via machine learning
Authors: Ioannis Bargiotas, Argyris Kalogeratos, Myrto Limnios, Pierre-Paul
  Vidal, Damien Ricard, Nicolas Vayatis
Categories: cs.LG stat.AP stat.ML
Comments: 16 pages, 11 figures (plots, tables, algorithms)
MSC-class: 62H15
\\
  Falling in Parkinsonian syndromes (PS) is associated with postural
instability and consists a common cause of disability among PS patients.
Current posturographic practices record the body's center-of-pressure
displacement (statokinesigram) while the patient stands on a force platform.
Statokinesigrams, after appropriate signal processing, can offer numerous
posturographic features, which however challenges the efforts for valid
statistics via standard univariate approaches. In this work, we present the
ts-AUC, a non-parametric multivariate two-sample test, which we employ to
analyze statokinesigram differences among PS patients that are fallers (PSf)
and non-fallers (PSNF). We included 123 PS patients who were classified into
PSF or PSNF based on clinical assessment and underwent simple Romberg Test
(eyes open/eyes closed). We analyzed posturographic features using both
multiple testing with p-value adjustment and the ts-AUC. While the ts-AUC
showed significant difference between groups (p-value = 0.01), multiple testing
did not show any such difference. Interestingly, significant difference between
the two groups was found only using the open-eyes protocol. PSF showed
significantly increased antero-posterior movements as well as increased
posturographic area, compared to PSNF. Our study demonstrates the superiority
of the ts-AUC test compared to standard statistical tools in distinguishing PSF
and PSNF in the multidimensional feature space. This result highlights more
generally the fact that machine learning-based statistical tests can be seen as
a natural extension of classical statistical approaches and should be
considered, especially when dealing with multifactorial assessments.
\\ ( https://arxiv.org/abs/1907.06614 ,  114kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06627
Date: Mon, 15 Jul 2019 17:58:04 GMT   (5417kb,D)

Title: Batch-Shaped Channel Gated Networks
Authors: Babak Ehteshami Bejnordi, Tijmen Blankevoort and Max Welling
Categories: cs.LG cs.CV stat.ML
\\
  We present a method for gating deep-learning architectures on a fine-grained
level. Individual convolutional maps are turned on/off conditionally on
features in the network. This method allows us to train neural networks with a
large capacity, but lower inference time than the full network. To achieve
this, we introduce a new residual block architecture that gates convolutional
channels in a fine-grained manner. We also introduce a generally applicable
tool "batch-shaping" that matches the marginal aggregate posteriors of features
in a neural network to a pre-specified prior distribution. We use this novel
technique to force gates to be more conditional on the data. We present results
on CIFAR-10 and ImageNet datasets for image classification and Cityscapes for
semantic segmentation. Our results show that our method can slim down large
architectures conditionally, such that the average computational cost on the
data is on par with a smaller architecture, but with higher accuracy. In
particular, our ResNet34 gated network achieves a performance of 72.55% top-1
accuracy compared to the 69.76% accuracy of the baseline ResNet18 model, for
similar complexity. We also show that the resulting networks automatically
learn to use more features for difficult examples and fewer features for simple
examples.
\\ ( https://arxiv.org/abs/1907.06627 ,  5417kb)
%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-%-
------------------------------------------------------------------------------
\\
arXiv:1907.06017 (*cross-listing*)
Date: Sat, 13 Jul 2019 06:27:24 GMT   (619kb,D)

Title: Learn Spelling from Teachers: Transferring Knowledge from Language
  Models to Sequence-to-Sequence Speech Recognition
Authors: Ye Bai, Jiangyan Yi, Jianhua Tao, Zhengkun Tian and Zhengqi Wen
Categories: eess.AS cs.CL
Comments: 5 pages, 3 figures, accepted by INTERSPEECH 2019
\\
  Integrating an external language model into a sequence-to-sequence speech
recognition system is non-trivial. Previous works utilize linear interpolation
or a fusion network to integrate external language models. However, these
approaches introduce external components, and increase decoding computation. In
this paper, we instead propose a knowledge distillation based training approach
to integrating external language models into a sequence-to-sequence model. A
recurrent neural network language model, which is trained on large scale
external text, generates soft labels to guide the sequence-to-sequence model
training. Thus, the language model plays the role of the teacher. This approach
does not add any external component to the sequence-to-sequence model during
testing. And this approach is flexible to be combined with shallow fusion
technique together for decoding. The experiments are conducted on public
Chinese datasets AISHELL-1 and CLMAD. Our approach achieves a character error
rate of 9.3%, which is relatively reduced by 18.42% compared with the vanilla
sequence-to-sequence model.
\\ ( https://arxiv.org/abs/1907.06017 ,  619kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06111 (*cross-listing*)
Date: Sat, 13 Jul 2019 17:52:17 GMT   (851kb,D)

Title: Speaker Recognition with Random Digit Strings Using Uncertainty
  Normalized HMM-based i-vectors
Authors: Nooshin Maghsoodi, Hossein Sameti, Hossein Zeinali, Themos~Stafylakis
Categories: eess.AS cs.CL cs.SD
\\
  In this paper, we combine Hidden Markov Models (HMMs) with i-vector
extractors to address the problem of text-dependent speaker recognition with
random digit strings. We employ digit-specific HMMs to segment the utterances
into digits, to perform frame alignment to HMM states and to extract Baum-Welch
statistics. By making use of the natural partition of input features into
digits, we train digit-specific i-vector extractors on top of each HMM and we
extract well-localized i-vectors, each modelling merely the phonetic content
corresponding to a single digit. We then examine ways to perform channel and
uncertainty compensation, and we propose a novel method for using the
uncertainty in the i-vector estimates. The experiments on RSR2015 part III show
that the proposed method attains 1.52\% and 1.77\% Equal Error Rate (EER) for
male and female respectively, outperforming state-of-the-art methods such as
x-vectors, trained on vast amounts of data. Furthermore, these results are
attained by a single system trained entirely on RSR2015, and by a simple
score-normalized cosine distance. Moreover, we show that the omission of
channel compensation yields only a minor degradation in performance, meaning
that the system attains state-of-the-art results even without recordings from
multiple handsets per speaker for training or enrolment. Similar conclusions
are drawn from our experiments on the RedDots corpus, where the same method is
evaluated on phrases. Finally, we report results with bottleneck features and
show that further improvement is attained when fusing them with spectral
features.
\\ ( https://arxiv.org/abs/1907.06111 ,  851kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06112 (*cross-listing*)
Date: Sat, 13 Jul 2019 17:57:55 GMT   (18kb)

Title: BUT VOiCES 2019 System Description
Authors: Hossein Zeinali, Pavel Mat\v{e}jka, Ladislav Mo\v{s}ner, Old\v{r}ich
  Plchot, Anna Silnova, Ond\v{r}ej Novotn\'y, J\'an Profant, Ond\v{r}ej
  Glembek, Luk\'a\v{s} Burget
Categories: eess.AS cs.CL cs.SD
\\
  This is a description of our effort in VOiCES 2019 Speaker Recognition
challenge. All systems in the fixed condition are based on the x-vector
paradigm with different features and DNN topologies. The single best system
reaches 1.2% EER and a fusion of 3 systems yields 1.0% EER, which is 15%
relative improvement. The open condition allowed us to use external data which
we did for the PLDA adaptation and achieved less than ~10% relative
improvement. In the submission to open condition, we used 3 x-vector systems
and also one i-vector based system.
\\ ( https://arxiv.org/abs/1907.06112 ,  18kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06205 (*cross-listing*)
Date: Sun, 14 Jul 2019 11:14:14 GMT   (98kb,D)

Title: Automatic Repair and Type Binding of Undeclared Variables using Neural
  Networks
Authors: Venkatesh Theru Mohan and Ali Jannesari
Categories: cs.SE cs.CL cs.FL cs.LG cs.PL stat.ML
Comments: 16 pages, 16 figures
\\
  Deep learning had been used in program analysis for the prediction of hidden
software defects using software defect datasets, security vulnerabilities using
generative adversarial networks as well as identifying syntax errors by
learning a trained neural machine translation on program codes. However, all
these approaches either require defect datasets or bug-free source codes that
are executable for training the deep learning model. Our neural network model
is neither trained with any defect datasets nor bug-free programming source
codes, instead it is trained using structural semantic details of Abstract
Syntax Tree (AST) where each node represents a construct appearing in the
source code. This model is implemented to fix one of the most common semantic
errors, such as undeclared variable errors as well as infer their type
information before program compilation. By this approach, the model has
achieved in correctly locating and identifying 81% of the programs on prutor
dataset of 1059 programs with only undeclared variable errors and also
inferring their types correctly in 80% of the programs.
\\ ( https://arxiv.org/abs/1907.06205 ,  98kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06330 (*cross-listing*)
Date: Mon, 15 Jul 2019 04:48:34 GMT   (1284kb,D)

Title: Ranking sentences from product description & bullets for better search
Authors: Prateek Verma, Aliasgar Kutiyanawala, Ke Shen
Categories: cs.IR cs.CL cs.LG
Comments: Accepted at SIGIR eCom'19
\\
  Products in an ecommerce catalog contain information-rich fields like
description and bullets that can be useful to extract entities (attributes)
using NER based systems. However, these fields are often verbose and contain
lot of information that is not relevant from a search perspective. Treating
each sentence within these fields equally can lead to poor full text match and
introduce problems in extracting attributes to develop ontologies, semantic
search etc. To address this issue, we describe two methods based on extractive
summarization with reinforcement learning by leveraging information in product
titles and search click through logs to rank sentences from bullets,
description, etc. Finally, we compare the accuracy of these two models.
\\ ( https://arxiv.org/abs/1907.06330 ,  1284kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05982 (*cross-listing*)
Date: Sat, 13 Jul 2019 00:23:26 GMT   (1879kb,D)

Title: Learning Complex Basis Functions for Invariant Representations of Audio
Authors: Stefan Lattner, Monika D\"orfler, Andreas Arzt
Categories: cs.SD cs.CV cs.LG eess.AS
Comments: Paper accepted at the 20th International Society for Music
  Information Retrieval Conference, ISMIR 2019, Delft, The Netherlands,
  November 4-8; 8 pages, 4 figures, 4 tables
\\
  Learning features from data has shown to be more successful than using
hand-crafted features for many machine learning tasks. In music information
retrieval (MIR), features learned from windowed spectrograms are highly variant
to transformations like transposition or time-shift. Such variances are
undesirable when they are irrelevant for the respective MIR task. We propose an
architecture called Complex Autoencoder (CAE) which learns features invariant
to orthogonal transformations. Mapping signals onto complex basis functions
learned by the CAE results in a transformation-invariant "magnitude space" and
a transformation-variant "phase space". The phase space is useful to infer
transformations between data pairs. When exploiting the invariance-property of
the magnitude space, we achieve state-of-the-art results in audio-to-score
alignment and repeated section discovery for audio. A PyTorch implementation of
the CAE, including the repeated section discovery method, is available online.
\\ ( https://arxiv.org/abs/1907.05982 ,  1879kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06053 (*cross-listing*)
Date: Sat, 13 Jul 2019 11:37:32 GMT   (5662kb,D)

Title: Learning better generative models for dexterous, single-view grasping of
  novel objects
Authors: Marek Kopicki, Dominik Belter and Jeremy L. Wyatt
Categories: cs.RO cs.CV cs.LG
Comments: 19 pages, 15 figures, 7 tables
ACM-class: I.2.9; I.2.10; I.2.6
\\
  This paper concerns the problem of how to learn to grasp dexterously, so as
to be able to then grasp novel objects seen only from a single view-point.
Recently, progress has been made in data-efficient learning of generative grasp
models which transfer well to novel objects. These generative grasp models are
learned from demonstration (LfD). One weakness is that, as this paper shall
show, grasp transfer under challenging single view conditions is unreliable.
Second, the number of generative model elements rises linearly in the number of
training examples. This, in turn, limits the potential of these generative
models for generalisation and continual improvement. In this paper, it is shown
how to address these problems. Several technical contributions are made: (i) a
view-based model of a grasp; (ii) a method for combining and compressing
multiple grasp models; (iii) a new way of evaluating contacts that is used both
to generate and to score grasps. These, together, improve both grasp
performance and reduce the number of models learned for grasp transfer. These
advances, in turn, also allow the introduction of autonomous training, in which
the robot learns from self-generated grasps. Evaluation on a challenging test
set shows that, with innovations (i)-(iii) deployed, grasp transfer success
rises from 55.1% to 81.6%. By adding autonomous training this rises to 87.8%.
These differences are statistically significant. In total, across all
experiments, 539 test grasps were executed on real objects.
\\ ( https://arxiv.org/abs/1907.06053 ,  5662kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06064 (*cross-listing*)
Date: Sat, 13 Jul 2019 12:17:00 GMT   (3054kb,D)

Title: Image Evolution Trajectory Prediction and Classification from Baseline
  using Learning-based Patch Atlas Selection for Early Diagnosis
Authors: Can Gafuroglu and Islem Rekik
Categories: cs.LG cs.CV stat.ML
\\
  Patients initially diagnosed with early mild cognitive impairment (eMCI) are
known to be a clinically heterogeneous group with very subtle patterns of brain
atrophy. To examine the boarders between normal controls (NC) and eMCI,
Magnetic Resonance Imaging (MRI) was extensively used as a non-invasive imaging
modality to pin-down subtle changes in brain images of MCI patients. However,
eMCI research remains limited by the number of available MRI acquisition
timepoints. Ideally, one would learn how to diagnose MCI patients in an early
stage from MRI data acquired at a single timepoint, while leveraging
'non-existing' follow-up observations. To this aim, we propose novel supervised
and unsupervised frameworks that learn how to jointly predict and label the
evolution trajectory of intensity patches, each seeded at a specific brain
landmark, from a baseline intensity patch. Specifically, both strategies aim to
identify the best training atlas patches at baseline timepoint to predict and
classify the evolution trajectory of a given testing baseline patch. The
supervised technique learns how to select the best atlas patches by training
bidirectional mappings from the space of pairwise patch similarities to their
corresponding prediction errors -when one patch was used to predict the other.
On the other hand, the unsupervised technique learns a manifold of baseline
atlas and testing patches using multiple kernels to well capture patch
distributions at multiple scales. Once the best baseline atlas patches are
selected, we retrieve their evolution trajectories and average them to predict
the evolution trajectory of the testing baseline patch. Next, we input the
predicted trajectories to an ensemble of linear classifiers, each trained at a
specific landmark. Our classification accuracy increased by up to 10% points in
comparison to single timepoint-based classification methods.
\\ ( https://arxiv.org/abs/1907.06064 ,  3054kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06071 (*cross-listing*)
Date: Sat, 13 Jul 2019 13:07:31 GMT   (4403kb,D)

Title: S&CNet: A Enhanced Coarse-to-fine Framework For Monocular Depth
  Completion
Authors: Lei Zhang, Weihai Chen, Chao Hu
Categories: eess.IV cs.CV
Comments: 12 pages,9 figures
\\
  Real-time depth completing is a critical problem for robotics and autonomous
driving tasks. In this paper, we propose a light-weight coarse-to-fine network
to complete a dense depth map from a single view RGB image and its related
sparse depth map. Both the coarse estimation network and refinement network are
in encoder-decoder form. To boost the performance of the coarse estimation
network, we propose a novel spatial-and-channel (S&C) enhancer to boost the
representation power of encoder network. The motivation for spatial-wise
attention is from our finding that a lower output stride of encoder network
preserve more detail but limit the receptive field. Thus, we employee
spatial-wise attention to capture long-range contextual information. Besides,
we found each channel in the features generated by the encoder network response
to different distance. This discovery drives us to adopt channel-wise attention
mechanism to reassign the weights of different channels as the decoder network
should pay more attention to the channels response to distance contain rich
objects, intuitively. To further improve the performance of our network, we
adopt a refinement network which take the coarse estimation and sparse depth
map as input. We evaluate our approach on KITTI benchmark, and the results show
that our approach achieves competitive performance on RMSE metric with the
state-of-the-art over published works but outperform it in all other metrics
(iRMSE,MAE and iMAE) significantly with almost 3:5 times higher running speed.
Crucially, our proposed S&C enhancer can be plugged into other existing
networks and boost their performance significantly with a minimal additional
computational cost.
\\ ( https://arxiv.org/abs/1907.06071 ,  4403kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06286 (*cross-listing*)
Date: Sun, 14 Jul 2019 21:58:10 GMT   (1358kb)

Title: Autoencoding sensory substitution
Authors: Viktor T\'oth, Lauri Parkkonen
Categories: q-bio.NC cs.CV cs.LG cs.SD eess.AS
DOI: 10.13140/RG.2.2.10576.87048
\\
  Tens of millions of people live blind, and their number is ever increasing.
Visual-to-auditory sensory substitution (SS) encompasses a family of cheap,
generic solutions to assist the visually impaired by conveying visual
information through sound. The required SS training is lengthy: months of
effort is necessary to reach a practical level of adaptation. There are two
reasons for the tedious training process: the elongated substituting audio
signal, and the disregard for the compressive characteristics of the human
hearing system. To overcome these obstacles, we developed a novel class of SS
methods, by training deep recurrent autoencoders for image-to-sound conversion.
We successfully trained deep learning models on different datasets to execute
visual-to-auditory stimulus conversion. By constraining the visual space, we
demonstrated the viability of shortened substituting audio signals, while
proposing mechanisms, such as the integration of computational hearing models,
to optimally convey visual features in the substituting stimulus as
perceptually discernible auditory components. We tested our approach in two
separate cases. In the first experiment, the author went blindfolded for 5
days, while performing SS training on hand posture discrimination. The second
experiment assessed the accuracy of reaching movements towards objects on a
table. In both test cases, above-chance-level accuracy was attained after a few
hours of training. Our novel SS architecture broadens the horizon of
rehabilitation methods engineered for the visually impaired. Further
improvements on the proposed model shall yield hastened rehabilitation of the
blind and a wider adaptation of SS devices as a consequence.
\\ ( https://arxiv.org/abs/1907.06286 ,  1358kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06543 (*cross-listing*)
Date: Mon, 15 Jul 2019 15:11:09 GMT   (4456kb,D)

Title: Deep Sequential Mosaicking of Fetoscopic Videos
Authors: Sophia Bano, Francisco Vasconcelos, Marcel Tella Amo, George Dwyer,
  Caspar Gruijthuijsen, Jan Deprest, Sebastien Ourselin, Emmanuel Vander
  Poorten, Tom Vercauteren, Danail Stoyanov
Categories: eess.IV cs.CV cs.LG stat.ML
Comments: Accepted at MICCAI 2019
\\
  Twin-to-twin transfusion syndrome treatment requires fetoscopic laser
photocoagulation of placental vascular anastomoses to regulate blood flow to
both fetuses. Limited field-of-view (FoV) and low visual quality during
fetoscopy make it challenging to identify all vascular connections. Mosaicking
can align multiple overlapping images to generate an image with increased FoV,
however, existing techniques apply poorly to fetoscopy due to the low visual
quality, texture paucity, and hence fail in longer sequences due to the drift
accumulated over time. Deep learning techniques can facilitate in overcoming
these challenges. Therefore, we present a new generalized Deep Sequential
Mosaicking (DSM) framework for fetoscopic videos captured from different
settings such as simulation, phantom, and real environments. DSM extends an
existing deep image-based homography model to sequential data by proposing
controlled data augmentation and outlier rejection methods. Unlike existing
methods, DSM can handle visual variations due to specular highlights and
reflection across adjacent frames, hence reducing the accumulated drift. We
perform experimental validation and comparison using 5 diverse fetoscopic
videos to demonstrate the robustness of our framework.
\\ ( https://arxiv.org/abs/1907.06543 ,  4456kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05885 (*cross-listing*)
Date: Thu, 11 Jul 2019 23:42:55 GMT   (1591kb,D)

Title: A Electric Network Reconfiguration Strategy with Case-Based Reasoning
  for the Smart Grid
Authors: Flavio G. Calhau and Joberto S. B. Martins
Categories: cs.AI cs.LG
Comments: 6 pages
DOI: 10.5281/zenodo.3277282
\\
  The complexity, heterogeneity and scale of electrical networks have grown far
beyond the limits of exclusively human-based management at the Smart Grid (SG).
Likewise, researchers cogitate the use of artificial intelligence and
heuristics techniques to create cognitive and autonomic management tools that
aim better assist and enhance SG management processes like in the grid
reconfiguration. The development of self-healing management approaches towards
a cognitive and autonomic distribution power network reconfiguration is a
scenario in which the scalability and on-the-fly computation are issues. This
paper proposes the use of Case-Based Reasoning (CBR) coupled with the HATSGA
algorithm for the fast reconfiguration of large distribution power networks.
The suitability and the scalability of the CBR-based reconfiguration strategy
using HATSGA algorithm are evaluated. The evaluation indicates that the adopted
HATSGA algorithm computes new reconfiguration topologies with a feasible
computational time for large networks. The CBR strategy looks for managerial
acceptable reconfiguration solutions at the CBR database and, as such,
contributes to reduce the required number of reconfiguration computation using
HATSGA. This suggests CBR can be applied with a fast reconfiguration algorithm
resulting in more efficient, dynamic and cognitive grid recovery strategy.
\\ ( https://arxiv.org/abs/1907.05885 ,  1591kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05905 (*cross-listing*)
Date: Fri, 12 Jul 2019 18:06:02 GMT   (1035kb,D)

Title: Voice Pathology Detection Using Deep Learning: a Preliminary Study
Authors: Pavol Harar, Jesus B. Alonso-Hernandez, Jiri Mekyska, Zoltan Galaz,
  Radim Burget and Zdenek Smekal
Categories: eess.AS cs.LG cs.SD
Comments: 4 pages, 1 figure, 5 tables
Journal-ref: In 2017 international conference and workshop on bioinspired
  intelligence (IWOBI), pp. 1-4. IEEE, 2017
DOI: 10.1109/IWOBI.2017.7985525
\\
  This paper describes a preliminary investigation of Voice Pathology Detection
using Deep Neural Networks (DNN). We used voice recordings of sustained vowel
/a/ produced at normal pitch from German corpus Saarbruecken Voice Database
(SVD). This corpus contains voice recordings and electroglottograph signals of
more than 2 000 speakers. The idea behind this experiment is the use of
convolutional layers in combination with recurrent Long-Short-Term-Memory
(LSTM) layers on raw audio signal. Each recording was split into 64 ms Hamming
windowed segments with 30 ms overlap. Our trained model achieved 71.36%
accuracy with 65.04% sensitivity and 77.67% specificity on 206 validation files
and 68.08% accuracy with 66.75% sensitivity and 77.89% specificity on 874
testing files. This is a promising result in favor of this approach because it
is comparable to similar previously published experiment that used different
methodology. Further investigation is needed to achieve the state-of-the-art
results.
\\ ( https://arxiv.org/abs/1907.05905 ,  1035kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05928 (*cross-listing*)
Date: Fri, 12 Jul 2019 19:47:31 GMT   (1137kb)

Title: A machine learning framework for computationally expensive transient
  models
Authors: Prashant Kumar, Kushal Sinha, Nandkishor Nere, Yujin Shin, Raimundo
  Ho, Ahmad Sheikh, Laurie Mlinar
Categories: physics.data-an cs.LG physics.app-ph
Comments: 25 pages and 6 figures
\\
  The promise of machine learning has been explored in a variety of scientific
disciplines in the last few years, however, its application on first-principles
based computationally expensive tools is still in nascent stage. Even with the
advances in computational resources and power, transient simulations of
large-scale dynamic systems using a variety of the first-principles based
computational tools are still limited. In this work, we propose an ensemble
approach where we combine one such computationally expensive tool, called
discrete element method (DEM), with a time-series forecasting method called
auto-regressive integrated moving average (ARIMA) and machine-learning methods
to significantly reduce the computational burden while retaining model accuracy
and performance. The developed machine-learning model shows good predictability
and agreement with the literature, demonstrating its tremendous potential in
scientific computing.
\\ ( https://arxiv.org/abs/1907.05928 ,  1137kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05944 (*cross-listing*)
Date: Fri, 12 Jul 2019 20:37:07 GMT   (23kb)

Title: Online-Learning for min-max discrete problems
Authors: Evripidis Bampis, Dimitris Christou, Bruno Escoffier, Nguyen Kim Thang
Categories: cs.DS cs.DM cs.LG
\\
  We study various discrete nonlinear combinatorial optimization problems in an
online learning framework. In the first part, we address the question of
whether there are negative results showing that getting a vanishing (or even
vanishing approximate) regret is computational hard. We provide a general
reduction showing that many (min-max) polynomial time solvable problems not
only do not have a vanishing regret, but also no vanishing approximation
$\alpha$-regret, for some $\alpha$ (unless $NP=BPP$). Then, we focus on a
particular min-max problem, the min-max version of the vertex cover problem
which is solvable in polynomial time in the offline case. The previous
reduction proves that there is no $(2-\epsilon)$-regret online algorithm,
unless Unique Game is in $BPP$; we prove a matching upper bound providing an
online algorithm based on the online gradient descent method. Then, we turn our
attention to online learning algorithms that are based on an offline
optimization oracle that, given a set of instances of the problem, is able to
compute the optimum static solution. We show that for different nonlinear
discrete optimization problems, it is strongly $NP$-hard to solve the offline
optimization oracle, even for problems that can be solved in polynomial time in
the static case (e.g. min-max vertex cover, min-max perfect matching, etc.). On
the positive side, we present an online algorithm with vanishing regret that is
based on the follow the perturbed leader algorithm for a generalized knapsack
problem.
\\ ( https://arxiv.org/abs/1907.05944 ,  23kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05964 (*cross-listing*)
Date: Fri, 12 Jul 2019 21:39:43 GMT   (35kb)

Title: Efficient average-case population recovery in the presence of insertions
  and deletions
Authors: Frank Ban, Xi Chen, Rocco A. Servedio, Sandip Sinha
Categories: cs.DS cs.IT cs.LG math.IT
\\
  Several recent works have considered the \emph{trace reconstruction problem},
in which an unknown source string $x\in\{0,1\}^n$ is transmitted through a
probabilistic channel which may randomly delete coordinates or insert random
bits, resulting in a \emph{trace} of $x$. The goal is to reconstruct the
original string~$x$ from independent traces of $x$. While the best algorithms
known for worst-case strings use $\exp(O(n^{1/3}))$ traces
\cite{DOS17,NazarovPeres17}, highly efficient algorithms are known
\cite{PZ17,HPP18} for the \emph{average-case} version, in which $x$ is
uniformly random. We consider a generalization of this average-case trace
reconstruction problem, which we call \emph{average-case population recovery in
the presence of insertions and deletions}. In this problem, there is an unknown
distribution $\cal{D}$ over $s$ unknown source strings $x^1,\dots,x^s \in
\{0,1\}^n$, and each sample is independently generated by drawing some $x^i$
from $\cal{D}$ and returning an independent trace of $x^i$.
  Building on \cite{PZ17} and \cite{HPP18}, we give an efficient algorithm for
this problem. For any support size $s \leq \smash{\exp(\Theta(n^{1/3}))}$, for
a $1-o(1)$ fraction of all $s$-element support sets $\{x^1,\dots,x^s\} \subset
\{0,1\}^n$, for every distribution $\cal{D}$ supported on $\{x^1,\dots,x^s\}$,
our algorithm efficiently recovers ${\cal D}$ up to total variation distance
$\epsilon$ with high probability, given access to independent traces of
independent draws from $\cal{D}$. The algorithm runs in time
poly$(n,s,1/\epsilon)$ and its sample complexity is
poly$(s,1/\epsilon,\exp(\log^{1/3}n)).$ This polynomial dependence on the
support size $s$ is in sharp contrast with the \emph{worst-case} version (when
$x^1,\dots,x^s$ may be any strings in $\{0,1\}^n$), in which the sample
complexity of the most efficient known algorithm \cite{BCFSS19} is doubly
exponential in $s$.
\\ ( https://arxiv.org/abs/1907.05964 ,  35kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05980 (*cross-listing*)
Date: Sat, 13 Jul 2019 00:18:45 GMT   (133kb)

Title: Convergence Analysis of Machine Learning Algorithms for the Numerical
  Solution of Mean Field Control and Games: I -- The Ergodic Case
Authors: Ren\'e Carmona, Mathieu Lauri\`ere
Categories: math.OC cs.LG cs.NA math.NA
\\
  We propose two algorithms for the solution of the optimal control of ergodic
McKean-Vlasov dynamics. Both algorithms are based on the approximation of the
theoretical solutions by neural networks, the latter being characterized by
their architecture and a set of parameters. This allows the use of modern
machine learning tools, and efficient implementations of stochastic gradient
descent. The first algorithm is based on the idiosyncrasies of the ergodic
optimal control problem. We provide a mathematical proof of the convergence of
the algorithm, and we analyze rigorously the approximation by controlling the
different sources of error. The second method is an adaptation of the deep
Galerkin method to the system of partial differential equations issued from the
optimality condition. We demonstrate the efficiency of these algorithms on
several numerical examples, some of them being chosen to show that our
algorithms succeed where existing ones failed. We also argue that both methods
can easily be applied to problems in dimensions larger than what can be found
in the existing literature. Finally, we illustrate the fact that, although the
first algorithm is specifically designed for mean field control problems, the
second one is more general and can also be applied to the partial differential
equation systems arising in the theory of mean field games.
\\ ( https://arxiv.org/abs/1907.05980 ,  133kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05984 (*cross-listing*)
Date: Sat, 13 Jul 2019 00:36:17 GMT   (2690kb,D)

Title: Distributed Black-Box Optimization via Error Correcting Codes
Authors: Burak Bartan, Mert Pilanci
Categories: cs.DC cs.IT cs.LG math.IT
\\
  We introduce a novel distributed derivative-free optimization framework that
is resilient to stragglers. The proposed method employs coded search directions
at which the objective function is evaluated, and a decoding step to find the
next iterate. Our framework can be seen as an extension of evolution strategies
and structured exploration methods where structured search directions were
utilized. As an application, we consider black-box adversarial attacks on deep
convolutional neural networks. Our numerical experiments demonstrate a
significant improvement in the computation times.
\\ ( https://arxiv.org/abs/1907.05984 ,  2690kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05991 (*cross-listing*)
Date: Sat, 13 Jul 2019 01:13:40 GMT   (340kb)

Title: Local Distribution Obfuscation via Probability Coupling
Authors: Yusuke Kawamoto and Takao Murakami
Categories: cs.CR cs.DB cs.IT cs.LG math.IT
Comments: Under submission (This paper extends some part of the unpublished v3
  of arXiv:1812.00939, while v4 of arXiv:1812.00939 extends the other part and
  is published in ESORICS'19.)
\\
  We introduce a general model for the local obfuscation of probability
distributions and investigate its theoretical properties. Specifically, we
relax a notion of distribution privacy by generalizing it to divergence, and
investigate local obfuscation mechanisms that provide the divergence
distribution privacy. To provide f-divergence distribution privacy, we prove
that the perturbation noise should be added proportionally to the Earth mover's
distance between the probability distributions that we want to make
indistinguishable. Furthermore, we introduce a local obfuscation mechanism,
which we call a coupling mechanism, that provides divergence distribution
privacy while optimizing the utility of obfuscated data by using
exact/approximate auxiliary information on the input distributions we want to
protect.
\\ ( https://arxiv.org/abs/1907.05991 ,  340kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06011 (*cross-listing*)
Date: Sat, 13 Jul 2019 05:21:05 GMT   (5947kb,D)

Title: Extracting Interpretable Physical Parameters from Spatiotemporal Systems
  using Unsupervised Learning
Authors: Peter Y. Lu, Samuel Kim, Marin Solja\v{c}i\'c
Categories: physics.comp-ph cs.LG physics.data-an stat.ML
\\
  Experimental data is often affected by uncontrolled variables that make
analysis and interpretation difficult. For spatiotemporal systems, this problem
is further exacerbated by their intricate dynamics. Modern machine learning
methods are well-suited for modeling complex datasets, but to be effective in
science, the result needs to be interpretable. We demonstrate an unsupervised
learning technique for extracting interpretable physical parameters from noisy
spatiotemporal data and for building a transferable model of the system. In
particular, we implement a physics-informed architecture based on variational
autoencoders that is designed for analyzing systems governed by partial
differential equations (PDEs). The architecture is trained end-to-end and
extracts latent parameters that parameterize the dynamics of a learned
predictive model for the system. To test our method, we train the architecture
on simulated data from a variety of PDEs with varying dynamical parameters that
act as uncontrolled variables. Specifically, we examine the
Kuramoto-Sivashinsky equation with varying viscosity damping parameter, the
nonlinear Schr\"odinger equation with varying nonlinearity coefficient, and the
convection-diffusion equation with varying diffusion constant and drift
velocity. Numerical experiments show that our method can accurately identify
relevant parameters and extract them from raw and even noisy spatiotemporal
data (tested with roughly 10% added noise). These extracted parameters
correlate well (linearly with $R^2>0.95$) with the ground truth physical
parameters used to generate the datasets. Our method for discovering
interpretable latent parameters in spatiotemporal systems will allow us to
better analyze and understand real-world phenomena and datasets, which often
have uncontrolled variables that alter the system dynamics and cause varying
behaviors that are difficult to disentangle.
\\ ( https://arxiv.org/abs/1907.06011 ,  5947kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06013 (*cross-listing*)
Date: Sat, 13 Jul 2019 05:34:01 GMT   (4191kb,D)

Title: Motion Planning Networks: Bridging the Gap Between Learning-based and
  Classical Motion Planners
Authors: Ahmed H. Qureshi, Yinglong Miao, Anthony Simeonov and Michael C. Yip
Categories: cs.RO cs.AI cs.LG
\\
  This paper describes Motion Planning Networks (MPNet), a computationally
efficient, learning-based neural planner for solving motion planning problems.
MPNet uses neural networks to learn general near-optimal heuristics for path
planning in seen and unseen environments. It receives environment information
as point-clouds, as well as a robot's initial and desired goal configurations
and recursively calls itself to bidirectionally generate connectable paths. In
addition to finding directly connectable and near-optimal paths in a single
pass, we show that worst-case theoretical guarantees can be proven if we merge
this neural network strategy with classical sample-based planners in a hybrid
approach while still retaining significant computational and optimality
improvements. To learn the MPNet models, we present an active continual
learning approach that enables MPNet to learn from streaming data and actively
ask for expert demonstrations when needed, drastically reducing data for
training. We validate MPNet against gold-standard and state-of-the-art planning
methods in a variety of problems from 2D to 7D robot configuration spaces in
challenging and cluttered environments, with results showing significant and
consistently stronger performance metrics, and motivating neural planning in
general as a modern strategy for solving motion planning problems efficiently.
\\ ( https://arxiv.org/abs/1907.06013 ,  4191kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06034 (*cross-listing*)
Date: Sat, 13 Jul 2019 09:17:57 GMT   (455kb,D)

Title: Towards Characterizing and Limiting Information Exposure in DNN Layers
Authors: Fan Mo, Ali Shahin Shamsabadi, Kleomenis Katevas, Andrea Cavallaro,
  Hamed Haddadi
Categories: cs.CR cs.LG
Comments: 5 pages, 6 figures, CCS PPML workshop
\\
  Pre-trained Deep Neural Network (DNN) models are increasingly used in
smartphones and other user devices to enable prediction services, leading to
potential disclosures of (sensitive) information from training data captured
inside these models. Based on the concept of generalization error, we propose a
framework to measure the amount of sensitive information memorized in each
layer of a DNN. Our results show that, when considered individually, the last
layers encode a larger amount of information from the training data compared to
the first layers. We find that, while the neuron of convolutional layers can
expose more (sensitive) information than that of fully connected layers, the
same DNN architecture trained with different datasets has similar exposure per
layer. We evaluate an architecture to protect the most sensitive layers within
the memory limits of Trusted Execution Environment (TEE) against potential
white-box membership inference attacks without the significant computational
overhead.
\\ ( https://arxiv.org/abs/1907.06034 ,  455kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06040 (*cross-listing*)
Date: Sat, 13 Jul 2019 09:57:12 GMT   (472kb,D)

Title: Energy-Efficient Radio Resource Allocation for Federated Edge Learning
Authors: Qunsong Zeng, Yuqing Du, Kin K. Leung, and Kaibin Huang
Categories: cs.IT cs.LG math.IT
\\
  Edge machine learning involves the development of learning algorithms at the
network edge to leverage massive distributed data and computation resources.
Among others, the framework of federated edge learning (FEEL) is particularly
promising for its data-privacy preservation. FEEL coordinates global model
training at a server and local model training at edge devices over wireless
links. In this work, we explore the new direction of energy-efficient radio
resource management (RRM) for FEEL. To reduce devices' energy consumption, we
propose energy-efficient strategies for bandwidth allocation and scheduling.
They adapt to devices' channel states and computation capacities so as to
reduce their sum energy consumption while warranting learning performance. In
contrast with the traditional rate-maximization designs, the derived optimal
policies allocate more bandwidth to those scheduled devices with weaker
channels or poorer computation capacities, which are the bottlenecks of
synchronized model updates in FEEL. On the other hand, the scheduling priority
function derived in closed form gives preferences to devices with better
channels and computation capacities. Substantial energy reduction contributed
by the proposed strategies is demonstrated in learning experiments.
\\ ( https://arxiv.org/abs/1907.06040 ,  472kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06051 (*cross-listing*)
Date: Sat, 13 Jul 2019 11:31:57 GMT   (136kb,D)

Title: k-hop Graph Neural Networks
Authors: Giannis Nikolentzos, George Dasoulas, Michalis Vazirgiannis
Categories: stat.ML cs.LG
\\
  Graph neural networks (GNNs) have emerged recently as a powerful architecture
for learning node and graph representations. Standard GNNs have the same
expressive power as the Weisfeiler-Leman test of graph isomorphism in terms of
distinguishing non-isomorphic graphs. However, it was recently shown that this
test cannot identify fundamental graph properties such as connectivity and
triangle freeness. We show that GNNs also suffer from the same limitation. To
address this limitation, we propose a more expressive architecture, k-hop GNNs,
which updates a node's representation by aggregating information not only from
its direct neighbors, but from its k-hop neighborhood. We show that the
proposed architecture can identify fundamental graph properties. We evaluate
the proposed architecture on standard node classification and graph
classification datasets. Our experimental evaluation confirms our theoretical
findings since the proposed model achieves performance better or comparable to
standard GNNs and to state-of-the-art algorithms.
\\ ( https://arxiv.org/abs/1907.06051 ,  136kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06066 (*cross-listing*)
Date: Sat, 13 Jul 2019 12:28:11 GMT   (48kb,D)

Title: The Use of Gaussian Processes in System Identification
Authors: Simo S\"arkk\"a
Categories: stat.ML cs.LG cs.SY eess.SY
Comments: To appear in Encyclopedia of systems and control, 2nd edition
\\
  Gaussian processes are used in machine learning to learn input-output
mappings from observed data. Gaussian process regression is based on imposing a
Gaussian process prior on the unknown regressor function and statistically
conditioning it on the observed data. In system identification, Gaussian
processes are used to form time series prediction models such as non-linear
finite-impulse response (NFIR) models as well as non-linear autoregressive
(NARX) models. Gaussian process state-space models (GPSS) can be used to learn
the dynamic and measurement models for a state-space representation of the
input-output data. Temporal and spatio-temporal Gaussian processes can be
directly used to form regressor on the data in the time domain. The aim of this
article is to briefly outline the main directions in system identification
methods using Gaussian processes.
\\ ( https://arxiv.org/abs/1907.06066 ,  48kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06098 (*cross-listing*)
Date: Sat, 13 Jul 2019 15:41:46 GMT   (2870kb,D)

Title: Seeker based Adaptive Guidance via Reinforcement Meta-Learning Applied
  to Asteroid Close Proximity Operations
Authors: Brian Gaudet, Richard Linares, Roberto Furfaro
Categories: eess.SY astro-ph.IM cs.LG cs.SY
Comments: Accepted for 2020 AAS Conference
\\
  Current practice for asteroid close proximity maneuvers requires extremely
accurate characterization of the environmental dynamics and precise spacecraft
positioning prior to the maneuver. This creates a delay of several months
between the spacecraft's arrival and the ability to safely complete close
proximity maneuvers. In this work we develop an adaptive integrated guidance,
navigation, and control system that can complete these maneuvers in
environments with unknown dynamics, with initial conditions spanning a large
deployment region, and without a shape model of the asteroid. The system is
implemented as a policy optimized using reinforcement meta-learning. The
spacecraft is equipped with an optical seeker that locks to either a terrain
feature, back-scattered light from a targeting laser, or an active beacon, and
the policy maps observations consisting of seeker angles and LIDAR range
readings directly to engine thrust commands. The policy implements a recurrent
network layer that allows the deployed policy to adapt real time to both
environmental forces acting on the agent and internal disturbances such as
actuator failure and center of mass variation. We validate the guidance system
through simulated landing maneuvers in a six degrees-of-freedom simulator. The
simulator randomizes the asteroid's characteristics such as solar radiation
pressure, density, spin rate, and nutation angle, requiring the guidance and
control system to adapt to the environment. We also demonstrate robustness to
actuator failure, sensor bias, and changes in the spacecraft's center of mass
and inertia tensor. Finally, we suggest a concept of operations for asteroid
close proximity maneuvers that is compatible with the guidance system.
\\ ( https://arxiv.org/abs/1907.06098 ,  2870kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06129 (*cross-listing*)
Date: Sat, 13 Jul 2019 21:09:40 GMT   (419kb,D)

Title: Towards Robust Voice Pathology Detection
Authors: Pavol Harar, Zoltan Galaz, Jesus B. Alonso-Hernandez, Jiri Mekyska,
  Radim Burget, Zdenek Smekal
Categories: cs.SD cs.LG eess.AS
Comments: 11 pages, 1 figure, 10 tables. Keywords: Voice pathology detection,
  deep learning, gradient boosting, anomaly detection
Journal-ref: Neural Computing and Applications (2018): 1-11
DOI: 10.1007/s00521-018-3464-7
\\
  Automatic objective non-invasive detection of pathological voice based on
computerized analysis of acoustic signals can play an important role in early
diagnosis, progression tracking and even effective treatment of pathological
voices. In search towards such a robust voice pathology detection system we
investigated 3 distinct classifiers within supervised learning and anomaly
detection paradigms. We conducted a set of experiments using a variety of input
data such as raw waveforms, spectrograms, mel-frequency cepstral coefficients
(MFCC) and conventional acoustic (dysphonic) features (AF). In comparison with
previously published works, this article is the first to utilize combination of
4 different databases comprising normophonic and pathological recordings of
sustained phonation of the vowel /a/ unrestricted to a subset of vocal
pathologies. Furthermore, to our best knowledge, this article is the first to
explore gradient boosted trees and deep learning for this application. The
following best classification performances measured by F1 score on dedicated
test set were achieved: XGBoost (0.733) using AF and MFCC, DenseNet (0.621)
using MFCC, and Isolation Forest (0.610) using AF. Even though these results
are of exploratory character, conducted experiments do show promising potential
of gradient boosting and deep learning methods to robustly detect voice
pathologies.
\\ ( https://arxiv.org/abs/1907.06129 ,  419kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06249 (*cross-listing*)
Date: Sun, 14 Jul 2019 17:12:55 GMT   (6890kb,D)

Title: Bayesian Synthesis of Probabilistic Programs for Automatic Data Modeling
Authors: Feras A. Saad, Marco F. Cusumano-Towner, Ulrich Schaechtle, Martin C.
  Rinard, Vikash K. Mansinghka
Categories: cs.PL cs.AI cs.LG stat.CO
Journal-ref: Proc. ACM Program. Lang. 3, POPL, Article 37 (January 2019)
DOI: 10.1145/3290350
\\
  We present new techniques for automatically constructing probabilistic
programs for data analysis, interpretation, and prediction. These techniques
work with probabilistic domain-specific data modeling languages that capture
key properties of a broad class of data generating processes, using Bayesian
inference to synthesize probabilistic programs in these modeling languages
given observed data. We provide a precise formulation of Bayesian synthesis for
automatic data modeling that identifies sufficient conditions for the resulting
synthesis procedure to be sound. We also derive a general class of synthesis
algorithms for domain-specific languages specified by probabilistic
context-free grammars and establish the soundness of our approach for these
languages. We apply the techniques to automatically synthesize probabilistic
programs for time series data and multivariate tabular data. We show how to
analyze the structure of the synthesized programs to compute, for key
qualitative properties of interest, the probability that the underlying data
generating process exhibits each of these properties. Second, we translate
probabilistic programs in the domain-specific language into probabilistic
programs in Venture, a general-purpose probabilistic programming system. The
translated Venture programs are then executed to obtain predictions of new time
series data and new multivariate data records. Experimental results show that
our techniques can accurately infer qualitative structure in multiple
real-world data sets and outperform standard data analysis methods in
forecasting and predicting new data.
\\ ( https://arxiv.org/abs/1907.06249 ,  6890kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06274 (*cross-listing*)
Date: Sun, 14 Jul 2019 20:06:53 GMT   (342kb,D)

Title: Predicting Merge Conflicts in Collaborative Software Development
Authors: Moein Owhadi-Kareshk, Sarah Nadi, Julia Rubin
Categories: cs.SE cs.LG
\\
  Background. During collaborative software development, developers often use
branches to add features or fix bugs. When merging changes from two branches,
conflicts may occur if the changes are inconsistent. Developers need to resolve
these conflicts before completing the merge, which is an error-prone and
time-consuming process. Early detection of merge conflicts, which warns
developers about resolving conflicts before they become large and complicated,
is among the ways of dealing with this problem. Existing techniques do this by
continuously pulling and merging all combinations of branches in the background
to notify developers as soon as a conflict occurs, which is a computationally
expensive process. One potential way for reducing this cost is to use a
machine-learning based conflict predictor that filters out the merge scenarios
that are not likely to have conflicts, ie safe merge scenarios. Aims. In this
paper, we assess if conflict prediction is feasible. Method. We design a
classifier for predicting merge conflicts, based on 9 light-weight Git feature
sets. To evaluate our predictor, we perform a large-scale study on 267, 657
merge scenarios from 744 GitHub repositories in seven programming languages.
Results. Our results show that we achieve high f1-scores, varying from 0.95 to
0.97 for different programming languages, when predicting safe merge scenarios.
The f1-score is between 0.57 and 0.68 for the conflicting merge scenarios.
Conclusions. Predicting merge conflicts is feasible in practice, especially in
the context of predicting safe merge scenarios as a pre-filtering step for
speculative merging.
\\ ( https://arxiv.org/abs/1907.06274 ,  342kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06323 (*cross-listing*)
Date: Mon, 15 Jul 2019 03:29:45 GMT   (7261kb,D)

Title: A Novel User Representation Paradigm for Making Personalized Candidate
  Retrieval
Authors: Zheng Liu, Yu Xing, Jianxun Lian, Defu Lian, Ziyao Li and Xing Xie
Categories: cs.IR cs.LG
\\
  Candidate retrieval is a crucial part in recommendation system, where quality
candidates need to be selected in realtime for user's recommendation request.
Conventional methods would make use of feature similarity directly for highly
scalable retrieval, yet their retrieval quality can be limited due to inferior
user interest modeling. In contrast, deep learning-based recommenders are
precise in modeling user interest, but they are difficult to be scaled for
efficient candidate retrieval.
  In this work, a novel paradigm Synthonet is proposed for both precise and
scalable candidate retrieval. With Synthonet, user is represented as a compact
vector known as retrieval key. By developing an Actor-Critic learning
framework, the generation of retrieval key is optimally conducted, such that
the similarity between retrieval key and item's representation will accurately
reflect user's interest towards the corresponding item. Consequently, quality
candidates can be acquired in realtime on top of highly efficient similarity
search methods. Comprehensive empirical studies are carried out for the
verification of our proposed methods, where consistent and remarkable
improvements are achieved over a series of competitive baselines, including
representative variations on metric learning.
\\ ( https://arxiv.org/abs/1907.06323 ,  7261kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06341 (*cross-listing*)
Date: Mon, 15 Jul 2019 06:28:40 GMT   (474kb,D)

Title: Controlling Model Complexity in Probabilistic Model-Based Dynamic
  Optimization of Neural Network Structures
Authors: Shota Saito, Shinichi Shirakawa
Categories: cs.NE cs.LG stat.ML
Comments: Accepted as a conference paper at the 28th International Conference
  on Artificial Neural Networks (ICANN 2019). The final authenticated
  publication will be available in the Springer Lecture Notes in Computer
  Science (LNCS). 13 pages
\\
  A method of simultaneously optimizing both the structure of neural networks
and the connection weights in a single training loop can reduce the enormous
computational cost of neural architecture search. We focus on the probabilistic
model-based dynamic neural network structure optimization that considers the
probability distribution of structure parameters and simultaneously optimizes
both the distribution parameters and connection weights based on gradient
methods. Since the existing algorithm searches for the structures that only
minimize the training loss, this method might find overly complicated
structures. In this paper, we propose the introduction of a penalty term to
control the model complexity of obtained structures. We formulate a penalty
term using the number of weights or units and derive its analytical natural
gradient. The proposed method minimizes the objective function injected the
penalty term based on the stochastic gradient descent. We apply the proposed
method in the unit selection of a fully-connected neural network and the
connection selection of a convolutional neural network. The experimental
results show that the proposed method can control model complexity while
maintaining performance.
\\ ( https://arxiv.org/abs/1907.06341 ,  474kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06430 (*cross-listing*)
Date: Mon, 15 Jul 2019 11:06:06 GMT   (80kb,D)

Title: A Causal Bayesian Networks Viewpoint on Fairness
Authors: Silvia Chiappa and William S. Isaac
Categories: stat.ML cs.LG
Journal-ref: Privacy and Identity Management. Fairness, Accountability, and
  Transparency in the Age of Big Data. IFIP Advances in Information and
  Communication Technology, vol 547. Springer, Cham, 2019
DOI: 10.1007/978-3-030-16744-8_1
\\
  We offer a graphical interpretation of unfairness in a dataset as the
presence of an unfair causal path in the causal Bayesian network representing
the data-generation mechanism. We use this viewpoint to revisit the recent
debate surrounding the COMPAS pretrial risk assessment tool and, more
generally, to point out that fairness evaluation on a model requires careful
considerations on the patterns of unfairness underlying the training data. We
show that causal Bayesian networks provide us with a powerful tool to measure
unfairness in a dataset and to design fair models in complex unfairness
scenarios.
\\ ( https://arxiv.org/abs/1907.06430 ,  80kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06441 (*cross-listing*)
Date: Mon, 15 Jul 2019 11:32:31 GMT   (266kb,D)

Title: Noise-Stable Rigid Graphs for Euclidean Embedding
Authors: Zishuo Zhao, Shi-Min Hu
Categories: cs.CG cs.DM cs.LG
\\
  We proposed a new criterion \textit{noise-stability}, which revised the
classical rigidity theory, for evaluation of MDS algorithms which can
truthfully represent the fidelity of global structure reconstruction; then we
proved the noise-stability of the cMDS algorithm in generic conditions, which
provides a rigorous theoretical guarantee for the precision and theoretical
bounds for Euclidean embedding and its application in fields including wireless
sensor network localization and satellite positioning.
  Furthermore, we looked into previous work about minimum-cost globally rigid
spanning subgraph, and proposed an algorithm to construct a minimum-cost
noise-stable spanning graph in the Euclidean space, which enabled reliable
localization on sparse graphs of noisy distance constraints with linear numbers
of edges and sublinear costs in total edge lengths. Additionally, this
algorithm enabled us to reconstruct point clouds from pairwise distances at a
minimum of $O(n)$ time complexity, down from $O(n^3)$ for cMDS.
\\ ( https://arxiv.org/abs/1907.06441 ,  266kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06481 (*cross-listing*)
Date: Mon, 15 Jul 2019 13:01:26 GMT   (478kb,D)

Title: Unsupervised Fault Detection in Varying Operating Conditions
Authors: Gabriel Michau and Olga Fink
Categories: stat.ML cs.LG stat.AP
Journal-ref: Proceedings of the 2019 IEEE International Conference on
  Prognostics and Health Management
\\
  Training data-driven approaches for complex industrial system health
monitoring is challenging. When data on faulty conditions are rare or not
available, the training has to be performed in a unsupervised manner. In
addition, when the observation period, used for training, is kept short, to be
able to monitor the system in its early life, the training data might not be
representative of all the system normal operating conditions. In this paper, we
propose five approaches to perform fault detection in such context. Two
approaches rely on the data from the unit to be monitored only: the baseline is
trained on the early life of the unit. An incremental learning procedure tries
to learn new operating conditions as they arise. Three other approaches take
advantage of data from other similar units within a fleet. In two cases, units
are directly compared to each other with similarity measures, and the data from
similar units are combined in the training set. We propose, in the third case,
a new deep-learning methodology to perform, first, a feature alignment of
different units with an Unsupervised Feature Alignment Network (UFAN). Then,
features of both units are combined in the training set of the fault detection
neural network.
  The approaches are tested on a fleet comprising 112 units, observed over one
year of data. All approaches proposed here are an improvement to the baseline,
trained with two months of data only. As units in the fleet are found to be
very dissimilar, the new architecture UFAN, that aligns units in the feature
space, is outperforming others.
\\ ( https://arxiv.org/abs/1907.06481 ,  478kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06484 (*cross-listing*)
Date: Mon, 15 Jul 2019 13:09:18 GMT   (661kb,D)

Title: A study on the Interpretability of Neural Retrieval Models using
  DeepSHAP
Authors: Zeon Trevor Fernando, Jaspreet Singh, Avishek Anand
Categories: cs.IR cs.LG
Comments: 4 pages; SIGIR 2019 Short Paper
DOI: 10.1145/3331184.3331312
\\
  A recent trend in IR has been the usage of neural networks to learn retrieval
models for text based adhoc search. While various approaches and architectures
have yielded significantly better performance than traditional retrieval models
such as BM25, it is still difficult to understand exactly why a document is
relevant to a query. In the ML community several approaches for explaining
decisions made by deep neural networks have been proposed -- including DeepSHAP
which modifies the DeepLift algorithm to estimate the relative importance
(shapley values) of input features for a given decision by comparing the
activations in the network for a given image against the activations caused by
a reference input. In image classification, the reference input tends to be a
plain black image. While DeepSHAP has been well studied for image
classification tasks, it remains to be seen how we can adapt it to explain the
output of Neural Retrieval Models (NRMs). In particular, what is a good "black"
image in the context of IR? In this paper we explored various reference input
document construction techniques. Additionally, we compared the explanations
generated by DeepSHAP to LIME (a model agnostic approach) and found that the
explanations differ considerably. Our study raises concerns regarding the
robustness and accuracy of explanations produced for NRMs. With this paper we
aim to shed light on interesting problems surrounding interpretability in NRMs
and highlight areas of future work.
\\ ( https://arxiv.org/abs/1907.06484 ,  661kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06490 (*cross-listing*)
Date: Mon, 15 Jul 2019 13:21:43 GMT   (1271kb,D)

Title: DeepSUM: Deep neural network for Super-resolution of Unregistered
  Multitemporal images
Authors: Andrea Bordone Molini, Diego Valsesia, Giulia Fracastoro, Enrico Magli
Categories: eess.IV cs.LG
\\
  Recently, convolutional neural networks (CNN) have been successfully applied
to many remote sensing problems. However, deep learning techniques for
multi-image super-resolution from multitemporal unregistered imagery have
received little attention so far. This work proposes a novel CNN-based
technique that exploits both spatial and temporal correlations to combine
multiple images. This novel framework integrates the spatial registration task
directly inside the CNN, and allows to exploit the representation learning
capabilities of the network to enhance registration accuracy. The entire
super-resolution process relies on a single CNN with three main stages: shared
2D convolutions to extract high-dimensional features from the input images; a
subnetwork proposing registration filters derived from the high-dimensional
feature representations; 3D convolutions for slow fusion of the features from
multiple images. The whole network can be trained end-to-end to recover a
single high resolution image from multiple unregistered low resolution images.
The method presented in this paper is the winner of the PROBA-V
super-resolution challenge issued by the European Space Agency.
\\ ( https://arxiv.org/abs/1907.06490 ,  1271kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06508 (*cross-listing*)
Date: Thu, 11 Jul 2019 13:02:25 GMT   (240kb,D)

Title: General Board Game Playing for Education and Research in Generic AI Game
  Learning
Authors: Wolfgang Konen
Categories: cs.AI cs.LG stat.ML
Comments: 8 pages, for: Conference on Games (CoG), London, 2019. Index Terms:
  game learning, general game playing, AI, temporal difference learning, board
  games, n-tuple systems
\\
  We present a new general board game (GBG) playing and learning framework. GBG
defines the common interfaces for board games, game states and their AI agents.
It allows one to run competitions of different agents on different games. It
standardizes those parts of board game playing and learning that otherwise
would be tedious and repetitive parts in coding. GBG is suitable for arbitrary
1-, 2-, ..., N-player board games. It makes a generic TD($\lambda$)-n-tuple
agent for the first time available to arbitrary games. On various games,
TD($\lambda$)-n-tuple is found to be superior to other generic agents like
MCTS. GBG aims at the educational perspective, where it helps students to start
faster in the area of game learning. GBG aims as well at the research
perspective by collecting a growing set of games and AI agents to assess their
strengths and generalization capabilities in meaningful competitions. Initial
successful educational and research results are reported.
\\ ( https://arxiv.org/abs/1907.06508 ,  240kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06511 (*cross-listing*)
Date: Wed, 10 Jul 2019 16:57:50 GMT   (6591kb,D)

Title: Reinforcement Learning with Chromatic Networks
Authors: Xingyou Song, Krzysztof Choromanski, Jack Parker-Holder, Yunhao Tang,
  Wenbo Gao, Aldo Pacchiano, Tamas Sarlos, Deepali Jain, Yuxiang Yang
Categories: cs.NE cs.AI cs.LG cs.RO
Comments: 10 main pages, 22 total pages
\\
  We present a new algorithm for finding compact neural networks encoding
reinforcement learning (RL) policies. To do it, we leverage in the novel RL
setting the theory of pointer networks and ENAS-type algorithms for
combinatorial optimization of RL policies as well as recent evolution
strategies (ES) optimization methods, and propose to define the combinatorial
search space to be the the set of different edge-partitionings (colorings) into
same-weight classes. For several RL tasks, we manage to learn colorings
translating to effective policies parameterized by as few as 17 weight
parameters, providing 6x compression over state-of-the-art compact policies
based on Toeplitz matrices. We believe that our work is one of the first
attempts to propose a rigorous approach to training structured neural network
architectures for RL problems that are of interest especially in mobile
robotics with limited storage and computational resources.
\\ ( https://arxiv.org/abs/1907.06511 ,  6591kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06550 (*cross-listing*)
Date: Mon, 15 Jul 2019 15:27:30 GMT   (22kb)

Title: A Dimension-free Algorithm for Contextual Continuum-armed Bandits
Authors: Wenhao Li, Ningyuan Chen, L.Jeff Hong
Categories: stat.ML cs.LG
\\
  In contextual continuum-armed bandits, the contexts $x$ and the arms $y$ are
both continuous and drawn from high-dimensional spaces. The payoff function to
learn $f(x,y)$ does not have a particular parametric form. The literature has
shown that for Lipschitz-continuous functions, the optimal regret is
$\tilde{O}(T^{\frac{d_x+d_y+1}{d_x+d_y+2}})$, where $d_x$ and $d_y$ are the
dimensions of contexts and arms, and thus suffers from the curse of
dimensionality. We develop an algorithm that achieves regret
$\tilde{O}(T^{\frac{d_x+1}{d_x+2}})$ when $f$ is globally concave in $y$. The
global concavity is a common assumption in many applications. The algorithm is
based on stochastic approximation and estimates the gradient information in an
online fashion. Our results generate a valuable insight that the curse of
dimensionality of the arms can be overcome with some mild structures of the
payoff function.
\\ ( https://arxiv.org/abs/1907.06550 ,  22kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06558 (*cross-listing*)
Date: Mon, 15 Jul 2019 15:56:49 GMT   (886kb,D)

Title: Addressing Delayed Feedback for Continuous Training with Neural Networks
  in CTR prediction
Authors: Sofia Ira Ktena, Alykhan Tejani, Lucas Theis, Pranay Kumar Myana,
  Deepak Dilipkumar, Ferenc Huszar, Steven Yoo, Wenzhe Shi
Categories: stat.ML cs.LG
Comments: Accepted at RecSys '19
\\
  One of the challenges in display advertising is that the distribution of
features and click through rate (CTR) can exhibit large shifts over time due to
seasonality, changes to ad campaigns and other factors. The predominant
strategy to keep up with these shifts is to train predictive models
continuously, on fresh data, in order to prevent them from becoming stale.
However, in many ad systems positive labels are only observed after a possibly
long and random delay. These delayed labels pose a challenge to data freshness
in continuous training: fresh data may not have complete label information at
the time they are ingested by the training algorithm. Naive strategies which
consider any data point a negative example until a positive label becomes
available tend to underestimate CTR, resulting in inferior user experience and
suboptimal performance for advertisers. The focus of this paper is to identify
the best combination of loss functions and models that enable large-scale
learning from a continuous stream of data in the presence of delayed labels. In
this work, we compare 5 different loss functions, 3 of them applied to this
problem for the first time. We benchmark their performance in offline settings
on both public and proprietary datasets in conjunction with shallow and deep
model architectures. We also discuss the engineering cost associated with
implementing each loss function in a production environment. Finally, we
carried out online experiments with the top performing methods, in order to
validate their performance in a continuous training scheme. While training on
668 million in-house data points offline, our proposed methods outperform
previous state-of-the-art by 3% relative cross entropy (RCE). During online
experiments, we observed 55% gain in revenue per thousand requests (RPMq)
against naive log loss.
\\ ( https://arxiv.org/abs/1907.06558 ,  886kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06566 (*cross-listing*)
Date: Mon, 15 Jul 2019 16:16:21 GMT   (6142kb,D)

Title: Improved Hybrid Layered Image Compression using Deep Learning and
  Traditional Codecs
Authors: Haisheng Fu, Feng Liang, Bo Lei, Nai Bian, Qian zhang, Mohammad
  Akbari, Jie Liang and Chengjie Tu
Categories: eess.IV cs.LG stat.ML
Comments: Submitted to Signal Processing: Image Communication
\\
  Recently deep learning-based methods have been applied in image compression
and achieved many promising results. In this paper, we propose an improved
hybrid layered image compression framework by combining deep learning and the
traditional image codecs. At the encoder, we first use a convolutional neural
network (CNN) to obtain a compact representation of the input image, which is
losslessly encoded by the FLIF codec as the base layer of the bit stream. A
coarse reconstruction of the input is obtained by another CNN from the
reconstructed compact representation. The residual between the input and the
coarse reconstruction is then obtained and encoded by the H.265/HEVC-based BPG
codec as the enhancement layer of the bit stream. Experimental results using
the Kodak and Tecnick datasets show that the proposed scheme outperforms the
state-of-the-art deep learning-based layered coding scheme and traditional
codecs including BPG in both PSNR and MS-SSIM metrics across a wide range of
bit rates, when the images are coded in the RGB444 domain.
\\ ( https://arxiv.org/abs/1907.06566 ,  6142kb)
------------------------------------------------------------------------------
\\
arXiv:1907.06589 (*cross-listing*)
Date: Mon, 15 Jul 2019 16:46:21 GMT   (1274kb,D)

Title: Experimental machine learning quantum homodyne tomography
Authors: E.S. Tiunov, V.V. Vyborova, A.E. Ulanov, A.I. Lvovsky, and A.K.
  Fedorov
Categories: quant-ph cs.LG
Comments: 6+1 pages, 3 figures
\\
  Complete characterization of states and processes that occur within quantum
devices is crucial for understanding and testing their potential to outperform
classical technologies for communications and computing. However, this task
becomes unwieldy for large and complex quantum systems. Here we realize and
experimentally demonstrate a method for complete characterization of a harmonic
oscillator based on an artificial neural network known as the restricted
Boltzmann machine. We apply the method to experimental balanced homodyne
tomography and show it to allow full estimation of quantum states based on a
smaller amount of experimental data. Although our experiment is in the optical
domain, our method provides a way of exploring quantum resources in a broad
class of physical systems, such as superconducting circuits, atomic and
molecular ensembles, and optomechanical systems.
\\ ( https://arxiv.org/abs/1907.06589 ,  1274kb)
%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%--%%
------------------------------------------------------------------------------
\\
arXiv:1801.00428
replaced with revised version Mon, 15 Jul 2019 13:25:29 GMT   (1066kb,D)

Title: Sanskrit Sandhi Splitting using seq2(seq)^2
Authors: Rahul Aralikatte, Neelamadhav Gantayat, Naveen Panwar, Anush Sankaran,
  Senthil Mani
Categories: cs.CL
Comments: Accepted in EMNLP 2018
\\ ( https://arxiv.org/abs/1801.00428 ,  1066kb)
------------------------------------------------------------------------------
\\
arXiv:1905.05701
replaced with revised version Sun, 14 Jul 2019 15:03:53 GMT   (6080kb,D)

Title: Modeling user context for valence prediction from narratives
Authors: Aniruddha Tammewar, Alessandra Cervone, Eva-Maria Messner, Giuseppe
  Riccardi
Categories: cs.CL cs.AI cs.LG stat.ML
Comments: To be published in Interspeech 2019
\\ ( https://arxiv.org/abs/1905.05701 ,  6080kb)
------------------------------------------------------------------------------
\\
arXiv:1905.06939
replaced with revised version Sat, 13 Jul 2019 21:52:48 GMT   (198kb,D)

Title: The Materials Science Procedural Text Corpus: Annotating Materials
  Synthesis Procedures with Shallow Semantic Structures
Authors: Sheshera Mysore, Zach Jensen, Edward Kim, Kevin Huang, Haw-Shiuan
  Chang, Emma Strubell, Jeffrey Flanigan, Andrew McCallum, Elsa Olivetti
Categories: cs.CL cs.LG
Comments: Accepted as a long paper at the Linguistic Annotation Workshop (LAW)
  at ACL 2019
\\ ( https://arxiv.org/abs/1905.06939 ,  198kb)
------------------------------------------------------------------------------
\\
arXiv:1905.10625
replaced with revised version Sun, 14 Jul 2019 00:50:53 GMT   (87kb,D)

Title: ESA: Entity Summarization with Attention
Authors: Dongjun Wei and Yaxin Liu
Categories: cs.CL cs.AI
Comments: 12pages, 6 figures
\\ ( https://arxiv.org/abs/1905.10625 ,  87kb)
------------------------------------------------------------------------------
\\
arXiv:1905.13150
replaced with revised version Sat, 13 Jul 2019 14:25:33 GMT   (200kb,D)

Title: Lattice-based lightly-supervised acoustic model training
Authors: Joachim Fainberg, Ond\v{r}ej Klejch, Steve Renals, Peter Bell
Categories: cs.CL cs.SD eess.AS
Comments: Proc. INTERSPEECH 2019
\\ ( https://arxiv.org/abs/1905.13150 ,  200kb)
------------------------------------------------------------------------------
\\
arXiv:1906.00156
replaced with revised version Sun, 14 Jul 2019 06:46:16 GMT   (3290kb)

Title: Promotion of Answer Value Measurement with Domain Effects in Community
  Question Answering Systems
Authors: Binbin Jin, Enhong Chen, Hongke Zhao, Zhenya Huang, Qi Liu, Hengshu
  Zhu, Shui Yu
Categories: cs.CL cs.IR
Comments: IEEE Transactions on Systems, Man, and Cybernetics: Systems
DOI: 10.1109/TSMC.2019.2917673
\\ ( https://arxiv.org/abs/1906.00156 ,  3290kb)
------------------------------------------------------------------------------
\\
arXiv:1906.05765
replaced with revised version Sun, 14 Jul 2019 07:21:22 GMT   (151kb,D)

Title: Anti dependency distance minimization in short sequences. A graph
  theoretic approach
Authors: Ramon Ferrer-i-Cancho and Carlos G\'omez-Rodr\'iguez
Categories: cs.CL
Comments: Little corrections before submitting the sources to production
  (English, format and typos); Journal of Quantitative Linguistics, in press
\\ ( https://arxiv.org/abs/1906.05765 ,  151kb)
------------------------------------------------------------------------------
\\
arXiv:1906.10225
replaced with revised version Sat, 13 Jul 2019 00:47:50 GMT   (164kb,D)

Title: Compound Probabilistic Context-Free Grammars for Grammar Induction
Authors: Yoon Kim, Chris Dyer, Alexander M. Rush
Categories: cs.CL stat.ML
Comments: ACL 2019
\\ ( https://arxiv.org/abs/1906.10225 ,  164kb)
------------------------------------------------------------------------------
\\
arXiv:1906.10256
replaced with revised version Sat, 13 Jul 2019 05:38:28 GMT   (404kb,D)

Title: Good Secretaries, Bad Truck Drivers? Occupational Gender Stereotypes in
  Sentiment Analysis
Authors: Jayadev Bhaskaran and Isha Bhallamudi
Categories: cs.CL
Comments: Accepted at GeBNLP (ACL Workshop on Gender Bias for NLP) at ACL 2019
\\ ( https://arxiv.org/abs/1906.10256 ,  404kb)
------------------------------------------------------------------------------
\\
arXiv:1906.11746
replaced with revised version Sat, 13 Jul 2019 10:12:10 GMT   (498kb,D)

Title: Compositional Semantic Parsing Across Graphbanks
Authors: Matthias Lindemann and Jonas Groschwitz and Alexander Koller
Categories: cs.CL
Comments: Accepted at ACL 2019
\\ ( https://arxiv.org/abs/1906.11746 ,  498kb)
------------------------------------------------------------------------------
\\
arXiv:1907.01118
replaced with revised version Mon, 15 Jul 2019 14:10:10 GMT   (174kb,D)

Title: Neural Machine Reading Comprehension: Methods and Trends
Authors: Shanshan Liu, Xin Zhang, Sheng Zhang, Hui Wang, Weiming Zhang
Categories: cs.CL
Comments: 39 pages
\\ ( https://arxiv.org/abs/1907.01118 ,  174kb)
------------------------------------------------------------------------------
\\
arXiv:1705.07222
replaced with revised version Sun, 14 Jul 2019 11:26:12 GMT   (4495kb,D)

Title: Quadruplet Network with One-Shot Learning for Fast Visual Object
  Tracking
Authors: Xingping Dong and Jianbing Shen and Dongming Wu and Kan Guo and
  Xiaogang Jin and Fatih Porikli
Categories: cs.CV
Journal-ref: IEEE Transactions on Image Processing ( Volume: 28 , Issue: 7 ,
  July 2019 )
DOI: 10.1109/TIP.2019.2898567
\\ ( https://arxiv.org/abs/1705.07222 ,  4495kb)
------------------------------------------------------------------------------
\\
arXiv:1804.04810
replaced with revised version Sun, 14 Jul 2019 04:55:49 GMT   (7097kb,D)

Title: Mutual Suppression Network for Video Prediction using Disentangled
  Features
Authors: Jungbeom Lee, Jangho Lee, Sungmin Lee, Sungroh Yoon
Categories: cs.CV
Comments: BMVC 2019 (Oral)
\\ ( https://arxiv.org/abs/1804.04810 ,  7097kb)
------------------------------------------------------------------------------
\\
arXiv:1806.11169
replaced with revised version Sat, 13 Jul 2019 16:04:29 GMT   (2363kb,D)

Title: 3D Normal Coordinate Systems for Cortical Areas
Authors: J. Tilak Ratnanather, Sylvain Arguill\`ere, Kwame S. Kutten, Peter
  Hubka, Andrej Kral, Laurent Younes
Categories: cs.CV
\\ ( https://arxiv.org/abs/1806.11169 ,  2363kb)
------------------------------------------------------------------------------
\\
arXiv:1807.01232
replaced with revised version Mon, 15 Jul 2019 02:40:55 GMT   (8876kb,D)

Title: SpaceNet: A Remote Sensing Dataset and Challenge Series
Authors: Adam Van Etten, Dave Lindenbaum, Todd M. Bacastow
Categories: cs.CV
Comments: 10 pages, 5 figures, 2 tables, 5 appendices
\\ ( https://arxiv.org/abs/1807.01232 ,  8876kb)
------------------------------------------------------------------------------
\\
arXiv:1808.08578
replaced with revised version Sat, 13 Jul 2019 19:39:39 GMT   (4659kb,D)

Title: Automatic 3D bi-ventricular segmentation of cardiac images by a
  shape-refined multi-task deep learning approach
Authors: Jinming Duan, Ghalib Bello, Jo Schlemper, Wenjia Bai, Timothy J W
  Dawes, Carlo Biffi, Antonio de Marvao, Georgia Doumou, Declan P O'Regan,
  Daniel Rueckert
Categories: cs.CV cs.AI
\\ ( https://arxiv.org/abs/1808.08578 ,  4659kb)
------------------------------------------------------------------------------
\\
arXiv:1808.09560
replaced with revised version Sun, 14 Jul 2019 05:01:58 GMT   (7399kb,D)

Title: On Learning 3D Face Morphable Model from In-the-wild Images
Authors: Luan Tran, Xiaoming Liu
Categories: cs.CV
Comments: IEEE Transactions on Pattern Analysis and Machine Intelligence
  (TPAMI). Conference version: arXiv:1804.03786 (CVPR'18). Source code:
  https://github.com/tranluan/Nonlinear_Face_3DMM , Project webpage:
  http://cvlab.cse.msu.edu/project-nonlinear-3dmm.html
DOI: 10.1109/TPAMI.2019.2927975
\\ ( https://arxiv.org/abs/1808.09560 ,  7399kb)
------------------------------------------------------------------------------
\\
arXiv:1811.00250
replaced with revised version Sun, 14 Jul 2019 10:31:03 GMT   (809kb,D)

Title: Filter Pruning via Geometric Median for Deep Convolutional Neural
  Networks Acceleration
Authors: Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, Yi Yang
Categories: cs.CV
Comments: Accepted to CVPR 2019 (Oral)
\\ ( https://arxiv.org/abs/1811.00250 ,  809kb)
------------------------------------------------------------------------------
\\
arXiv:1811.01395
replaced with revised version Sat, 13 Jul 2019 18:55:59 GMT   (3403kb,D)

Title: A Deep One-Shot Network for Query-based Logo Retrieval
Authors: Ayan Kumar Bhunia, Ankan Kumar Bhunia, Shuvozit Ghose, Abhirup Das,
  Partha Pratim Roy, Umapada Pal
Categories: cs.CV
Comments: Accepted in Pattern Recognition, Elsevier(2019)
DOI: 10.1016/j.patcog.2019.106965
\\ ( https://arxiv.org/abs/1811.01395 ,  3403kb)
------------------------------------------------------------------------------
\\
arXiv:1812.00645
replaced with revised version Mon, 15 Jul 2019 11:11:30 GMT   (3748kb,D)

Title: Unsupervised Deep Slow Feature Analysis for Change Detection in
  Multi-Temporal Remote Sensing Images
Authors: Bo Du, Lixiang Ru, Chen Wu, Liangpei Zhang
Categories: cs.CV
Comments: 17 pages, 14 figures, accepted by IEEE Transactions of Geoscience and
  Remote Sensing
\\ ( https://arxiv.org/abs/1812.00645 ,  3748kb)
------------------------------------------------------------------------------
\\
arXiv:1812.10306
replaced with revised version Sat, 13 Jul 2019 09:13:34 GMT   (429kb,D)

Title: Spotting Micro-Expressions on Long Videos Sequences
Authors: Jingting Li and Catherine Soladie and Renaud Sguier and Sujing Wang
  and Moi Hoon Yap
Categories: cs.CV
Comments: 4 pages, 3 figures and 3 tables
Journal-ref: The 14th IEEE International Conference on Automatic Face & Gesture
  Recognition (FG 2019)
DOI: 10.1109/FG.2019.8756626
\\ ( https://arxiv.org/abs/1812.10306 ,  429kb)
------------------------------------------------------------------------------
\\
arXiv:1902.11123
replaced with revised version Mon, 15 Jul 2019 15:16:40 GMT   (5610kb,D)

Title: Adaptive Masked Proxies for Few-Shot Segmentation
Authors: Mennatullah Siam, Boris Oreshkin, Martin Jagersand
Categories: cs.CV cs.LG stat.ML
Comments: Submitted to ICCV'19
\\ ( https://arxiv.org/abs/1902.11123 ,  5610kb)
------------------------------------------------------------------------------
\\
arXiv:1903.07377
replaced with revised version Mon, 15 Jul 2019 11:40:53 GMT   (80kb,D)

Title: Evaluating Sequence-to-Sequence Models for Handwritten Text Recognition
Authors: Johannes Michael, Roger Labahn, Tobias Gr\"uning, Jochen Z\"ollner
Categories: cs.CV cs.LG
Comments: 8 pages, 1 figure, 8 tables
\\ ( https://arxiv.org/abs/1903.07377 ,  80kb)
------------------------------------------------------------------------------
\\
arXiv:1904.04317
replaced with revised version Mon, 15 Jul 2019 15:21:07 GMT   (5539kb,D)

Title: $\mathcal{G}$-softmax: Improving Intra-class Compactness and Inter-class
  Separability of Features
Authors: Yan Luo, Yongkang Wong, Mohan Kankanhalli, and Qi Zhao
Categories: cs.CV cs.LG
Comments: 15 pages, published in TNNLS
Journal-ref: IEEE Transactions on Neural Networks and Learning Systems in 2019
DOI: 10.1109/TNNLS.2019.2909737
\\ ( https://arxiv.org/abs/1904.04317 ,  5539kb)
------------------------------------------------------------------------------
\\
arXiv:1905.01040
replaced with revised version Sat, 13 Jul 2019 02:45:07 GMT   (1829kb,D)

Title: PFA-ScanNet: Pyramidal Feature Aggregation with Synergistic Learning for
  Breast Cancer Metastasis Analysis
Authors: Zixu Zhao, Huangjing Lin, Hao Chen, Pheng-Ann Heng
Categories: cs.CV
Comments: Accepted by MICCAI 2019
\\ ( https://arxiv.org/abs/1905.01040 ,  1829kb)
------------------------------------------------------------------------------
\\
arXiv:1905.05425
replaced with revised version Mon, 15 Jul 2019 16:24:41 GMT   (1702kb,D)

Title: Panoramic Annular Localizer: Tackling the Variation Challenges of
  Outdoor Localization Using Panoramic Annular Images and Active Deep
  Descriptors
Authors: Ruiqi Cheng, Kaiwei Wang, Shufei Lin, Weijian Hu, Kailun Yang, Xiao
  Huang, Huabing Li, Dongming Sun, Jian Bai
Categories: cs.CV
Comments: Accepted by ITSC 2019
\\ ( https://arxiv.org/abs/1905.05425 ,  1702kb)
------------------------------------------------------------------------------
\\
arXiv:1906.06698
replaced with revised version Mon, 15 Jul 2019 08:11:09 GMT   (1111kb,D)

Title: Beyond Product Quantization: Deep Progressive Quantization for Image
  Retrieval
Authors: Lianli Gao, Xiaosu Zhu, Jingkuan Song, Zhou Zhao and Heng Tao Shen
Categories: cs.CV
\\ ( https://arxiv.org/abs/1906.06698 ,  1111kb)
------------------------------------------------------------------------------
\\
arXiv:1906.06699
replaced with revised version Mon, 15 Jul 2019 07:57:43 GMT   (648kb,D)

Title: Deep Recurrent Quantization for Generating Sequential Binary Codes
Authors: Jingkuan Song, Xiaosu Zhu, Lianli Gao, Xin-Shun Xu, Wu Liu, Heng Tao
  Shen
Categories: cs.CV
\\ ( https://arxiv.org/abs/1906.06699 ,  648kb)
------------------------------------------------------------------------------
\\
arXiv:1906.10925
replaced with revised version Sun, 14 Jul 2019 13:19:54 GMT   (799kb,D)

Title: FA-Harris: A Fast and Asynchronous Corner Detector for Event Cameras
Authors: Ruoxiang Li, Dianxi Shi, Yongjun Zhang, Kaiyue Li, Ruihao Li
Categories: cs.CV cs.RO
Comments: 7 pages, 3 figures, Accepted by IROS 2019. Video:
  https://www.youtube.com/watch?v=v5CcBVkmI6w&feature=youtu.be
\\ ( https://arxiv.org/abs/1906.10925 ,  799kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05047
replaced with revised version Sun, 14 Jul 2019 11:12:28 GMT   (402kb,D)

Title: BlazeFace: Sub-millisecond Neural Face Detection on Mobile GPUs
Authors: Valentin Bazarevsky, Yury Kartynnik, Andrey Vakunov, Karthik
  Raveendran, Matthias Grundmann
Categories: cs.CV
Comments: 4 pages, 3 figures; CVPR Workshop on Computer Vision for Augmented
  and Virtual Reality, Long Beach, CA, USA, 2019
\\ ( https://arxiv.org/abs/1907.05047 ,  402kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05272
replaced with revised version Sun, 14 Jul 2019 07:48:14 GMT   (680kb)

Title: Introduction to Camera Pose Estimation with Deep Learning
Authors: Yoli Shavit and Ron Ferens
Categories: cs.CV
\\ ( https://arxiv.org/abs/1907.05272 ,  680kb)
------------------------------------------------------------------------------
\\
arXiv:1802.04350
replaced with revised version Sat, 13 Jul 2019 20:34:57 GMT   (70kb,D)

Title: Cost-Aware Learning for Improved Identifiability with Multiple
  Experiments
Authors: Longyun Guo and Jean Honorio and John Morgan
Categories: cs.LG stat.ML
Comments: 17 pages, 4 figures
Journal-ref: IEEE International Symposium on Information Theory (ISIT) 2019
\\ ( https://arxiv.org/abs/1802.04350 ,  70kb)
------------------------------------------------------------------------------
\\
arXiv:1802.06266
replaced with revised version Sat, 13 Jul 2019 04:56:49 GMT   (1943kb,D)

Title: An analysis of training and generalization errors in shallow and deep
  networks
Authors: Hrushikesh Mhaskar, Tomaso Poggio
Categories: cs.LG cs.NA math.NA
Comments: 21 pages
\\ ( https://arxiv.org/abs/1802.06266 ,  1943kb)
------------------------------------------------------------------------------
\\
arXiv:1808.07018
replaced with revised version Mon, 15 Jul 2019 11:22:00 GMT   (220kb)

Title: Hypernetwork Knowledge Graph Embeddings
Authors: Ivana Bala\v{z}evi\'c, Carl Allen and Timothy M. Hospedales
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1808.07018 ,  220kb)
------------------------------------------------------------------------------
\\
arXiv:1810.00846
replaced with revised version Sat, 13 Jul 2019 12:16:18 GMT   (2228kb,D)

Title: Classification from Positive, Unlabeled and Biased Negative Data
Authors: Yu-Guan Hsieh, Gang Niu, Masashi Sugiyama
Categories: cs.LG stat.ML
Comments: In Proceedings of the 36th International Conference on Machine
  Learning (ICML 2019)
\\ ( https://arxiv.org/abs/1810.00846 ,  2228kb)
------------------------------------------------------------------------------
\\
arXiv:1811.06802
replaced with revised version Sun, 14 Jul 2019 14:05:30 GMT   (4072kb,D)

Title: PaccMann: Prediction of anticancer compound sensitivity with multi-modal
  attention-based neural networks
Authors: Ali Oskooei, Jannis Born, Matteo Manica, Vigneshwari Subramanian,
  Julio S\'aez-Rodr\'iguez, Mar\'ia Rodr\'iguez Mart\'inez
Categories: cs.LG q-bio.MN q-bio.QM
Comments: 10 pages, 5 figures, 2 tables. NIPS MLMM 2018
\\ ( https://arxiv.org/abs/1811.06802 ,  4072kb)
------------------------------------------------------------------------------
\\
arXiv:1812.02341
replaced with revised version Sun, 14 Jul 2019 17:49:51 GMT   (9465kb,D)

Title: Quantifying Generalization in Reinforcement Learning
Authors: Karl Cobbe, Oleg Klimov, Chris Hesse, Taehoon Kim, John Schulman
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1812.02341 ,  9465kb)
------------------------------------------------------------------------------
\\
arXiv:1903.06412
replaced with revised version Sun, 14 Jul 2019 14:38:10 GMT   (25kb)

Title: A Faster Algorithm Enumerating Relevant Features over Finite Fields
Authors: Mikito Nanashima
Categories: cs.LG cs.DS stat.ML
Comments: 23 pages
MSC-class: 68Q32
\\ ( https://arxiv.org/abs/1903.06412 ,  25kb)
------------------------------------------------------------------------------
\\
arXiv:1903.10572
replaced with revised version Sat, 13 Jul 2019 17:18:14 GMT   (319kb)

Title: On the Functional Equivalence of TSK Fuzzy Systems to Neural Networks,
  Mixture of Experts, CART, and Stacking Ensemble Regression
Authors: Dongrui Wu and Chin-Teng Lin and Jian Huang and Zhigang Zeng
Categories: cs.LG cs.AI stat.ML
\\ ( https://arxiv.org/abs/1903.10572 ,  319kb)
------------------------------------------------------------------------------
\\
arXiv:1904.01561
replaced with revised version Fri, 12 Jul 2019 23:11:43 GMT   (4070kb,AD)

Title: Are Learned Molecular Representations Ready For Prime Time?
Authors: Kevin Yang, Kyle Swanson, Wengong Jin, Connor Coley, Philipp Eiden,
  Hua Gao, Angel Guzman-Perez, Timothy Hopper, Brian Kelley, Miriam Mathea,
  Andrew Palmer, Volker Settels, Tommi Jaakkola, Klavs Jensen, Regina Barzilay
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1904.01561 ,  4070kb)
------------------------------------------------------------------------------
\\
arXiv:1904.08831
replaced with revised version Sun, 14 Jul 2019 19:03:37 GMT   (816kb,D)

Title: Neural-Attention-Based Deep Learning Architectures for Modeling Traffic
  Dynamics on Lane Graphs
Authors: Matthew A. Wright, Simon F. G. Ehlers, Roberto Horowitz
Categories: cs.LG cs.SY stat.ML
Comments: To appear at 2019 IEEE Conference on Intelligent Transportation
  Systems
\\ ( https://arxiv.org/abs/1904.08831 ,  816kb)
------------------------------------------------------------------------------
\\
arXiv:1904.11223
replaced with revised version Sun, 14 Jul 2019 14:00:55 GMT   (6240kb,D)

Title: Towards Explainable Anticancer Compound Sensitivity Prediction via
  Multimodal Attention-based Convolutional Encoders
Authors: Matteo Manica, Ali Oskooei, Jannis Born, Vigneshwari Subramanian,
  Julio S\'aez-Rodr\'iguez, Mar\'ia Rodr\'iguez Mart\'inez
Categories: cs.LG cs.AI q-bio.QM stat.ML
Comments: 11 pages, 5 figures, 1 table, Workshop on Computational Biology at
  the International Conference on Machine Learning (ICML), Long Beach, CA, 2019
\\ ( https://arxiv.org/abs/1904.11223 ,  6240kb)
------------------------------------------------------------------------------
\\
arXiv:1904.12857
replaced with revised version Mon, 15 Jul 2019 13:55:58 GMT   (1134kb,D)

Title: AutoCross: Automatic Feature Crossing for Tabular Data in Real-World
  Applications
Authors: Yuanfei Luo and Mengshuo Wang and Hao Zhou and Quanming Yao and WeiWei
  Tu and Yuqiang Chen and Qiang Yang and Wenyuan Dai
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1904.12857 ,  1134kb)
------------------------------------------------------------------------------
\\
arXiv:1905.01127
replaced with revised version Mon, 15 Jul 2019 16:32:10 GMT   (5091kb,D)

Title: Uncertainty-Aware Principal Component Analysis
Authors: Jochen G\"ortler, Thilo Spinner, Dirk Streeb, Daniel Weiskopf, Oliver
  Deussen
Categories: cs.LG cs.HC stat.ML
\\ ( https://arxiv.org/abs/1905.01127 ,  5091kb)
------------------------------------------------------------------------------
\\
arXiv:1905.05339
replaced with revised version Sat, 13 Jul 2019 02:53:23 GMT   (15kb)

Title: Adaptive Robust Optimization with Nearly Submodular Structure
Authors: Shaojie Tang and Jing Yuan
Categories: cs.LG math.OC
\\ ( https://arxiv.org/abs/1905.05339 ,  15kb)
------------------------------------------------------------------------------
\\
arXiv:1905.12418
replaced with revised version Sat, 13 Jul 2019 10:58:47 GMT   (4012kb,D)

Title: Probabilistically True and Tight Bounds for Robust Deep Neural Network
  Training
Authors: Salman Alsubaihi, Adel Bibi, Modar Alfadly and Bernard Ghanem
Categories: cs.LG cs.CR stat.ML
\\ ( https://arxiv.org/abs/1905.12418 ,  4012kb)
------------------------------------------------------------------------------
\\
arXiv:1906.00460
replaced with revised version Mon, 15 Jul 2019 10:12:08 GMT   (898kb,D)

Title: On The Radon--Nikodym Spectral Approach With Optimal Clustering
Authors: Vladislav Gennadievich Malyshkin
Categories: cs.LG cs.CV cs.NA math.NA stat.ML
Comments: Relation to PCA variation expansion is added. Whereas a regular PCA
  variation expansion depends on attributes normalizing, the PCA variation
  expansion in the Lebesgue quadrature arXiv:1807.06007 basis is unique thus
  does not depend on attributes scale, moreover it is invariant relatively any
  non-degenerated linear transform of input vector components. A model of the
  first order logic type is added
DOI: 10.2139/ssrn.3398755
\\ ( https://arxiv.org/abs/1906.00460 ,  898kb)
------------------------------------------------------------------------------
\\
arXiv:1906.10264
replaced with revised version Sun, 14 Jul 2019 07:48:36 GMT   (8389kb,D)

Title: Sequential Neural Processes
Authors: Gautam Singh, Jaesik Yoon, Youngsung Son, Sungjin Ahn
Categories: cs.LG stat.ML
Comments: First two authors contributed equally. 27 pages with appendix
  including experimental details
\\ ( https://arxiv.org/abs/1906.10264 ,  8389kb)
------------------------------------------------------------------------------
\\
arXiv:1907.02519
replaced with revised version Sat, 13 Jul 2019 21:34:19 GMT   (486kb,D)

Title: Neuron ranking -- an informed way to condense convolutional neural
  networks architecture
Authors: Kamil Adamczewski, Mijung Park
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1907.02519 ,  486kb)
------------------------------------------------------------------------------
\\
arXiv:1907.03215
replaced with revised version Sat, 13 Jul 2019 16:22:38 GMT   (306kb,D)

Title: Quantitative $W_1$ Convergence of Langevin-Like Stochastic Processes
  with Non-Convex Potential State-Dependent Noise
Authors: Xiang Cheng, Dong Yin, Peter L. Bartlett, Michael I. Jordan
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1907.03215 ,  306kb)
------------------------------------------------------------------------------
\\
arXiv:1907.03976
replaced with revised version Sat, 13 Jul 2019 01:11:51 GMT   (1384kb,D)

Title: Ranking-Based Reward Extrapolation without Rankings
Authors: Daniel S. Brown, Wonjoon Goo, and Scott Niekum
Categories: cs.LG stat.ML
\\ ( https://arxiv.org/abs/1907.03976 ,  1384kb)
------------------------------------------------------------------------------
\\
arXiv:1907.04201
replaced with revised version Mon, 15 Jul 2019 09:25:32 GMT   (368kb,D)

Title: Thompson Sampling for Combinatorial Network Optimization in Unknown
  Environments
Authors: Alihan H\"uy\"uk and Cem Tekin
Categories: cs.LG stat.ML
Comments: 14 pages, 3 figures. This work has been submitted to the IEEE for
  possible publication. arXiv admin note: substantial text overlap with
  arXiv:1809.02707
\\ ( https://arxiv.org/abs/1907.04201 ,  368kb)
------------------------------------------------------------------------------
\\
arXiv:1907.04964
replaced with revised version Mon, 15 Jul 2019 05:35:35 GMT   (817kb,D)

Title: A Model-based Approach for Sample-efficient Multi-task Reinforcement
  Learning
Authors: Nicholas C. Landolfi and Garrett Thomas and Tengyu Ma
Categories: cs.LG cs.AI stat.ML
Comments: 13 pages, 3 figures
\\ ( https://arxiv.org/abs/1907.04964 ,  817kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05813
replaced with revised version Mon, 15 Jul 2019 14:14:51 GMT   (2640kb,D)

Title: Automated Real-time Anomaly Detection in Human Trajectories using
  Sequence to Sequence Networks
Authors: Giorgos Bouritsas, Stelios Daveas, Antonios Danelakis, Constantinos
  Rizogiannis and Stelios C. A. Thomopoulos
Categories: cs.LG cs.CV eess.IV
Comments: AVSS 2019
\\ ( https://arxiv.org/abs/1907.05813 ,  2640kb)
------------------------------------------------------------------------------
\\
arXiv:1907.01549
replaced with revised version Mon, 15 Jul 2019 09:17:51 GMT   (312kb,D)

Title: Learning to Rank Broad and Narrow Queries in E-Commerce
Authors: Siddhartha Devapujula, Sagar Arora, Sumit Borar
Categories: cs.IR cs.CL cs.LG stat.ML
Comments: 7+1 pages
\\ ( https://arxiv.org/abs/1907.01549 ,  312kb)
------------------------------------------------------------------------------
\\
arXiv:1907.03950
replaced with revised version Mon, 15 Jul 2019 09:33:51 GMT   (7009kb,D)

Title: Learning by Abstraction: The Neural State Machine
Authors: Drew A. Hudson and Christopher D. Manning
Categories: cs.AI cs.CL cs.CV cs.LG
\\ ( https://arxiv.org/abs/1907.03950 ,  7009kb)
------------------------------------------------------------------------------
\\
arXiv:1906.03039
replaced with revised version Sun, 14 Jul 2019 04:33:23 GMT   (8154kb,D)

Title: Coherent Point Drift Networks: Unsupervised Learning of Non-Rigid Point
  Set Registration
Authors: Lingjing Wang, Xiang Li, Jianchun Chen and Yi Fang
Categories: cs.GR cs.CV
\\ ( https://arxiv.org/abs/1906.03039 ,  8154kb)
------------------------------------------------------------------------------
\\
arXiv:1906.05845 (*cross-listing*)
replaced with revised version Mon, 15 Jul 2019 11:24:37 GMT   (1878kb,D)

Title: Mask2Lesion: Mask-Constrained Adversarial Skin Lesion Image Synthesis
Authors: Kumar Abhishek, Ghassan Hamarneh
Categories: eess.IV cs.CV
Comments: 10 pages, 5 figures
\\ ( https://arxiv.org/abs/1906.05845 ,  1878kb)
------------------------------------------------------------------------------
\\
arXiv:1907.01262 (*cross-listing*)
replaced with revised version Fri, 12 Jul 2019 19:05:59 GMT   (1260kb)

Title: Dual Network Architecture for Few-view CT -- Trained on ImageNet Data
  and Transferred for Medical Imaging
Authors: Huidong Xie, Hongming Shan, Wenxiang Cong, Xiaohua Zhang, Shaohua Liu,
  Ruola Ning, Ge Wang
Categories: eess.IV cs.CV cs.LG
Comments: 9 pages, 4 figures, 5 tables
\\ ( https://arxiv.org/abs/1907.01262 ,  1260kb)
------------------------------------------------------------------------------
\\
arXiv:1907.04360
replaced with revised version Mon, 15 Jul 2019 13:20:59 GMT   (4160kb,D)

Title: Hybrid system identification using switching density networks
Authors: Michael Burke and Yordan Hristov and Subramanian Ramamoorthy
Categories: cs.RO cs.CV
\\ ( https://arxiv.org/abs/1907.04360 ,  4160kb)
------------------------------------------------------------------------------
\\
arXiv:1704.07971 (*cross-listing*)
replaced with revised version Sun, 14 Jul 2019 08:10:47 GMT   (141kb,D)

Title: A Flexible Framework for Hypothesis Testing in High-dimensions
Authors: Adel Javanmard and Jason D. Lee
Categories: math.ST cs.LG stat.AP stat.ME stat.ML stat.TH
Comments: 44 pages
\\ ( https://arxiv.org/abs/1704.07971 ,  141kb)
------------------------------------------------------------------------------
\\
arXiv:1803.00092
replaced with revised version Sat, 13 Jul 2019 10:39:04 GMT   (3612kb,D)

Title: NETT: Solving Inverse Problems with Deep Neural Networks
Authors: Housen Li, Johannes Schwab, Stephan Antholzer, Markus Haltmeier
Categories: math.NA cs.LG cs.NA
\\ ( https://arxiv.org/abs/1803.00092 ,  3612kb)
------------------------------------------------------------------------------
\\
arXiv:1804.10028 (*cross-listing*)
replaced with revised version Mon, 15 Jul 2019 07:38:13 GMT   (427kb,D)

Title: Decentralized learning with budgeted network load using Gaussian copulas
  and classifier ensembles
Authors: John Klein, Mahmoud Albardan, Benjamin Guedj and Olivier Colot
Categories: stat.ML cs.AI cs.DC cs.LG
\\ ( https://arxiv.org/abs/1804.10028 ,  427kb)
------------------------------------------------------------------------------
\\
arXiv:1806.01551 (*cross-listing*)
replaced with revised version Sat, 13 Jul 2019 09:44:42 GMT   (2821kb,D)

Title: Deep Mixed Effect Models using Gaussian Process: A Personalized and
  Reliable Prediction Model for Healthcare
Authors: Ingyo Chung, Saehoon Kim, Juho Lee, Kwang Joon Kim, Sung Ju Hwang,
  Eunho Yang
Categories: stat.ML cs.LG
\\ ( https://arxiv.org/abs/1806.01551 ,  2821kb)
------------------------------------------------------------------------------
\\
arXiv:1807.05207 (*cross-listing*)
replaced with revised version Mon, 15 Jul 2019 15:54:11 GMT   (8085kb,D)

Title: Parametric generation of conditional geological realizations using
  generative neural networks
Authors: Shing Chan and Ahmed H. Elsheikh
Categories: stat.ML cs.LG physics.comp-ph
Journal-ref: Computational Geosciences (2019)
DOI: 10.1007/s10596-019-09850-7
\\ ( https://arxiv.org/abs/1807.05207 ,  8085kb)
------------------------------------------------------------------------------
\\
arXiv:1807.05620
replaced with revised version Fri, 12 Jul 2019 18:47:26 GMT   (1989kb,D)

Title: NEUZZ: Efficient Fuzzing with Neural Program Smoothing
Authors: Dongdong She, Kexin Pei, Dave Epstein, Junfeng Yang, Baishakhi Ray,
  Suman Jana
Categories: cs.CR cs.LG
Comments: To appear in the 40th IEEE Symposium on Security and Privacy, May
  20--22, 2019, San Francisco, CA, USA
\\ ( https://arxiv.org/abs/1807.05620 ,  1989kb)
------------------------------------------------------------------------------
\\
arXiv:1809.10482 (*cross-listing*)
replaced with revised version Mon, 15 Jul 2019 16:22:06 GMT   (2520kb,D)

Title: Budgeted Multi-Objective Optimization with a Focus on the Central Part
  of the Pareto Front -- Extended Version
Authors: David Gaudrie and Rodolphe Le Riche and Victor Picheny and Benoit
  Enaux and Vincent Herbert
Categories: stat.ML cs.LG math.OC
Comments: Submission pre-print, extended version
\\ ( https://arxiv.org/abs/1809.10482 ,  2520kb)
------------------------------------------------------------------------------
\\
arXiv:1810.05369 (*cross-listing*)
replaced with revised version Mon, 15 Jul 2019 06:33:39 GMT   (687kb,D)

Title: Regularization Matters: Generalization and Optimization of Neural Nets
  v.s. their Induced Kernel
Authors: Colin Wei, Jason D. Lee, Qiang Liu, Tengyu Ma
Categories: stat.ML cs.LG
Comments: version 2: title changed from originally "On the Margin Theory of
  Feedforward Neural Networks". Substantial changes from old version of paper,
  including a new lower bound on NTK sample complexity version 3: reorganized
  NTK lower bound proof
\\ ( https://arxiv.org/abs/1810.05369 ,  687kb)
------------------------------------------------------------------------------
\\
arXiv:1811.08284 (*cross-listing*)
replaced with revised version Sat, 13 Jul 2019 01:58:31 GMT   (206kb,D)

Title: Feature exploration for almost zero-resource ASR-free keyword spotting
  using a multilingual bottleneck extractor and correspondence autoencoders
Authors: Raghav Menon, Herman Kamper, Ewald van der Westhuizen, John Quinn,
  Thomas Niesler
Categories: eess.AS cs.LG cs.SD stat.ML
Comments: 5 pages, 2 figures, 2 tables, 38 references, Accepted at Interspeech
  2019
\\ ( https://arxiv.org/abs/1811.08284 ,  206kb)
------------------------------------------------------------------------------
\\
arXiv:1812.06598
replaced with revised version Mon, 15 Jul 2019 14:31:52 GMT   (5833kb,D)

Title: Community structure: A comparative evaluation of community detection
  methods
Authors: Vinh-Loc Dao, C\'ecile Bothorel, Philippe Lenca
Categories: cs.SI cs.LG stat.ML
Comments: This version has been submitted to the Network Science journal
  (http://journals.cambridge.org/NWS)
\\ ( https://arxiv.org/abs/1812.06598 ,  5833kb)
------------------------------------------------------------------------------
\\
arXiv:1901.06811
replaced with revised version Sat, 13 Jul 2019 00:49:41 GMT   (881kb,D)

Title: Straggler Resilient Serverless Computing Based on Polar Codes
Authors: Burak Bartan, Mert Pilanci
Categories: cs.IT cs.DC cs.LG math.IT
Comments: New results added in the new version. More discussion on serverless
  computing
\\ ( https://arxiv.org/abs/1901.06811 ,  881kb)
------------------------------------------------------------------------------
\\
arXiv:1901.08974 (*cross-listing*)
replaced with revised version Fri, 12 Jul 2019 20:20:43 GMT   (669kb,D)

Title: Rescaling and other forms of unsupervised preprocessing introduce bias
  into cross-validation
Authors: Amit Moscovich, Saharon Rosset
Categories: stat.ME cs.LG stat.ML
MSC-class: 62-07
ACM-class: G.3
\\ ( https://arxiv.org/abs/1901.08974 ,  669kb)
------------------------------------------------------------------------------
\\
arXiv:1902.01724
replaced with revised version Sun, 14 Jul 2019 16:16:44 GMT   (43kb)

Title: AlphaStar: An Evolutionary Computation Perspective
Authors: Kai Arulkumaran, Antoine Cully, Julian Togelius
Categories: cs.NE cs.AI cs.LG
Comments: Genetic and EvolutionaryComputation Conference Companion 2019
DOI: 10.1145/3319619.3321894
\\ ( https://arxiv.org/abs/1902.01724 ,  43kb)
------------------------------------------------------------------------------
\\
arXiv:1904.00943
replaced with revised version Sun, 14 Jul 2019 05:16:58 GMT   (50kb)

Title: Distributed Metropolis Sampler with Optimal Parallelism
Authors: Weiming Feng, Thomas P. Hayes, Yitong Yin
Categories: cs.DS cs.LG
\\ ( https://arxiv.org/abs/1904.00943 ,  50kb)
------------------------------------------------------------------------------
\\
arXiv:1904.03796
replaced with revised version Sun, 14 Jul 2019 03:23:20 GMT   (2256kb,D)

Title: Minimum Enclosing Ball Revisited: Stability, Sub-linear Time Algorithms,
  and Extension
Authors: Hu Ding
Categories: cs.CG cs.LG
\\ ( https://arxiv.org/abs/1904.03796 ,  2256kb)
------------------------------------------------------------------------------
\\
arXiv:1904.12225
replaced with revised version Sat, 13 Jul 2019 23:44:11 GMT   (12842kb,D)

Title: A Deep Generative Model for Graph Layout
Authors: Oh-Hyun Kwon and Kwan-Liu Ma
Categories: cs.SI cs.GR cs.HC cs.LG stat.ML
Comments: To appear in IEEE Transactions on Visualization and Computer Graphics
  and IEEE VIS 2019 (InfoVis)
\\ ( https://arxiv.org/abs/1904.12225 ,  12842kb)
------------------------------------------------------------------------------
\\
arXiv:1904.13247
replaced with revised version Sun, 14 Jul 2019 18:17:34 GMT   (433kb)

Title: Online Causal Structure Learning in the Presence of Latent Variables
Authors: Durdane Kocacoban, James Cussens
Categories: cs.AI cs.LG stat.ML
Comments: 16 pages, 9 figures, 2 tables
\\ ( https://arxiv.org/abs/1904.13247 ,  433kb)
------------------------------------------------------------------------------
\\
arXiv:1905.07866
replaced with revised version Mon, 15 Jul 2019 06:44:33 GMT   (4190kb,D)

Title: Reinforcement Learning without Ground-Truth State
Authors: Xingyu Lin, Harjatin Singh Baweja and David Held
Categories: cs.RO cs.LG
\\ ( https://arxiv.org/abs/1905.07866 ,  4190kb)
------------------------------------------------------------------------------
\\
arXiv:1905.12363 (*cross-listing*)
replaced with revised version Mon, 15 Jul 2019 15:06:01 GMT   (2147kb,D)

Title: Extra-gradient with player sampling for provable fast convergence in
  n-player games
Authors: Samy Jelassi, Carles Domingo Enrich, Damien Scieur, Arthur Mensch,
  Joan Bruna
Categories: stat.ML cs.LG math.OC
\\ ( https://arxiv.org/abs/1905.12363 ,  2147kb)
------------------------------------------------------------------------------
\\
arXiv:1906.02975
replaced with revised version Sun, 14 Jul 2019 23:05:39 GMT   (356kb,D)

Title: Audio tagging with noisy labels and minimal supervision
Authors: Eduardo Fonseca, Manoj Plakal, Frederic Font, Daniel P. W. Ellis and
  Xavier Serra
Categories: cs.SD cs.LG eess.AS stat.ML
Comments: submitted to DCASE2019 Workshop
\\ ( https://arxiv.org/abs/1906.02975 ,  356kb)
------------------------------------------------------------------------------
\\
arXiv:1906.03417
replaced with revised version Sat, 13 Jul 2019 20:38:21 GMT   (3139kb)

Title: Class-specific Differential Detection in Diffractive Optical Neural
  Networks Improves Inference Accuracy
Authors: Jingxi Li, Deniz Mengu, Yi Luo, Yair Rivenson, Aydogan Ozcan
Categories: cs.NE cs.LG eess.IV physics.optics
Comments: 21 pages, 6 Figures, 3 Tables
\\ ( https://arxiv.org/abs/1906.03417 ,  3139kb)
------------------------------------------------------------------------------
\\
arXiv:1907.00269
replaced with revised version Sat, 13 Jul 2019 15:47:36 GMT   (1831kb,D)

Title: On Training Flexible Robots using Deep Reinforcement Learning
Authors: Zach Dwiel, Madhavun Candadai, Mariano Phielipp
Categories: cs.RO cs.AI cs.LG
Comments: Accepted at the Intelligent Robots and Systems (IRoS) conference,
  2019. Camera-ready version coming soon
\\ ( https://arxiv.org/abs/1907.00269 ,  1831kb)
------------------------------------------------------------------------------
\\
arXiv:1907.04699 (*cross-listing*)
replaced with revised version Sat, 13 Jul 2019 08:04:10 GMT   (2180kb)

Title: Generalized Rank Minimization based Group Sparse Coding for Low-level
  Image Restoration via Dictionary Learning
Authors: Yunyi Li, Guan Gui, Xiefeng Cheng
Categories: eess.IV cs.LG eess.SP
\\ ( https://arxiv.org/abs/1907.04699 ,  2180kb)
------------------------------------------------------------------------------
\\
arXiv:1907.05579
replaced with revised version Mon, 15 Jul 2019 03:15:19 GMT   (631kb,D)

Title: Learning a Static Bug Finder from Data
Authors: Yu Wang, Fengjuan Gao, Linzhang Wang, Ke Wang
Categories: cs.SE cs.LG
\\ ( https://arxiv.org/abs/1907.05579 ,  631kb)
%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---%%%---
