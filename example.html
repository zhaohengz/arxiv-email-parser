<h1><a href="https://arxiv.org/abs/1907.06679">Towards Near-imperceptible Steganographic Text </a></h1>
<h3>Authors: Falcon Z. Dai, Zheng Cai</h3>
<h3>Categories: cs.CL cs.CR cs.LG</h3>
<h3>Comments: To appear at ACL 2019. Code available</h3>
<hr />
<p>We show that the imperceptibility of several existing linguistic
steganographic systems (Fang et al., 2017; Yang et al., 2018) relies on
implicit assumptions on statistical behaviors of fluent text. We formally
analyze them and empirically evaluate these assumptions. Furthermore, based on
these observations, we propose an encoding algorithm called patient-Huffman
with improved near-imperceptible guarantees.</p>
<h1><a href="https://arxiv.org/abs/1907.06745">Low-supervision urgency detection and transfer in short crisis messages </a></h1>
<h3>Authors: Mayank Kejriwal and Peilin Zhou</h3>
<h3>Categories: cs.CL cs.LG cs.SI</h3>
<h3>Comments: 8 pages, short version published in ASONAM 2019</h3>
<hr />
<p>Humanitarian disasters have been on the rise in recent years due to the
effects of climate change and socio-political situations such as the refugee
crisis. Technology can be used to best mobilize resources such as food and
water in the event of a natural disaster, by semi-automatically flagging tweets
and short messages as indicating an urgent need. The problem is challenging not
just because of the sparseness of data in the immediate aftermath of a
disaster, but because of the varying characteristics of disasters in developing
countries (making it difficult to train just one system) and the noise and
quirks in social media. In this paper, we present a robust, low-supervision
social media urgency system that adapts to arbitrary crises by leveraging both
labeled and unlabeled data in an ensemble setting. The system is also able to
adapt to new crises where an unlabeled background corpus may not be available
yet by utilizing a simple and effective transfer learning methodology.
Experimentally, our transfer learning and low-supervision approaches are found
to outperform viable baselines with high significance on myriad disaster
datasets.</p>
<h1><a href="https://arxiv.org/abs/1907.06860">A generic rule-based system for clinical trial patient selection </a></h1>
<h3>Authors: Jianlin Shi, Kevin Graves, John F. Hurdle</h3>
<h3>Categories: cs.CL cs.CY</h3>
<hr />
<p>The n2c2 2018 Challenge task 1 aimed to identify patients who meet lists of
heterogeneous inclusion/exclusion criteria for a hypothetical clinical trial.
We demonstrate a generic rule-based natural language pipeline can support this
task with decent performance (the average F1 score on the test set is 0.89,
ranked the 8th out of 45 teams ).</p>
<h1><a href="https://arxiv.org/abs/1907.06944">Language comparison via network topology </a></h1>
<h3>Authors: Bla\v{z} \v{S}krlj and Senja Pollak</h3>
<h3>Categories: cs.CL</h3>
<hr />
<p>Modeling relations between languages can offer understanding of language
characteristics and uncover similarities and differences between languages.
Automated methods applied to large textual corpora can be seen as opportunities
for novel statistical studies of language development over time, as well as for
improving cross-lingual natural language processing techniques. In this work,
we first propose how to represent textual data as a directed, weighted network
by the text2net algorithm. We next explore how various fast,
network-topological metrics, such as network community structure, can be used
for cross-lingual comparisons. In our experiments, we employ eight different
network topology metrics, and empirically showcase on a parallel corpus, how
the methods can be used for modeling the relations between nine selected
languages. We demonstrate that the proposed method scales to large corpora
consisting of hundreds of thousands of aligned sentences on an of-the-shelf
laptop. We observe that on the one hand properties such as communities, capture
some of the known differences between the languages, while others can be seen
as novel opportunities for linguistic studies.</p>
<h1><a href="https://arxiv.org/abs/1907.07033">Neural Language Model Based Training Data Augmentation for Weakly Supervised Early Rumor Detection </a></h1>
<h3>Authors: Sooji Han, Jie Gao, Fabio Ciravegna</h3>
<h3>Categories: cs.CL cs.LG</h3>
<h3>Comments: 8 pages</h3>
<hr />
<p>The scarcity and class imbalance of training data are known issues in current
rumor detection tasks. We propose a straight-forward and general-purpose data
augmentation technique which is beneficial to early rumor detection relying on
event propagation patterns. The key idea is to exploit massive unlabeled event
data sets on social media to augment limited labeled rumor source tweets. This
work is based on rumor spreading patterns revealed by recent rumor studies and
semantic relatedness between labeled and unlabeled data. A state-of-the-art
neural language model (NLM) and large credibility-focused Twitter corpora are
employed to learn context-sensitive representations of rumor tweets. Six
different real-world events based on three publicly available rumor datasets
are employed in our experiments to provide a comparative evaluation of the
effectiveness of the method. The results show that our method can expand the
size of an existing rumor data set nearly by 200% and corresponding social
context (i.e., conversational threads) by 100% with reasonable quality.
Preliminary experiments with a state-of-the-art deep learning-based rumor
detection model show that augmented data can alleviate over-fitting and class
imbalance caused by limited train data and can help to train complex neural
networks (NNs). With augmented data, the performance of rumor detection can be
improved by 12.1% in terms of F-score. Our experiments also indicate that
augmented training data can help to generalize rumor detection models on unseen
rumors.</p>
<h1><a href="https://arxiv.org/abs/1907.07073">RadioTalk: a large-scale corpus of talk radio transcripts </a></h1>
<h3>Authors: Doug Beeferman, William Brannon and Deb Roy</h3>
<h3>Categories: cs.CL</h3>
<h3>Comments: 5 pages, 4 figures, accepted by Interspeech 2019</h3>
<hr />
<p>We introduce RadioTalk, a corpus of speech recognition transcripts sampled
from talk radio broadcasts in the United States between October of 2018 and
March of 2019. The corpus is intended for use by researchers in the fields of
natural language processing, conversational analysis, and the social sciences.
The corpus encompasses approximately 2.8 billion words of automatically
transcribed speech from 284,000 hours of radio, together with metadata about
the speech, such as geographical location, speaker turn boundaries, gender, and
radio program information. In this paper we summarize why and how we prepared
the corpus, give some descriptive statistics on stations, shows and speakers,
and carry out a few high-level analyses.</p>
<h1><a href="https://arxiv.org/abs/1907.06670">Slow Feature Analysis for Human Action Recognition </a></h1>
<h3>Authors: Zhang Zhang and Dacheng Tao</h3>
<h3>Categories: cs.CV</h3>
<hr />
<p>Slow Feature Analysis (SFA) extracts slowly varying features from a quickly
varying input signal. It has been successfully applied to modeling the visual
receptive fields of the cortical neurons. Sufficient experimental results in
neuroscience suggest that the temporal slowness principle is a general learning
principle in visual perception. In this paper, we introduce the SFA framework
to the problem of human action recognition by incorporating the discriminative
information with SFA learning and considering the spatial relationship of body
parts. In particular, we consider four kinds of SFA learning strategies,
including the original unsupervised SFA (U-SFA), the supervised SFA (S-SFA),
the discriminative SFA (D-SFA), and the spatial discriminative SFA (SD-SFA), to
extract slow feature functions from a large amount of training cuboids which
are obtained by random sampling in motion boundaries. Afterward, to represent
action sequences, the squared first order temporal derivatives are accumulated
over all transformed cuboids into one feature vector, which is termed the
Accumulated Squared Derivative (ASD) feature. The ASD feature encodes the
statistical distribution of slow features in an action sequence. Finally, a
linear support vector machine (SVM) is trained to classify actions represented
by ASD features. We conduct extensive experiments, including two sets of
control experiments, two sets of large scale experiments on the KTH and
Weizmann databases, and two sets of experiments on the CASIA and UT-interaction
databases, to demonstrate the effectiveness of SFA for human action
recognition.</p>
<h1><a href="https://arxiv.org/abs/1907.06713">MaskPlus: Improving Mask Generation for Instance Segmentation </a></h1>
<h3>Authors: Shichao Xu, Shuyue Lan, Qi Zhu</h3>
<h3>Categories: cs.CV</h3>
<hr />
<p>Instance segmentation is a promising yet challenging topic in computer
vision. Recent approaches such as Mask R-CNN typically divide this problem into
two parts -- a detection component and a mask generation branch, and mostly
focus on the improvement of the detection part. In this paper, we present an
approach that extends Mask R-CNN with five novel optimization techniques for
improving the mask generation branch and reducing the conflicts between the
mask branch and the detection component in training. These five techniques are
independent to each other and can be flexibly utilized in building various
instance segmentation architectures for increasing the overall accuracy. We
demonstrate the effectiveness of our approach with tests on the COCO dataset.</p>
<h1><a href="https://arxiv.org/abs/1907.06724">Real-time Facial Surface Geometry from Monocular Video on Mobile GPUs </a></h1>
<h3>Authors: Yury Kartynnik, Artsiom Ablavatski, Ivan Grishchenko, Matthias Grundmann</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: 4 pages, 4 figures; CVPR Workshop on Computer Vision for Augmented and Virtual Reality, Long Beach, CA, USA, 2019</h3>
<hr />
<p>We present an end-to-end neural network-based model for inferring an
approximate 3D mesh representation of a human face from single camera input for
AR applications. The relatively dense mesh model of 468 vertices is well-suited
for face-based AR effects. The proposed model demonstrates super-realtime
inference speed on mobile GPUs (100-1000+ FPS, depending on the device and
model variant) and a high prediction quality that is comparable to the variance
in manual annotations of the same image.</p>
<h1><a href="https://arxiv.org/abs/1907.06740">Real-time Hair Segmentation and Recoloring on Mobile GPUs </a></h1>
<h3>Authors: Andrei Tkachenka, Gregory Karpiak, Andrey Vakunov, Yury Kartynnik, Artsiom Ablavatski, Valentin Bazarevsky, Siargey Pisarchyk</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: 4 pages, 5 figures; CVPR Workshop on Computer Vision for Augmented and Virtual Reality, Long Beach, CA, USA, 2019</h3>
<hr />
<p>We present a novel approach for neural network-based hair segmentation from a
single camera input specifically designed for real-time, mobile application.
Our relatively small neural network produces a high-quality hair segmentation
mask that is well suited for AR effects, e.g. virtual hair recoloring. The
proposed model achieves real-time inference speed on mobile GPUs (30-100+ FPS,
depending on the device) with high accuracy. We also propose a very realistic
hair recoloring scheme. Our method has been deployed in major AR application
and is used by millions of users.</p>
<h1><a href="https://arxiv.org/abs/1907.06757">AugLabel: Exploiting Word Representations to Augment Labels for Face Attribute Classification </a></h1>
<h3>Authors: Binod Bhattarai, Rumeysa Bodur, Tae-Kyun Kim</h3>
<h3>Categories: cs.CV</h3>
<hr />
<p>Augmenting data in image space (eg. flipping, cropping etc) and activation
space (eg. dropout) are being widely used to regularise deep neural networks
and have been successfully applied on several computer vision tasks. Unlike
previous works, which are mostly focused on doing augmentation in the
aforementioned domains, we propose to do augmentation in label space. In this
paper, we present a novel method to generate fixed dimensional labels with
continuous values for images by exploiting the word2vec representations of the
existing categorical labels. We then append these representations with existing
categorical labels and train the model. We validated our idea on two
challenging face attribute classification data sets viz. CelebA and LFWA. Our
extensive experiments show that the augmented labels improve the performance of
the competitive deep learning baseline and reduce the need of annotated real
data up to 50%, while attaining a performance similar to the state-of-the-art
methods.</p>
<h1><a href="https://arxiv.org/abs/1907.06772">Efficient Pipeline for Camera Trap Image Review </a></h1>
<h3>Authors: Sara Beery, Dan Morris, Siyu Yang</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: From the Data Mining and AI for Conservation Workshop at KDD19</h3>
<hr />
<p>Biologists all over the world use camera traps to monitor biodiversity and
wildlife population density. The computer vision community has been making
strides towards automating the species classification challenge in camera
traps, but it has proven difficult to to apply models trained in one region to
images collected in different geographic areas. In some cases, accuracy falls
off catastrophically in new region, due to both changes in background and the
presence of previously-unseen species. We propose a pipeline that takes
advantage of a pre-trained general animal detector and a smaller set of labeled
images to train a classification model that can efficiently achieve accurate
results in a new region.</p>
<h1><a href="https://arxiv.org/abs/1907.06777">Improving 3D Object Detection for Pedestrians with Virtual Multi-View Synthesis Orientation Estimation </a></h1>
<h3>Authors: Jason Ku, Alex D. Pon, Sean Walsh, and Steven L. Waslander</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: Accepted in IROS 2019</h3>
<hr />
<p>Accurately estimating the orientation of pedestrians is an important and
challenging task for autonomous driving because this information is essential
for tracking and predicting pedestrian behavior. This paper presents a flexible
Virtual Multi-View Synthesis module that can be adopted into 3D object
detection methods to improve orientation estimation. The module uses a
multi-step process to acquire the fine-grained semantic information required
for accurate orientation estimation. First, the scene's point cloud is
densified using a structure preserving depth completion algorithm and each
point is colorized using its corresponding RGB pixel. Next, virtual cameras are
placed around each object in the densified point cloud to generate novel
viewpoints, which preserve the object's appearance. We show that this module
greatly improves the orientation estimation on the challenging pedestrian class
on the KITTI benchmark. When used with the open-source 3D detector AVOD-FPN, we
outperform all other published methods on the pedestrian Orientation, 3D, and
Bird's Eye View benchmarks.</p>
<h1><a href="https://arxiv.org/abs/1907.06781">Rethinking RGB-D Salient Object Detection: Models, Datasets, and Large-Scale Benchmarks </a></h1>
<h3>Authors: Deng-Ping Fan, Zheng Lin, Jia-Xing Zhao, Yun Liu, Zhao Zhang, Qibin Hou, Menglong Zhu, Ming-Ming Cheng</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: 15 pages</h3>
<hr />
<p>The use of RGB-D information for salient object detection has been explored
in recent years. However, relatively few efforts have been spent in modeling
salient object detection over real-world human activity scenes with RGB-D. In
this work, we fill the gap by making the following contributions to RGB-D
salient object detection. First, we carefully collect a new salient person
(SIP) dataset, which consists of 1K high-resolution images that cover diverse
real-world scenes from various viewpoints, poses, occlusion, illumination, and
background. Second, we conduct a large-scale and so far the most comprehensive
benchmark comparing contemporary methods, which has long been missing in the
area and can serve as a baseline for future research. We systematically
summarized 31 popular models, evaluated 17 state-of-the-art methods over seven
datasets with totally about 91K images. Third, we propose a simple baseline
architecture, called Deep Depth-Depurator Network (D3Net). It consists of a
depth depurator unit and a feature learning module, performing initial
low-quality depth map filtering and cross-modal feature learning respectively.
These components form a nested structure and are elaborately designed to be
learned jointly. D3Net exceeds the performance of any prior contenders across
five metrics considered, thus serves as a strong baseline to advance the
research frontier. We also demonstrate that D3Net can be used to efficiently
extract salient person masks from the real scenes, enabling effective
background changed book cover application with 20 fps on a single GPU. All the
saliency maps, our new SIP dataset, baseline model, and evaluation tools are
made publicly available at https://github.com/DengPingFan/D3NetBenchmark.</p>
<h1><a href="https://arxiv.org/abs/1907.06794">2nd Place Solution to the GQA Challenge 2019 </a></h1>
<h3>Authors: Shijie Geng and Ji Zhang and Hang Zhang and Ahmed Elgammal and Dimitris N. Metaxas</h3>
<h3>Categories: cs.CV</h3>
<hr />
<p>We present a simple method that achieves unexpectedly superior performance
for Complex Reasoning involved Visual Question Answering. Our solution collects
statistical features from high-frequency words of all the questions asked about
an image and use them as accurate knowledge for answering further questions of
the same image. We are fully aware that this setting is not ubiquitously
applicable, and in a more common setting one should assume the questions are
asked separately and they cannot be gathered to obtain a knowledge base.
Nonetheless, we use this method as an evidence to demonstrate our observation
that the bottleneck effect is more severe on the feature extraction part than
it is on the knowledge reasoning part. We show significant gaps when using the
same reasoning model with 1) ground-truth features; 2) statistical features; 3)
detected features from completely learned detectors, and analyze what these
gaps mean to researches on visual reasoning topics. Our model with the
statistical features achieves the 2nd place in the GQA Challenge 2019.</p>
<h1><a href="https://arxiv.org/abs/1907.06796">Instant Motion Tracking and Its Applications to Augmented Reality </a></h1>
<h3>Authors: Jianing Wei, Genzhi Ye, Tyler Mullen, Matthias Grundmann, Adel Ahmadyan, Tingbo Hou</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: CVPR Workshop on Computer Vision for Augmented and Virtual Reality, Long Beach, CA, 2019</h3>
<hr />
<p>Augmented Reality (AR) brings immersive experiences to users. With recent
advances in computer vision and mobile computing, AR has scaled across
platforms, and has increased adoption in major products. One of the key
challenges in enabling AR features is proper anchoring of the virtual content
to the real world, a process referred to as tracking. In this paper, we present
a system for motion tracking, which is capable of robustly tracking planar
targets and performing relative-scale 6DoF tracking without calibration. Our
system runs in real-time on mobile phones and has been deployed in multiple
major products on hundreds of millions of devices.</p>
<h1><a href="https://arxiv.org/abs/1907.06823">Stereo-based terrain traversability analysis using normal-based segmentation and superpixel surface analysis </a></h1>
<h3>Authors: Aras R. Dargazany</h3>
<h3>Categories: cs.CV cs.RO eess.IV</h3>
<hr />
<p>In this paper, an stereo-based traversability analysis approach for all
terrains in off-road mobile robotics, e.g. Unmanned Ground Vehicles (UGVs) is
proposed. This approach reformulates the problem of terrain traversability
analysis into two main problems: (1) 3D terrain reconstruction and (2) terrain
all surfaces detection and analysis. The proposed approach is using stereo
camera for perception and 3D reconstruction of the terrain. In order to detect
all the existing surfaces in the 3D reconstructed terrain as superpixel
surfaces (i.e. segments), an image segmentation technique is applied using
geometry-based features (pixel-based surface normals). Having detected all the
surfaces, Superpixel Surface Traversability Analysis approach (SSTA) is applied
on all of the detected surfaces (superpixel segments) in order to classify them
based on their traversability index. The proposed SSTA approach is based on:
(1) Superpixel surface normal and plane estimation, (2) Traversability analysis
using superpixel surface planes. Having analyzed all the superpixel surfaces
based on their traversability, these surfaces are finally classified into five
main categories as following: traversable, semi-traversable, non-traversable,
unknown and undecided.</p>
<h1><a href="https://arxiv.org/abs/1907.06844">Deep inspection: an electrical distribution pole parts study via deep neural networks </a></h1>
<h3>Authors: Liangchen Liu, Teng Zhang, Kun Zhao, Arnold Wiliem, Kieren Astin-Walmsley, Brian Lovell</h3>
<h3>Categories: cs.CV eess.IV</h3>
<h3>Comments: electrical distribution pole inspection, integrated inspection system, object detection, imbalanced data classification, To appear in Proceeding of ICIP 2019</h3>
<hr />
<p>Electrical distribution poles are important assets in electricity supply.
These poles need to be maintained in good condition to ensure they protect
community safety, maintain reliability of supply, and meet legislative
obligations. However, maintaining such a large volumes of assets is an
expensive and challenging task. To address this, recent approaches utilise
imagery data captured from helicopter and/or drone inspections. Whilst reducing
the cost for manual inspection, manual analysis on each image is still
required. As such, several image-based automated inspection systems have been
proposed. In this paper, we target two major challenges: tiny object detection
and extremely imbalanced datasets, which currently hinder the wide deployment
of the automatic inspection. We propose a novel two-stage zoom-in detection
method to gradually focus on the object of interest. To address the imbalanced
dataset problem, we propose the resampling as well as reweighting schemes to
iteratively adapt the model to the large intra-class variation of major class
and balance the contributions to the loss from each class. Finally, we
integrate these components together and devise a novel automatic inspection
framework. Extensive experiments demonstrate that our proposed approaches are
effective and can boost the performance compared to the baseline methods.</p>
<h1><a href="https://arxiv.org/abs/1907.06876">Separable Convolutional LSTMs for Faster Video Segmentation </a></h1>
<h3>Authors: Andreas Pfeuffer and Klaus Dietmayer</h3>
<h3>Categories: cs.CV eess.IV</h3>
<hr />
<p>Semantic Segmentation is an important module for autonomous robots such as
self-driving cars. The advantage of video segmentation approaches compared to
single image segmentation is that temporal image information is considered, and
their performance increases due to this. Hence, single image segmentation
approaches are extended by recurrent units such as convolutional LSTM
(convLSTM) cells, which are placed at suitable positions in the basic network
architecture. However, a major critique of video segmentation approaches based
on recurrent neural networks is their large parameter count and their
computational complexity, and so, their inference time of one video frame takes
up to 66 percent longer than their basic version. Inspired by the success of
the spatial and depthwise separable convolutional neural networks, we
generalize these techniques for convLSTMs in this work, so that the number of
parameters and the required FLOPs are reduced significantly. Experiments on
different datasets show that the segmentation approaches using the proposed,
modified convLSTM cells achieve similar or slightly worse accuracy, but are up
to 15 percent faster on a GPU than the ones using the standard convLSTM cells.
Furthermore, a new evaluation metric is introduced, which measures the amount
of flickering pixels in the segmented video sequence.</p>
<h1><a href="https://arxiv.org/abs/1907.06881">Cascade RetinaNet: Maintaining Consistency for Single-Stage Object Detection </a></h1>
<h3>Authors: Hongkai Zhang, Hong Chang, Bingpeng Ma, Shiguang Shan, Xilin Chen</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: BMVC 2019</h3>
<hr />
<p>Recent researches attempt to improve the detection performance by adopting
the idea of cascade for single-stage detectors. In this paper, we analyze and
discover that inconsistency is the major factor limiting the performance. The
refined anchors are associated with the feature extracted from the previous
location and the classifier is confused by misaligned classification and
localization. Further, we point out two main designing rules for the cascade
manner: improving consistency between classification confidence and
localization performance, and maintaining feature consistency between different
stages. A multistage object detector named Cas-RetinaNet, is then proposed for
reducing the misalignments. It consists of sequential stages trained with
increasing IoU thresholds for improving the correlation, and a novel Feature
Consistency Module for mitigating the feature inconsistency. Experiments show
that our proposed Cas-RetinaNet achieves stable performance gains across
different models and input scales. Specifically, our method improves RetinaNet
from 39.1 AP to 41.1 AP on the challenging MS COCO dataset without any bells or
whistles.</p>
<h1><a href="https://arxiv.org/abs/1907.06882">Learning Depth from Monocular Videos Using Synthetic Data: A Temporally-Consistent Domain Adaptation Approach </a></h1>
<h3>Authors: Yipeng Mou, Mingming Gong, Huan Fu, Kayhan Batmanghelich, Kun Zhang, Dacheng Tao</h3>
<h3>Categories: cs.CV</h3>
<hr />
<p>Majority of state-of-the-art monocular depth estimation methods are
supervised learning approaches. The success of such approaches heavily depends
on the high-quality depth labels which are expensive to obtain. Recent methods
try to learn depth networks by exploring unsupervised cues from monocular
videos which are easier to acquire but less reliable. In this paper, we propose
to resolve this dilemma by transferring knowledge from synthetic videos with
easily obtainable ground truth depth labels. Due to the stylish difference
between synthetic and real images, we propose a temporally-consistent domain
adaptation (TCDA) approach that simultaneously explores labels in the synthetic
domain and temporal constraints in the videos to improve style transfer and
depth prediction. Furthermore, we make use of the ground truth optical flow and
pose information in the synthetic data to learn moving mask and pose prediction
networks. The learned moving masks can filter out moving regions that produces
erroneous temporal constraints and the estimated poses provide better
initializations for estimating temporal constraints. The experimental results
demonstrate the effectiveness of our method and comparable performance against
state-of-the-art.</p>
<h1><a href="https://arxiv.org/abs/1907.06890">A General Framework for Uncertainty Estimation in Deep Learning </a></h1>
<h3>Authors: Mattia Seg`u, Antonio Loquercio, Davide Scaramuzza</h3>
<h3>Categories: cs.CV stat.ML</h3>
<hr />
<p>End-to-end learning has recently emerged as a promising technique to tackle
the problem of autonomous driving. Existing works show that learning a
navigation policy from raw sensor data may reduce the system's reliance on
external sensing systems, (e.g. GPS), and/or outperform traditional methods
based on state estimation and planning. However, existing end-to-end methods
generally trade off performance for safety, hindering their diffusion to
real-life applications. For example, when confronted with an input which is
radically different from the training data, end-to-end autonomous driving
systems are likely to fail, compromising the safety of the vehicle. To detect
such failure cases, this work proposes a general framework for uncertainty
estimation which enables a policy trained end-to-end to predict not only action
commands, but also a confidence about its own predictions. In contrast to
previous works, our framework can be applied to any existing neural network and
task, without the need to change the network's architecture or loss, or to
train the network. In order to do so, we generate confidence levels by forward
propagation of input and model uncertainties using Bayesian inference. We test
our framework on the task of steering angle regression for an autonomous car,
and compare our approach to existing methods with both qualitative and
quantitative results on a real dataset. Finally, we show an interesting
by-product of our framework: robustness against adversarial attacks.</p>
<h1><a href="https://arxiv.org/abs/1907.06915">Mango Tree Net -- A fully convolutional network for semantic segmentation and individual crown detection of mango trees </a></h1>
<h3>Authors: Vikas Agaradahalli Gurumurthy, Ramesh Kestur, Omkar Narasipura</h3>
<h3>Categories: cs.CV</h3>
<hr />
<p>This work presents a method for semantic segmentation of mango trees in high
resolution aerial imagery, and, a novel method for individual crown detection
of mango trees using segmentation output. Mango Tree Net, a fully convolutional
neural network (FCN), is trained using supervised learning to perform semantic
segmentation of mango trees in imagery acquired using an unmanned aerial
vehicle (UAV). The proposed network is retrained to separate
touching/overlapping tree crowns in segmentation output. Contour based
connected object detection is performed on the segmentation output from
retrained network. Bounding boxes are drawn on the original images using
coordinates of connected objects to achieve individual crown detection. The
training dataset consists of 8,824 image patches of size 240 x 240. The
approach is tested for performance on segmentation and individual crown
detection tasks using test datasets containing 36 and 4 images respectively.
The performance is analyzed using standard metrics precision, recall, f1-score
and accuracy. Results obtained demonstrate the robustness of the proposed
methods despite variations in factors such as scale, occlusion, lighting
conditions and surrounding vegetation.</p>
<h1><a href="https://arxiv.org/abs/1907.06922">Human Pose Estimation for Real-World Crowded Scenarios </a></h1>
<h3>Authors: Thomas Golda, Tobias Kalb, Arne Schumann, J\"urgen Beyerer</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: Accepted for the 16th IEEE International Conference on Advanced Video and Signal-based Surveillance (AVSS)</h3>
<hr />
<p>Human pose estimation has recently made significant progress with the
adoption of deep convolutional neural networks. Its many applications have
attracted tremendous interest in recent years. However, many practical
applications require pose estimation for human crowds, which still is a rarely
addressed problem. In this work, we explore methods to optimize pose estimation
for human crowds, focusing on challenges introduced with dense crowds, such as
occlusions, people in close proximity to each other, and partial visibility of
people. In order to address these challenges, we evaluate three aspects of a
pose detection approach: i) a data augmentation method to introduce robustness
to occlusions, ii) the explicit detection of occluded body parts, and iii) the
use of the synthetic generated datasets. The first approach to improve the
accuracy in crowded scenarios is to generate occlusions at training time using
person and object cutouts from the object recognition dataset COCO (Common
Objects in Context). Furthermore, the synthetically generated dataset JTA
(Joint Track Auto) is evaluated for the use in real-world crowd applications.
In order to overcome the transfer gap of JTA originating from a low pose
variety and less dense crowds, an extension dataset is created to ease the use
for real-world applications. Additionally, the occlusion flags provided with
JTA are utilized to train a model, which explicitly distinguishes between
occluded and visible body parts in two distinct branches. The combination of
the proposed additions to the baseline method help to improve the overall
accuracy by 4.7% AP and thereby provide comparable results to current
state-of-the-art approaches on the respective dataset.</p>
<h1><a href="https://arxiv.org/abs/1907.06941">Semi-supervised Breast Lesion Detection in Ultrasound Video Based on Temporal Coherence </a></h1>
<h3>Authors: Sihong Chen and Weiping Yu and Kai Ma and Xinlong Sun and Xiaona Lin and Desheng Sun and Yefeng Zheng</h3>
<h3>Categories: cs.CV</h3>
<hr />
<p>Breast lesion detection in ultrasound video is critical for computer-aided
diagnosis. However, detecting lesion in video is quite challenging due to the
blurred lesion boundary, high similarity to soft tissue and lack of video
annotations. In this paper, we propose a semi-supervised breast lesion
detection method based on temporal coherence which can detect the lesion more
accurately. We aggregate features extracted from the historical key frames with
adaptive key-frame scheduling strategy. Our proposed method accomplishes the
unlabeled videos detection task by leveraging the supervision information from
a different set of labeled images. In addition, a new WarpNet is designed to
replace both the traditional spatial warping and feature aggregation operation,
leading to a tremendous increase in speed. Experiments on 1,060 2D ultrasound
sequences demonstrate that our proposed method achieves state-of-the-art video
detection result as 91.3% in mean average precision and 19 ms per frame on GPU,
compared to a RetinaNet based detection method in 86.6% and 32 ms.</p>
<h1><a href="https://arxiv.org/abs/1907.06955">Fused Detection of Retinal Biomarkers in OCT Volumes </a></h1>
<h3>Authors: Thomas Kurmann and Pablo M\'arquez-Neila and Siqing Yu and Marion Munk and Sebastian Wolf and Raphael Sznitman</h3>
<h3>Categories: cs.CV cs.LG</h3>
<hr />
<p>Optical Coherence Tomography (OCT) is the primary imaging modality for
detecting pathological biomarkers associated to retinal diseases such as
Age-Related Macular Degeneration. In practice, clinical diagnosis and treatment
strategies are closely linked to biomarkers visible in OCT volumes and the
ability to identify these plays an important role in the development of
ophthalmic pharmaceutical products. In this context, we present a method that
automatically predicts the presence of biomarkers in OCT cross-sections by
incorporating information from the entire volume. We do so by adding a
bidirectional LSTM to fuse the outputs of a Convolutional Neural Network that
predicts individual biomarkers. We thus avoid the need to use pixel-wise
annotations to train our method, and instead provide fine-grained biomarker
information regardless. On a dataset of 416 volumes, we show that our approach
imposes coherence between biomarker predictions across volume slices and our
predictions are superior to several existing approaches.</p>
<h1><a href="https://arxiv.org/abs/1907.06968">A Unified Deep Framework for Joint 3D Pose Estimation and Action Recognition from a Single RGB Camera </a></h1>
<h3>Authors: Huy Hieu Pham, Houssam Salmane, Louahdi Khoudour, Alain Crouzil, Pablo Zegers, Sergio A Velastin</h3>
<h3>Categories: cs.CV</h3>
<hr />
<p>We present a deep learning-based multitask framework for joint 3D human pose
estimation and action recognition from RGB video sequences. Our approach
proceeds along two stages. In the first, we run a real-time 2D pose detector to
determine the precise pixel location of important keypoints of the body. A
two-stream neural network is then designed and trained to map detected 2D
keypoints into 3D poses. In the second, we deploy the Efficient Neural
Architecture Search (ENAS) algorithm to find an optimal network architecture
that is used for modeling the spatio-temporal evolution of the estimated 3D
poses via an image-based intermediate representation and performing action
recognition. Experiments on Human3.6M, MSR Action3D and SBU Kinect Interaction
datasets verify the effectiveness of the proposed method on the targeted tasks.
Moreover, we show that our method requires a low computational budget for
training and inference.</p>
<h1><a href="https://arxiv.org/abs/1907.06987">A Short Note on the Kinetics-700 Human Action Dataset </a></h1>
<h3>Authors: Joao Carreira, Eric Noland, Chloe Hillier, Andrew Zisserman</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: arXiv admin note: substantial text overlap with arXiv:1808.01340</h3>
<hr />
<p>We describe an extension of the DeepMind Kinetics human action dataset from
600 classes to 700 classes, where for each class there are at least 600 video
clips from different YouTube videos. This paper details the changes introduced
for this new release of the dataset, and includes a comprehensive set of
statistics as well as baseline results using the I3D neural network
architecture.</p>
<h1><a href="https://arxiv.org/abs/1907.06989">Speed estimation evaluation on the KITTI benchmark based on motion and monocular depth information </a></h1>
<h3>Authors: R\'obert-Adrian Rill</h3>
<h3>Categories: cs.CV eess.IV</h3>
<h3>Comments: technical report with 16 pages, 3 figures, 7 tables</h3>
<hr />
<p>In this technical report we investigate speed estimation of the ego-vehicle
on the KITTI benchmark using state-of-the-art deep neural network based optical
flow and single-view depth prediction methods. Using a straightforward
intuitive approach and approximating a single scale factor, we evaluate several
application schemes of the deep networks and formulate meaningful conclusions
such as: combining depth information with optical flow improves speed
estimation accuracy as opposed to using optical flow alone; the quality of the
deep neural network methods influences speed estimation performance; using the
depth and optical flow results from smaller crops of wide images degrades
performance. With these observations in mind, we achieve a RMSE of less than 1
m/s for vehicle speed estimation using monocular images as input from
recordings of the KITTI benchmark. Limitations and possible future directions
are discussed as well.</p>
<h1><a href="https://arxiv.org/abs/1907.06996">Perception of visual numerosity in humans and machines </a></h1>
<h3>Authors: Alberto Testolin, Serena Dolfi, Mathijs Rochus and Marco Zorzi</h3>
<h3>Categories: cs.CV cs.NE q-bio.NC</h3>
<h3>Comments: 27 pages, 7 figures</h3>
<hr />
<p>Numerosity perception is foundational to mathematical learning, but its
computational bases are strongly debated. Some investigators argue that humans
are endowed with a specialized system supporting numerical representation;
others argue that visual numerosity is estimated using continuous magnitudes,
such as density or area, which usually co-vary with number. Here we reconcile
these contrasting perspectives by testing deep networks on the same numerosity
comparison task that was administered to humans, using a stimulus space that
allows to measure the contribution of non-numerical features. Our model
accurately simulated the psychophysics of numerosity perception and the
associated developmental changes: discrimination was driven by numerosity
information, but non-numerical features had a significant impact, especially
early during development. Representational similarity analysis further
highlighted that both numerosity and continuous magnitudes were spontaneously
encoded even when no task had to be carried out, demonstrating that numerosity
is a major, salient property of our visual environment.</p>
<h1><a href="https://arxiv.org/abs/1907.07011">Improving Semantic Segmentation via Dilated Affinity </a></h1>
<h3>Authors: Boxi Wu, Shuai Zhao, Wenqing Chu, Zheng Yang, Deng Cai</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: 10 pages, 5 figures, under review of NIPS2019</h3>
<hr />
<p>Introducing explicit constraints on the structural predictions has been an
effective way to improve the performance of semantic segmentation models.
Existing methods are mainly based on insufficient hand-crafted rules that only
partially capture the image structure, and some methods can also suffer from
the efficiency issue. As a result, most of the state-of-the-art fully
convolutional networks did not adopt these techniques. In this work, we propose
a simple, fast yet effective method that exploits structural information
through direct supervision with minor additional expense. To be specific, our
method explicitly requires the network to predict semantic segmentation as well
as dilated affinity, which is a sparse version of pair-wise pixel affinity. The
capability of telling the relationships between pixels are directly built into
the model and enhance the quality of segmentation in two stages. 1) Joint
training with dilated affinity can provide robust feature representations and
thus lead to finer segmentation results. 2) The extra output of affinity
information can be further utilized to refine the original segmentation with a
fast propagation process. Consistent improvements are observed on various
benchmark datasets when applying our framework to the existing state-of-the-art
model. Codes will be released soon.</p>
<h1><a href="https://arxiv.org/abs/1907.07023">Data Selection for training Semantic Segmentation CNNs with cross-dataset weak supervision </a></h1>
<h3>Authors: Panagiotis Meletis and Rob Romijnders and Gijs Dubbelman</h3>
<h3>Categories: cs.CV cs.LG</h3>
<h3>Comments: IEEE ITSC 2019</h3>
<hr />
<p>Training convolutional networks for semantic segmentation with strong
(per-pixel) and weak (per-bounding-box) supervision requires a large amount of
weakly labeled data. We propose two methods for selecting the most relevant
data with weak supervision. The first method is designed for finding visually
similar images without the need of labels and is based on modeling image
representations with a Gaussian Mixture Model (GMM). As a byproduct of GMM
modeling, we present useful insights on characterizing the data generating
distribution. The second method aims at finding images with high object
diversity and requires only the bounding box labels. Both methods are developed
in the context of automated driving and experimentation is conducted on
Cityscapes and Open Images datasets. We demonstrate performance gains by
reducing the amount of employed weakly labeled images up to 100 times for Open
Images and up to 20 times for Cityscapes.</p>
<h1><a href="https://arxiv.org/abs/1907.07034">Uncertainty-aware Self-ensembling Model for Semi-supervised 3D Left Atrium Segmentation </a></h1>
<h3>Authors: Lequan Yu, Shujun Wang, Xiaomeng Li, Chi-Wing Fu, Pheng-Ann Heng</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: Accepted by MICCAI2019; Code is available in</h3>
<hr />
<p>Training deep convolutional neural networks usually requires a large amount
of labeled data. However, it is expensive and time-consuming to annotate data
for medical image segmentation tasks. In this paper, we present a novel
uncertainty-aware semi-supervised framework for left atrium segmentation from
3D MR images. Our framework can effectively leverage the unlabeled data by
encouraging consistent predictions of the same input under different
perturbations. Concretely, the framework consists of a student model and a
teacher model, and the student model learns from the teacher model by
minimizing a segmentation loss and a consistency loss with respect to the
targets of the teacher model. We design a novel uncertainty-aware scheme to
enable the student model to gradually learn from the meaningful and reliable
targets by exploiting the uncertainty information. Experiments show that our
method achieves high performance gains by incorporating the unlabeled data. Our
method outperforms the state-of-the-art semi-supervised methods, demonstrating
the potential of our framework for the challenging semi-supervised problems.</p>
<h1><a href="https://arxiv.org/abs/1907.07045">Pedestrian Tracking by Probabilistic Data Association and Correspondence Embeddings </a></h1>
<h3>Authors: Borna Bi\'cani\'c, Marin Or\v{s}i\'c, Ivan Markovi\'c, Sini\v{s}a \v{S}egvi\'c, Ivan Petrovi\'c</h3>
<h3>Categories: cs.CV cs.LG cs.RO</h3>
<hr />
<p>This paper studies the interplay between kinematics (position and velocity)
and appearance cues for establishing correspondences in multi-target pedestrian
tracking. We investigate tracking-by-detection approaches based on a deep
learning detector, joint integrated probabilistic data association (JIPDA), and
appearance-based tracking of deep correspondence embeddings. We first addressed
the fixed-camera setup by fine-tuning a convolutional detector for accurate
pedestrian detection and combining it with kinematic-only JIPDA. The resulting
submission ranked first on the 3DMOT2015 benchmark. However, in sequences with
a moving camera and unknown ego-motion, we achieved the best results by
replacing kinematic cues with global nearest neighbor tracking of deep
correspondence embeddings. We trained the embeddings by fine-tuning features
from the second block of ResNet-18 using angular loss extended by a margin
term. We note that integrating deep correspondence embeddings directly in JIPDA
did not bring significant improvement. It appears that geometry of deep
correspondence embeddings for soft data association needs further investigation
in order to obtain the best from both worlds.</p>
<h1><a href="https://arxiv.org/abs/1907.07061">How much real data do we actually need: Analyzing object detection performance using synthetic and real data </a></h1>
<h3>Authors: Farzan Erlik Nowruzi and Prince Kapoor and Dhanvin Kolhatkar and Fahed Al Hassanat and Robert Laganiere and Julien Rebut</h3>
<h3>Categories: cs.CV</h3>
<h3>Comments: Accepted in International Conference on Machine Learning (ICML 2019) Workshop on AI for Autonomous Driving</h3>
<hr />
<p>In recent years, deep learning models have resulted in a huge amount of
progress in various areas, including computer vision. By nature, the supervised
training of deep models requires a large amount of data to be available. This
ideal case is usually not tractable as the data annotation is a tremendously
exhausting and costly task to perform. An alternative is to use synthetic data.
In this paper, we take a comprehensive look into the effects of replacing real
data with synthetic data. We further analyze the effects of having a limited
amount of real data. We use multiple synthetic and real datasets along with a
simulation tool to create large amounts of cheaply annotated synthetic data. We
analyze the domain similarity of each of these datasets. We provide insights
about designing a methodological procedure for training deep networks using
these datasets.</p>
<h1><a href="https://arxiv.org/abs/1907.07156">Efficient Segmentation: Learning Downsampling Near Semantic Boundaries </a></h1>
<h3>Authors: Dmitrii Marin, Zijian He, Peter Vajda, Priyam Chatterjee, Sam Tsai, Fei Yang, Yuri Boykov</h3>
<h3>Categories: cs.CV cs.LG</h3>
<hr />
<p>Many automated processes such as auto-piloting rely on a good semantic
segmentation as a critical component. To speed up performance, it is common to
downsample the input frame. However, this comes at the cost of missed small
objects and reduced accuracy at semantic boundaries. To address this problem,
we propose a new content-adaptive downsampling technique that learns to favor
sampling locations near semantic boundaries of target classes. Cost-performance
analysis shows that our method consistently outperforms the uniform sampling
improving balance between accuracy and computational efficiency. Our adaptive
sampling gives segmentation with better quality of boundaries and more reliable
support for smaller-size objects.</p>
<h1><a href="https://arxiv.org/abs/1907.07160">EnforceNet: Monocular Camera Localization in Large Scale Indoor Sparse LiDAR Point Cloud </a></h1>
<h3>Authors: Yu Chen and Guan Wang</h3>
<h3>Categories: cs.CV cs.RO eess.IV</h3>
<hr />
<p>Pose estimation is a fundamental building block for robotic applications such
as autonomous vehicles, UAV, and large scale augmented reality. It is also a
prohibitive factor for those applications to be in mass production, since the
state-of-the-art, centimeter-level pose estimation often requires long mapping
procedures and expensive localization sensors, e.g. LiDAR and high precision
GPS/IMU, etc. To overcome the cost barrier, we propose a neural network based
solution to localize a consumer degree RGB camera within a prior sparse LiDAR
map with comparable centimeter-level precision. We achieved it by introducing a
novel network module, which we call resistor module, to enforce the network
generalize better, predicts more accurately, and converge faster. Such results
are benchmarked by several datasets we collected in the large scale indoor
parking garage scenes. We plan to open both the data and the code for the
community to join the effort to advance this field.</p>
<h1><a href="https://arxiv.org/abs/1907.07161">Predicting Next-Season Designs on High Fashion Runway </a></h1>
<h3>Authors: Yusan Lin and Hao Yang</h3>
<h3>Categories: cs.CV</h3>
<hr />
<p>Fashion is a large and fast-changing industry. Foreseeing the upcoming
fashion trends is beneficial for fashion designers, consumers, and retailers.
However, fashion trends are often perceived as unpredictable due to the
enormous amount of factors involved into designers' subjectivity. In this
paper, we propose a fashion trend prediction framework and design neural
network models to leverage structured fashion runway show data, learn the
fashion collection embedding, and further train RNN/LSTM models to capture the
designers' style evolution. Our proposed framework consists of (1) a runway
embedding learning model that uses fashion runway images to learn every
season's collection embedding, and (2) a next-season fashion design prediction
model that leverage the concept of designer style and trend to predict
next-season design given designers. Through experiments on a collected dataset
across 32 years of fashion shows, our framework can achieve the best
performance of 78.42% AUC on average and 95% for an individual designer when
predicting the next season's design.</p>
<h1><a href="https://arxiv.org/abs/1907.07171">On the ''steerability" of generative adversarial networks </a></h1>
<h3>Authors: Ali Jahanian, Lucy Chai, Phillip Isola</h3>
<h3>Categories: cs.CV cs.LG</h3>
<hr />
<p>An open secret in contemporary machine learning is that many models work
beautifully on standard benchmarks but fail to generalize outside the lab. This
has been attributed to training on biased data, which provide poor coverage
over real world events. Generative models are no exception, but recent advances
in generative adversarial networks (GANs) suggest otherwise -- these models can
now synthesize strikingly realistic and diverse images. Is generative modeling
of photos a solved problem? We show that although current GANs can fit standard
datasets very well, they still fall short of being comprehensive models of the
visual manifold. In particular, we study their ability to fit simple
transformations such as camera movements and color changes. We find that the
models reflect the biases of the datasets on which they are trained (e.g.,
centered objects), but that they also exhibit some capacity for generalization:
by "steering" in latent space, we can shift the distribution while still
creating realistic images. We hypothesize that the degree of distributional
shift is related to the breadth of the training data distribution, and conduct
experiments that demonstrate this. Code is released on our project page:
https://ali-design.github.io/gan_steerability/</p>
<h1><a href="https://arxiv.org/abs/1907.06632">Metamorphic Testing of a Deep Learning based Forecaster </a></h1>
<h3>Authors: Anurag Dwarakanath, Manish Ahuja, Sanjay Podder, Silja Vinu, Arijit Naskar, Koushik MV</h3>
<h3>Categories: cs.LG cs.SE</h3>
<h3>Comments: Paper published at the 2019 IEEE/ACM 4th International Workshop on Metamorphic Testing (MET)</h3>
<hr />
<p>In this paper, we present the Metamorphic Testing of an in-use deep learning
based forecasting application. The application looks at the past data of system
characteristics (e.g. `memory allocation') to predict outages in the future. We
focus on two statistical / machine learning based components - a) detection of
co-relation between system characteristics and b) estimating the future value
of a system characteristic using an LSTM (a deep learning architecture). In
total, 19 Metamorphic Relations have been developed and we provide proofs &amp;
algorithms where applicable. We evaluated our method through two settings. In
the first, we executed the relations on the actual application and uncovered 8
issues not known before. Second, we generated hypothetical bugs, through
Mutation Testing, on a reference implementation of the LSTM based forecaster
and found that 65.9% of the bugs were caught through the relations.</p>
<h1><a href="https://arxiv.org/abs/1907.06633">On improving learning capability of ELM and an application to brain-computer interface </a></h1>
<h3>Authors: Apdullah Yay{\i}k, Yakup Kutlu, G\"okhan Altan</h3>
<h3>Categories: cs.LG eess.SP stat.ML</h3>
<h3>Comments: 11 pages, 6 figures, Neural Computing and Application, Springer (under-review)</h3>
<hr />
<p>As a type of pseudoinverse learning, extreme learning machine (ELM) is able
to achieve high performances in a rapid pace on benchmark datasets. However,
when it is applied to real life large data, decline related to low-convergence
of singular value decomposition (SVD) method occurs. Our study aims to resolve
this issue via replacing SVD with theoretically and empirically much efficient
5 number of methods: lower upper triangularization, Hessenberg decomposition,
Schur decomposition, modified Gram Schmidt algorithm and Householder
reflection. Comparisons were made on electroencephalography based
brain-computer interface classification problem to decide which method is the
most useful. Results of subject-based classifications suggested that if
priority was given to training pace, Hessenberg decomposition method, whereas
if priority was given to performances Householder reflection method should be
preferred.</p>
<h1><a href="https://arxiv.org/abs/1907.06671">Robust Variational Autoencoders for Outlier Detection in Mixed-Type Data </a></h1>
<h3>Authors: Sim\~ao Eduardo, Alfredo Naz\'abal, Christopher K. I. Williams, Charles Sutton</h3>
<h3>Categories: cs.LG stat.ML</h3>
<h3>Comments: In submission to NeurIPS 2019</h3>
<hr />
<p>We focus on the problem of unsupervised cell outlier detection in mixed type
tabular datasets. Traditional methods for outlier detection are concerned only
on detecting which rows in the dataset are outliers. However, identifying which
cells in the dataset corrupt a specific row is an important problem in
practice, especially in high-dimensional tables. We introduce the Robust
Variational Autoencoder (RVAE), a deep generative model that learns the joint
distribution of the clean data while identifying the outlier cells in the
dataset. RVAE learns the probability of each cell in the dataset being an
outlier, balancing the contributions of the different likelihood models in the
row outlier score, making the method suitable for outlier detection in mixed
type datasets. We show experimentally that the RVAE performs better than
several state of the art methods in cell outlier detection for tabular
datasets, while providing comparable or better results for row outlier
detection.</p>
<h1><a href="https://arxiv.org/abs/1907.06698">A Stratification Approach to Partial Dependence for Codependent Variables </a></h1>
<h3>Authors: Terence Parr and James D. Wilson</h3>
<h3>Categories: cs.LG stat.ML</h3>
<h3>Comments: See repo https://github.com/parrt/stratx</h3>
<hr />
<p>Model interpretability is important to machine learning practitioners, and a
key component of interpretation is the characterization of partial dependence
of the response variable on any subset of features used in the model. The two
most common strategies for assessing partial dependence suffer from a number of
critical weaknesses. In the first strategy, linear regression model
coefficients describe how a unit change in an explanatory variable changes the
response, while holding other variables constant. But, linear regression is
inapplicable for high dimensional (p&gt;n) data sets and is often insufficient to
capture the relationship between explanatory variables and the response. In the
second strategy, Partial Dependence (PD) plots and Individual Conditional
Expectation (ICE) plots give biased results for the common situation of
codependent variables and they rely on fitted models provided by the user. When
the supplied model is a poor choice due to systematic bias or overfitting,
PD/ICE plots provide little (if any) useful information.
  To address these issues, we introduce a new strategy, called StratPD, that
does not depend on a user's fitted model, provides accurate results in the
presence codependent variables, and is applicable to high dimensional settings.
The strategy works by stratifying a data set into groups of observations that
are similar, except in the variable of interest, through the use of a decision
tree. Any fluctuations of the response variable within a group is likely due to
the variable of interest. We apply StratPD to a collection of simulations and
case studies to show that StratPD is a fast, reliable, and robust method for
assessing partial dependence with clear advantages over state-of-the-art
methods.</p>
<h1><a href="https://arxiv.org/abs/1907.06704">PPO Dash: Improving Generalization in Deep Reinforcement Learning </a></h1>
<h3>Authors: Joe Booth</h3>
<h3>Categories: cs.LG cs.AI</h3>
<h3>Comments: 8 pages, 3 figures</h3>
<hr />
<p>Deep reinforcement learning is prone to overfitting, and traditional
benchmarks such as Atari 2600 benchmark can exacerbate this problem. The
Obstacle Tower Challenge addresses this by using randomized environments and
separate seeds for training, validation, and test runs. This paper examines
various improvements and best practices to the PPO algorithm using the Obstacle
Tower Challenge to empirically study their impact with regards to
generalization. Our experiments show that the combination provides
state-of-the-art performance on the Obstacle Tower Challenge.</p>
<h1><a href="https://arxiv.org/abs/1907.06732">Pad\'e Activation Units: End-to-end Learning of Flexible Activation Functions in Deep Networks </a></h1>
<h3>Authors: Alejandro Molina, Patrick Schramowski, Kristian Kersting</h3>
<h3>Categories: cs.LG cs.NE</h3>
<h3>Comments: 12 Pages, 6 Figures</h3>
<hr />
<p>The performance of deep network learning strongly depends on the choice of
the non-linear activation function associated with each neuron. However,
deciding on the best activation is non-trivial and the choice depends on the
architecture, hyper-parameters, and even on the dataset. Typically these
activations are fixed by hand before training. Here, we demonstrate how to
eliminate the reliance on first picking fixed activation functions by using
flexible parametric rational functions instead. The resulting Pad\'e Activation
Units (PAUs) can both approximate common activation functions and also learn
new ones while providing compact representations. Our empirical evidence shows
that end-to-end learning deep networks with PAUs can increase the predictive
performance and reduce the training time of common deep architectures.
Moreover, PAUs pave the way to approximations with provable robustness. The
source code can be found at https://github.com/ml-research/pau</p>
<h1><a href="https://arxiv.org/abs/1907.06771">Subspace Determination through Local Intrinsic Dimensional </a></h1>
<h3>Authors: Ruben Becker, Imane Hafnaoui, Michael E. Houle, Pan Li, Arthur Zimek</h3>
<h3>Categories: cs.LG stat.ML</h3>
<hr />
<p>Axis-aligned subspace clustering generally entails searching through enormous
numbers of subspaces (feature combinations) and evaluation of cluster quality
within each subspace. In this paper, we tackle the problem of identifying
subsets of features with the most significant contribution to the formation of
the local neighborhood surrounding a given data point. For each point, the
recently-proposed Local Intrinsic Dimension (LID) model is used in identifying
the axis directions along which features have the greatest local
discriminability, or equivalently, the fewest number of components of LID that
capture the local complexity of the data. In this paper, we develop an
estimator of LID along axis projections, and provide preliminary evidence that
this LID decomposition can indicate axis-aligned data subspaces that support
the formation of clusters.</p>
<h1><a href="https://arxiv.org/abs/1907.06795">Efficient Autonomy Validation in Simulation with Adaptive Stress Testing </a></h1>
<h3>Authors: Mark Koren and Mykel Kochenderfer</h3>
<h3>Categories: cs.LG cs.RO cs.SE cs.SY eess.SY stat.ML</h3>
<h3>Comments: Submitted to IEEE ITSC 2019</h3>
<hr />
<p>During the development of autonomous systems such as driverless cars, it is
important to characterize the scenarios that are most likely to result in
failure. Adaptive Stress Testing (AST) provides a way to search for the
most-likely failure scenario as a Markov decision process (MDP). Our previous
work used a deep reinforcement learning (DRL) solver to identify likely failure
scenarios. However, the solver's use of a feed-forward neural network with a
discretized space of possible initial conditions poses two major problems.
First, the system is not treated as a black box, in that it requires analyzing
the internal state of the system, which leads to considerable implementation
complexities. Second, in order to simulate realistic settings, a new instance
of the solver needs to be run for each initial condition. Running a new solver
for each initial condition not only significantly increases the computational
complexity, but also disregards the underlying relationship between similar
initial conditions. We provide a solution to both problems by employing a
recurrent neural network that takes a set of initial conditions from a
continuous space as input. This approach enables robust and efficient detection
of failures because the solution generalizes across the entire space of initial
conditions. By simulating an instance where an autonomous car drives while a
pedestrian is crossing a road, we demonstrate the solver is now capable of
finding solutions for problems that would have previously been intractable.</p>
<h1><a href="https://arxiv.org/abs/1907.06800">Graph Interpolating Activation Improves Both Natural and Robust Accuracies in Data-Efficient Deep Learning </a></h1>
<h3>Authors: Bao Wang and Stanley J. Osher</h3>
<h3>Categories: cs.LG cs.NA math.NA stat.ML</h3>
<h3>Comments: 34 pages, 10 figures</h3>
<hr />
<p>Improving the accuracy and robustness of deep neural nets (DNNs) and adapting
them to small training data are primary tasks in deep learning research. In
this paper, we replace the output activation function of DNNs, typically the
data-agnostic softmax function, with a graph Laplacian-based high dimensional
interpolating function which, in the continuum limit, converges to the solution
of a Laplace-Beltrami equation on a high dimensional manifold. Furthermore, we
propose end-to-end training and testing algorithms for this new architecture.
The proposed DNN with graph interpolating activation integrates the advantages
of both deep learning and manifold learning. Compared to the conventional DNNs
with the softmax function as output activation, the new framework demonstrates
the following major advantages: First, it is better applicable to
data-efficient learning in which we train high capacity DNNs without using a
large number of training data. Second, it remarkably improves both natural
accuracy on the clean images and robust accuracy on the adversarial images
crafted by both white-box and black-box adversarial attacks. Third, it is a
natural choice for semi-supervised learning. For reproducibility, the code is
available at \url{https://github.com/BaoWangMath/DNN-DataDependentActivation}.</p>
<h1><a href="https://arxiv.org/abs/1907.06814">A Quantum-inspired Algorithm for General Minimum Conical Hull Problems </a></h1>
<h3>Authors: Yuxuan Du, Min-Hsiu Hsieh, Tongliang Liu, Dacheng Tao</h3>
<h3>Categories: cs.LG quant-ph stat.ML</h3>
<hr />
<p>A wide range of fundamental machine learning tasks that are addressed by the
maximum a posteriori estimation can be reduced to a general minimum conical
hull problem. The best-known solution to tackle general minimum conical hull
problems is the divide-and-conquer anchoring learning scheme (DCA), whose
runtime complexity is polynomial in size. However, big data is pushing these
polynomial algorithms to their performance limits. In this paper, we propose a
sublinear classical algorithm to tackle general minimum conical hull problems
when the input has stored in a sample-based low-overhead data structure. The
algorithm's runtime complexity is polynomial in the rank and polylogarithmic in
size. The proposed algorithm achieves the exponential speedup over DCA and,
therefore, provides advantages for high dimensional problems.</p>
<h1><a href="https://arxiv.org/abs/1907.06831">Evaluating Explanation Without Ground Truth in Interpretable Machine Learning </a></h1>
<h3>Authors: Fan Yang, Mengnan Du, Xia Hu</h3>
<h3>Categories: cs.LG cs.AI cs.HC stat.ML</h3>
<hr />
<p>Interpretable Machine Learning (IML) has become increasingly important in
many applications, such as autonomous cars and medical diagnosis, where
explanations are preferred to help people better understand how machine
learning systems work and further enhance their trust towards systems.
Particularly in robotics, explanations from IML are significantly helpful in
providing reasons for those adverse and inscrutable actions, which could impair
the safety and profit of the public. However, due to the diversified scenarios
and subjective nature of explanations, we rarely have the ground truth for
benchmark evaluation in IML on the quality of generated explanations. Having a
sense of explanation quality not only matters for quantifying system
boundaries, but also helps to realize the true benefits to human users in
real-world applications. To benchmark evaluation in IML, in this paper, we
rigorously define the problem of evaluating explanations, and systematically
review the existing efforts. Specifically, we summarize three general aspects
of explanation (i.e., predictability, fidelity and persuasibility) with formal
definitions, and respectively review the representative methodologies for each
of them under different tasks. Further, a unified evaluation framework is
designed according to the hierarchical needs from developers and end-users,
which could be easily adopted for different scenarios in practice. In the end,
open problems are discussed, and several limitations of current evaluation
techniques are raised for future explorations.</p>
<h1><a href="https://arxiv.org/abs/1907.06835">An Inter-Layer Weight Prediction and Quantization for Deep Neural Networks based on a Smoothly Varying Weight Hypothesis </a></h1>
<h3>Authors: Kang-Ho Lee, JoonHyun Jeong, and Sung-Ho Bae</h3>
<h3>Categories: cs.LG cs.CV stat.ML</h3>
<h3>Comments: 12 pages, 7 figures</h3>
<hr />
<p>Network compression for deep neural networks has become an important part of
deep learning research, because of increased demand for deep learning models in
practical resource-constrained environments. In this paper, we observe that the
weights in adjacent convolution layers share strong similarity in shapes and
values, i.e., the weights tend to vary smoothly along the layers. We call this
phenomenon \textit{Smoothly Varying Weight Hypothesis} (SVWH). Based on SVWH
and an inter-frame prediction method in conventional video coding schemes, we
propose a new \textit{Inter-Layer Weight Prediction} (ILWP) and quantization
method which quantize the predicted residuals of the weights. Since the
predicted weight residuals tend to follow Laplacian distributions with very low
variance, the weight quantization can more effectively be applied, thus
producing more zero weights and enhancing weight compression ratio. In
addition, we propose a new loss for eliminating non-texture bits, which enabled
us to more effectively store only texture bits. That is, the proposed loss
regularizes the weights such that the collocated weights between the adjacent
two layers have the same values. Our comprehensive experiments show that the
proposed method achieved much higher weight compression rate at the same
accuracy level compared with the previous quantization-based compression
methods in deep neural networks.</p>
<h1><a href="https://arxiv.org/abs/1907.06837">A Self-Attentive model for Knowledge Tracing </a></h1>
<h3>Authors: Shalini Pandey, George Karypis</h3>
<h3>Categories: cs.LG cs.CY stat.ML</h3>
<h3>Comments: International Conference on Education Data Mining</h3>
<hr />
<p>Knowledge tracing is the task of modeling each student's mastery of knowledge
concepts (KCs) as (s)he engages with a sequence of learning activities. Each
student's knowledge is modeled by estimating the performance of the student on
the learning activities. It is an important research area for providing a
personalized learning platform to students. In recent years, methods based on
Recurrent Neural Networks (RNN) such as Deep Knowledge Tracing (DKT) and
Dynamic Key-Value Memory Network (DKVMN) outperformed all the traditional
methods because of their ability to capture complex representation of human
learning. However, these methods face the issue of not generalizing well while
dealing with sparse data which is the case with real-world data as students
interact with few KCs. In order to address this issue, we develop an approach
that identifies the KCs from the student's past activities that are
\textit{relevant} to the given KC and predicts his/her mastery based on the
relatively few KCs that it picked. Since predictions are made based on
relatively few past activities, it handles the data sparsity problem better
than the methods based on RNN. For identifying the relevance between the KCs,
we propose a self-attention based approach, Self Attentive Knowledge Tracing
(SAKT). Extensive experimentation on a variety of real-world dataset shows that
our model outperforms the state-of-the-art models for knowledge tracing,
improving AUC by 4.43% on average.</p>
<h1><a href="https://arxiv.org/abs/1907.06838">Improved Reinforcement Learning through Imitation Learning Pretraining Towards Image-based Autonomous Driving </a></h1>
<h3>Authors: Tianqi Wang, Dong Eui Chang</h3>
<h3>Categories: cs.LG cs.AI cs.CV eess.IV</h3>
<h3>Comments: 5 pages, 2019 19th International Conference on Control, Automation and Systems (ICCAS 2019)</h3>
<hr />
<p>We present a training pipeline for the autonomous driving task given the
current camera image and vehicle speed as the input to produce the throttle,
brake, and steering control output. The simulator Airsim's convenient weather
and lighting API provides a sufficient diversity during training which can be
very helpful to increase the trained policy's robustness. In order to not limit
the possible policy's performance, we use a continuous and deterministic
control policy setting. We utilize ResNet-34 as our actor and critic networks
with some slight changes in the fully connected layers. Considering human's
mastery of this task and the high-complexity nature of this task, we first use
imitation learning to mimic the given human policy and leverage the trained
policy and its weights to the reinforcement learning phase for which we use
DDPG. This combination shows a considerable performance boost comparing to both
pure imitation learning and pure DDPG for the autonomous driving task.</p>
<h1><a href="https://arxiv.org/abs/1907.06840">The Quantum Version Of Classification Decision Tree Constructing Algorithm C5.0 </a></h1>
<h3>Authors: Kamil Khadiev, Ilnaz Mannapov and Liliya Safina</h3>
<h3>Categories: cs.LG quant-ph stat.ML</h3>
<hr />
<p>In the paper, we focus on complexity of C5.0 algorithm for constructing
decision tree classifier that is the models for the classification problem from
machine learning. In classical case the decision tree is constructed in
$O(hd(NM+N \log N))$ running time, where $M$ is a number of classes, $N$ is the
size of a training data set, $d$ is a number of attributes of each element, $h$
is a tree height. Firstly, we improved the classical version, the running time
of the new version is $O(h\cdot d\cdot N\log N)$. Secondly, we suggest a
quantum version of this algorithm, which uses quantum subroutines like the
amplitude amplification and the D{\"u}rr-H{\o}yer minimum search algorithms
that are based on Grover's algorithm. The running time of the quantum algorithm
is $O\big(h\cdot \sqrt{d}\log d \cdot N \log N\big)$ that is better than
complexity of the classical algorithm.</p>
<h1><a href="https://arxiv.org/abs/1907.06870">Light Multi-segment Activation for Model Compression </a></h1>
<h3>Authors: Zhenhui Xu, Guolin Ke, Jia Zhang, Jiang Bian, Tie-Yan Liu</h3>
<h3>Categories: cs.LG</h3>
<hr />
<p>Model compression has become necessary when applying neural networks (NN)
into many real application tasks that can accept slightly-reduced model
accuracy with strict tolerance to model complexity. Recently, Knowledge
Distillation, which distills the knowledge from well-trained and highly complex
teacher model into a compact student model, has been widely used for model
compression. However, under the strict requirement on the resource cost, it is
quite challenging to achieve comparable performance with the teacher model,
essentially due to the drastically-reduced expressiveness ability of the
compact student model. Inspired by the nature of the expressiveness ability in
Neural Networks, we propose to use multi-segment activation, which can
significantly improve the expressiveness ability with very little cost, in the
compact student model. Specifically, we propose a highly efficient
multi-segment activation, called Light Multi-segment Activation (LMA), which
can rapidly produce multiple linear regions with very few parameters by
leveraging the statistical information. With using LMA, the compact student
model is capable of achieving much better performance effectively and
efficiently, than the ReLU-equipped one with same model scale. Furthermore, the
proposed method is compatible with other model compression techniques, such as
quantization, which means they can be used jointly for better compression
performance. Experiments on state-of-the-art NN architectures over the
real-world tasks demonstrate the effectiveness and extensibility of the LMA.</p>
<h1><a href="https://arxiv.org/abs/1907.06901">Meta-Learning for Black-box Optimization </a></h1>
<h3>Authors: Vishnu TV, Pankaj Malhotra, Jyoti Narwariya, Lovekesh Vig, Gautam Shroff</h3>
<h3>Categories: cs.LG stat.ML</h3>
<hr />
<p>Recently, neural networks trained as optimizers under the "learning to learn"
or meta-learning framework have been shown to be effective for a broad range of
optimization tasks including derivative-free black-box function optimization.
Recurrent neural networks (RNNs) trained to optimize a diverse set of synthetic
non-convex differentiable functions via gradient descent have been effective at
optimizing derivative-free black-box functions. In this work, we propose
RNN-Opt: an approach for learning RNN-based optimizers for optimizing
real-parameter single-objective continuous functions under limited budget
constraints. Existing approaches utilize an observed improvement based
meta-learning loss function for training such models. We propose training
RNN-Opt by using synthetic non-convex functions with known (approximate)
optimal values by directly using discounted regret as our meta-learning loss
function. We hypothesize that a regret-based loss function mimics typical
testing scenarios, and would therefore lead to better optimizers compared to
optimizers trained only to propose queries that improve over previous queries.
Further, RNN-Opt incorporates simple yet effective enhancements during training
and inference procedures to deal with the following practical challenges: i)
Unknown range of possible values for the black-box function to be optimized,
and ii) Practical and domain-knowledge based constraints on the input
parameters. We demonstrate the efficacy of RNN-Opt in comparison to existing
methods on several synthetic as well as standard benchmark black-box functions
along with an anonymized industrial constrained optimization problem.</p>
<h1><a href="https://arxiv.org/abs/1907.06916">Single-bit-per-weight deep convolutional neural networks without batch-normalization layers for embedded systems </a></h1>
<h3>Authors: Mark D. McDonnell, Hesham Mostafa, Runchun Wang and Andre van Schaik</h3>
<h3>Categories: cs.LG cs.CV cs.NE stat.ML</h3>
<h3>Comments: 8 pages, published IEEE conference paper</h3>
<hr />
<p>Batch-normalization (BN) layers are thought to be an integrally important
layer type in today's state-of-the-art deep convolutional neural networks for
computer vision tasks such as classification and detection. However, BN layers
introduce complexity and computational overheads that are highly undesirable
for training and/or inference on low-power custom hardware implementations of
real-time embedded vision systems such as UAVs, robots and Internet of Things
(IoT) devices. They are also problematic when batch sizes need to be very small
during training, and innovations such as residual connections introduced more
recently than BN layers could potentially have lessened their impact. In this
paper we aim to quantify the benefits BN layers offer in image classification
networks, in comparison with alternative choices. In particular, we study
networks that use shifted-ReLU layers instead of BN layers. We found, following
experiments with wide residual networks applied to the ImageNet, CIFAR 10 and
CIFAR 100 image classification datasets, that BN layers do not consistently
offer a significant advantage. We found that the accuracy margin offered by BN
layers depends on the data set, the network size, and the bit-depth of weights.
We conclude that in situations where BN layers are undesirable due to speed,
memory or complexity costs, that using shifted-ReLU layers instead should be
considered; we found they can offer advantages in all these areas, and often do
not impose a significant accuracy cost.</p>
<h1><a href="https://arxiv.org/abs/1907.06923">The Bregman-Tweedie Classification Model </a></h1>
<h3>Authors: Hyenkyun Woo</h3>
<h3>Categories: cs.LG stat.ML</h3>
<hr />
<p>This work proposes the Bregman-Tweedie classification model and analyzes the
domain structure of the extended exponential function, an extension of the
classic generalized exponential function with additional scaling parameter, and
related high-level mathematical structures, such as the Bregman-Tweedie loss
function and the Bregman-Tweedie divergence. The base function of this
divergence is the convex function of Legendre type induced from the extended
exponential function. The Bregman-Tweedie loss function of the proposed
classification model is the regular Legendre transformation of the
Bregman-Tweedie divergence. This loss function is a polynomial parameterized
function between unhinge loss and the logistic loss function. Actually, we have
two sub-models of the Bregman-Tweedie classification model; H-Bregman with
hinge-like loss function and L-Bregman with logistic-like loss function.
Although the proposed classification model is nonconvex and unbounded,
empirically, we have observed that the H-Bregman and L-Bregman outperform, in
terms of the Friedman ranking, logistic regression and SVM and show reasonable
performance in terms of the classification accuracy in the category of the
binary linear classification problem.</p>
<h1><a href="https://arxiv.org/abs/1907.06969">Random projections and sampling algorithms for clustering of high-dimensional polygonal curves </a></h1>
<h3>Authors: Stefan Meintrup, Alexander Munteanu, Dennis Rohde</h3>
<h3>Categories: cs.LG stat.ML</h3>
<hr />
<p>We study the center and median clustering problems for high-dimensional
polygonal curves with finite but unbounded complexity. We tackle the
computational issue that arises from the high number of dimensions by defining
a Johnson-Lindenstrauss projection for polygonal curves. We analyze the
resulting error in terms of the Fr\'echet distance, which is a natural
dissimilarity measure for curves. Our algorithms for the median clustering
achieve sublinear dependency on the number of input curves via subsampling. For
the center clustering we utilize Buchin et al. (2019a) algorithm that achieves
linear running-time in the number of input curves. We evaluate our results
empirically utilizing a fast, CUDA-parallelized variant of the Alt and Godau
algorithm for the Fr\'echet distance. Our experiments show that our clustering
algorithms have fast and accurate practical implementations that yield
meaningful results on real world data from various physical domains.</p>
<h1><a href="https://arxiv.org/abs/1907.07001">Latent Adversarial Defence with Boundary-guided Generation </a></h1>
<h3>Authors: Xiaowei Zhou, Ivor W. Tsang, Jie Yin</h3>
<h3>Categories: cs.LG cs.CR</h3>
<h3>Comments: 11 pages</h3>
<hr />
<p>Deep Neural Networks (DNNs) have recently achieved great success in many
tasks, which encourages DNNs to be widely used as a machine learning service in
model sharing scenarios. However, attackers can easily generate adversarial
examples with a small perturbation to fool the DNN models to predict wrong
labels. To improve the robustness of shared DNN models against adversarial
attacks, we propose a novel method called Latent Adversarial Defence (LAD). The
proposed LAD method improves the robustness of a DNN model through adversarial
training on generated adversarial examples. Different from popular attack
methods which are carried in the input space and only generate adversarial
examples of repeating patterns, LAD generates myriad of adversarial examples
through adding perturbations to latent features along the normal of the
decision boundary which is constructed by an SVM with an attention mechanism.
Once adversarial examples are generated, we adversarially train the model
through augmenting the training data with generated adversarial examples.
Extensive experiments on the MNIST, SVHN, and CelebA dataset demonstrate the
effectiveness of our model in defending against different types of adversarial
attacks.</p>
<h1><a href="https://arxiv.org/abs/1907.07035">Structured Variational Inference in Unstable Gaussian Process State Space Models </a></h1>
<h3>Authors: Silvan Melchior, Felix Berkenkamp, Sebastian Curi, Andreas Krause</h3>
<h3>Categories: cs.LG cs.SY eess.SY stat.ML</h3>
<hr />
<p>Gaussian processes are expressive, non-parametric statistical models that are
well-suited to learn nonlinear dynamical systems. However, large-scale
inference in these state space models is a challenging problem. In this paper,
we propose CBF-SSM a scalable model that employs a structured variational
approximation to maintain temporal correlations. In contrast to prior work, our
approach applies to the important class of unstable systems, where state
uncertainty grows unbounded over time. For these systems, our method contains a
probabilistic, model-based backward pass that infers latent states during
training. We demonstrate state-of-the-art performance in our experiments.
Moreover, we show that CBF-SSM can be combined with physical models in the form
of ordinary differential equations to learn a reliable model of a physical
flying robotic vehicle.</p>
<h1><a href="https://arxiv.org/abs/1907.07063">SGD momentum optimizer with step estimation by online parabola model </a></h1>
<h3>Authors: Jarek Duda</h3>
<h3>Categories: cs.LG stat.ML</h3>
<h3>Comments: 4 pages, 1 figure</h3>
<hr />
<p>In stochastic gradient descent, especially for neural network training, there
are currently dominating first order methods: not modeling local distance to
minimum. This information required for optimal step size is provided by second
order methods, however, they have many difficulties, starting with full Hessian
having square of dimension number of coefficients.
  This article proposes a minimal step from successful first order momentum
method toward second order: online parabola modelling in just a single
direction: normalized $\hat{v}$ from momentum method. It is done by estimating
linear trend of gradients $\vec{g}=\nabla F(\vec{\theta})$ in $\hat{v}$
direction: such that $g(\vec{\theta}<em>\bot+\theta\hat{v})\approx \lambda (\theta
-p)$ for $\theta = \vec{\theta}\cdot \hat{v}$, $g= \vec{g}\cdot \hat{v}$,
$\vec{\theta}</em>\bot=\vec{\theta}-\theta\hat{v}$. Using linear regression,
$\lambda$, $p$ are MSE estimated by just updating four averages (of $g$,
$\theta$, $g\theta$, $\theta^2$) in the considered direction. Exponential
moving averages allow here for inexpensive online estimation, weakening
contribution of the old gradients. Controlling sign of curvature $\lambda$, we
can repel from saddles in contrast to attraction in standard Newton method. In
the remaining directions: not considered in second order model, we can
simultaneously perform e.g. gradient descent.</p>
<h1><a href="https://arxiv.org/abs/1907.07066">Selection Heuristics on Semantic Genetic Programming for Classification Problems </a></h1>
<h3>Authors: Claudia N. S\'anchez and Mario Graff</h3>
<h3>Categories: cs.LG cs.NE stat.ML</h3>
<hr />
<p>In a steady-state evolution, tournament selection traditionally uses the
fitness function to select the parents, and negative selection chooses an
individual to be replaced with an offspring. This contribution focuses on
analyzing the behavior, in terms of performance, of different heuristics when
used instead of the fitness function in tournament selection. The heuristics
analyzed are related to measuring the similarity of the individuals in the
semantic space. In addition, the analysis includes random selection and
traditional tournament selection. These selection functions were implemented on
our Semantic Genetic Programming system, namely EvoDAG, which is inspired by
the geometric genetic operators and tested on 30 classification problems with a
variable number of samples, variables, and classes. The result indicated that
the combination of accuracy and the random selection, in the negative
tournament, produces the best combination, and the difference in performances
between this combination and the tournament selection is statistically
significant. Furthermore, we compare EvoDAG's performance using the selection
heuristics against 18 classifiers that included traditional approaches as well
as auto-machine-learning techniques. The results indicate that our proposal is
competitive with state-of-art classifiers. Finally, it is worth to mention that
EvoDAG is available as open source software.</p>
<h1><a href="https://arxiv.org/abs/1907.07129">Topology Based Scalable Graph Kernels </a></h1>
<h3>Authors: Kin Sum Liu, Chien-Chun Ni, Yu-Yao Lin, Jie Gao</h3>
<h3>Categories: cs.LG stat.ML</h3>
<hr />
<p>We propose a new graph kernel for graph classification and comparison using
Ollivier Ricci curvature. The Ricci curvature of an edge in a graph describes
the connectivity in the local neighborhood. An edge in a densely connected
neighborhood has positive curvature and an edge serving as a local bridge has
negative curvature. We use the edge curvature distribution to form a graph
kernel which is then used to compare and cluster graphs. The curvature kernel
uses purely the graph topology and thereby works for settings when node
attributes are not available.</p>
<h1><a href="https://arxiv.org/abs/1907.07157">The Tradeoff Between Privacy and Accuracy in Anomaly Detection Using Federated XGBoost </a></h1>
<h3>Authors: Mengwei Yang, Linqi Song, Jie Xu, Congduan Li, Guozhen Tan</h3>
<h3>Categories: cs.LG cs.CR stat.ML</h3>
<hr />
<p>Privacy has raised considerable concerns recently, especially with the advent
of information explosion and numerous data mining techniques to explore the
information inside large volumes of data. In this context, a new distributed
learning paradigm termed federated learning becomes prominent recently to
tackle the privacy issues in distributed learning, where only learning models
will be transmitted from the distributed nodes to servers without revealing
users' own data and hence protecting the privacy of users.
  In this paper, we propose a horizontal federated XGBoost algorithm to solve
the federated anomaly detection problem, where the anomaly detection aims to
identify abnormalities from extremely unbalanced datasets and can be considered
as a special classification problem. Our proposed federated XGBoost algorithm
incorporates data aggregation and sparse federated update processes to balance
the tradeoff between privacy and learning performance. In particular, we
introduce the virtual data sample by aggregating a group of users' data
together at a single distributed node. We compute parameters based on these
virtual data samples in the local nodes and aggregate the learning model in the
central server. In the learning model upgrading process, we focus more on the
wrongly classified data before in the virtual sample and hence to generate
sparse learning model parameters. By carefully controlling the size of these
groups of samples, we can achieve a tradeoff between privacy and learning
performance. Our experimental results show the effectiveness of our proposed
scheme by comparing with existing state-of-the-arts.</p>
<h1><a href="https://arxiv.org/abs/1907.07165">Explaining Classifiers with Causal Concept Effect (CaCE) </a></h1>
<h3>Authors: Yash Goyal, Uri Shalit, Been Kim</h3>
<h3>Categories: cs.LG cs.CV stat.ML</h3>
<hr />
<p>How can we understand classification decisions made by deep neural nets? We
propose answering this question by using ideas from causal inference. We define
the ``Causal Concept Effect'' (CaCE) as the causal effect that the presence or
absence of a concept has on the prediction of a given deep neural net. We then
use this measure as a mean to understand what drives the network's prediction
and what does not. Yet many existing interpretability methods rely solely on
correlations, resulting in potentially misleading explanations. We show how
CaCE can avoid such mistakes. In high-risk domains such as medicine, knowing
the root cause of the prediction is crucial. If we knew that the network's
prediction was caused by arbitrary concepts such as the lighting conditions in
an X-ray room instead of medically meaningful concept, this would prevent us
from disastrous deployment of such models.
  Estimating CaCE is difficult in situations where we cannot easily simulate
the do-operator. As a simple solution, we propose learning a generative model,
specifically a Variational AutoEncoder (VAE) on image pixels or image
embeddings extracted from the classifier to measure VAE-CaCE. We show that
VAE-CaCE is able to correctly estimate the true causal effect as compared to
other baselines in controlled settings with synthetic and semi-natural high
dimensional images.</p>
<h1><a href="https://arxiv.org/abs/1907.07174">Natural Adversarial Examples </a></h1>
<h3>Authors: Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, Dawn Song</h3>
<h3>Categories: cs.LG cs.CV stat.ML</h3>
<h3>Comments: Dataset and code available at</h3>
<hr />
<p>We introduce natural adversarial examples -- real-world, unmodified, and
naturally occurring examples that cause classifier accuracy to significantly
degrade. We curate 7,500 natural adversarial examples and release them in an
ImageNet classifier test set that we call ImageNet-A. This dataset serves as a
new way to measure classifier robustness. Like l_p adversarial examples,
ImageNet-A examples successfully transfer to unseen or black-box classifiers.
For example, on ImageNet-A a DenseNet-121 obtains around 2% accuracy, an
accuracy drop of approximately 90%. Recovering this accuracy is not simple
because ImageNet-A examples exploit deep flaws in current classifiers including
their over-reliance on color, texture, and background cues. We observe that
popular training techniques for improving robustness have little effect, but we
show that some architectural changes can enhance robustness to natural
adversarial examples. Future research is required to enable robust
generalization to this hard ImageNet test set.</p>
<h1><a href="https://arxiv.org/abs/1907.06585">Parallelism Theorem and Derived Rules for Parallel Coherent Transformations </a></h1>
<h3>Authors: Thierry Boy de la Tour</h3>
<h3>Categories: math.CT cs.CL</h3>
<h3>Comments: 16 pages</h3>
<hr />
<p>An Independent Parallelism Theorem is proven in the theory of adhesive HLR
categories. It shows the bijective correspondence between sequential
independent and parallel independent direct derivations in the Weak
Double-Pushout framework, see [2]. The parallel derivations are expressed by
means of Parallel Coherent Transformations (PCTs), hence without assuming the
existence of coproducts compatible with M as in the standard Parallelism
Theorem. It is aslo shown that a derived rule can be extracted from any PCT, in
the sense that to any direct derivation of this rule corresponds a valid PCT.</p>
<h1><a href="https://arxiv.org/abs/1907.06773">Logic Conditionals, Supervenience, and Selection Tasks </a></h1>
<h3>Authors: Giovanni Sileno</h3>
<h3>Categories: cs.AI cs.CL cs.SC</h3>
<hr />
<p>Principles of cognitive economy would require that concepts about objects,
properties and relations should be introduced only if they simplify the
conceptualisation of a domain. Unexpectedly, classic logic conditionals,
specifying structures holding within elements of a formal conceptualisation, do
not always satisfy this crucial principle. The paper argues that this
requirement is captured by \emph{supervenience}, hereby further identified as a
property necessary for compression. The resulting theory suggests an
alternative explanation of the empirical experiences observable in Wason's
selection tasks, associating human performance with conditionals on the ability
of dealing with compression, rather than with logic necessity.</p>
<h1><a href="https://arxiv.org/abs/1907.06848">Modeling competitive evolution of multiple languages </a></h1>
<h3>Authors: Zejie Zhou, Boleslaw K. Szymanski, Jianxi Gao</h3>
<h3>Categories: cs.CY cs.CL</h3>
<h3>Comments: 13 pages, 6 figures</h3>
<hr />
<p>Increasing evidence demonstrates that in many places language coexistence has
become ubiquitous and essential for supporting language and cultural diversity
and associated with its financial and economic benefits. The competitive
evolution among multiple languages determines the evolution outcome, either
coexistence, decline, or extinction. Here, we extend the Abrams-Strogatz model
of language competition to multiple languages and then validate it by analyzing
the behavioral transitions of language usage over the recent several decades in
Singapore and Hong Kong. In each case, we estimate from data the model
parameters that measure each language utility for its speakers and the strength
of two biases, the majority preference for their language, and the minority
aversion to it. The values of these two biases decide which language is the
fastest growing in the competition and what would be the stable state of the
system. We also study the system convergence time to stable states and discover
the existence of tipping points with multiple attractors. Moreover, the
critical slowdown of convergence to the stable fractions of language users
appears near and peaks at the tipping points, signaling when the system
approaches them. Our analysis furthers our understanding of multiple language
evolution and the role of tipping points in behavioral transitions. These
insights may help to protect languages from extinction and retain the language
and cultural diversity.</p>
<h1><a href="https://arxiv.org/abs/1907.06950">Abstract categorial grammars with island constraints and effective decidability </a></h1>
<h3>Authors: Sergey Slavnov</h3>
<h3>Categories: math.LO cs.CL</h3>
<hr />
<p>A well-known approach to treating syntactic island constraints in the setting
of Lambek grammars consists in adding specific bracket modalities to the logic.
We adapt this approach to abstract categorial grammars (ACG). Thus we define
bracketed (implicational) linear logic, bracketed lambda-calculus, and,
eventually, bracketed ACG based on bracketed $\lambda$-calculus. This allows us
modeling at least simplest island constraints, typically, in the context of
relativization. Next we identify specific safely bracketed ACG which, just like
ordinary (bracket-free) second order ACG generate effectively decidable
languages, but are sufficiently flexible to model some higher order phenomena
like relativization and correctly deal with syntactic islands, at least in
simple toy examples.</p>
<h1><a href="https://arxiv.org/abs/1907.06727">Deep learning-based color holographic microscopy </a></h1>
<h3>Authors: Tairan Liu, Zhensong Wei, Yair Rivenson, Kevin de Haan, Yibo Zhang, Yichen Wu, Aydogan Ozcan</h3>
<h3>Categories: eess.IV cs.CV cs.LG physics.optics</h3>
<h3>Comments: 25 pages, 8 Figures, 2 Tables</h3>
<hr />
<p>We report a framework based on a generative adversarial network (GAN) that
performs high-fidelity color image reconstruction using a single hologram of a
sample that is illuminated simultaneously by light at three different
wavelengths. The trained network learns to eliminate missing-phase-related
artifacts, and generates an accurate color transformation for the reconstructed
image. Our framework is experimentally demonstrated using lung and prostate
tissue sections that are labeled with different histological stains. This
framework is envisaged to be applicable to point-of-care histopathology, and
presents a significant improvement in the throughput of coherent microscopy
systems given that only a single hologram of the specimen is required for
accurate color imaging.</p>
<h1><a href="https://arxiv.org/abs/1907.06826">Adversarial Sensor Attack on LiDAR-based Perception in Autonomous Driving </a></h1>
<h3>Authors: Yulong Cao, Chaowei Xiao, Benjamin Cyr, Yimeng Zhou, Won Park, Sara Rampazzi, Qi Alfred Chen, Kevin Fu, Z. Morley Mao</h3>
<h3>Categories: cs.CR cs.CV eess.SP stat.ML</h3>
<hr />
<p>In Autonomous Vehicles (AVs), one fundamental pillar is perception, which
leverages sensors like cameras and LiDARs (Light Detection and Ranging) to
understand the driving environment. Due to its direct impact on road safety,
multiple prior efforts have been made to study its the security of perception
systems. In contrast to prior work that concentrates on camera-based
perception, in this work we perform the first security study of LiDAR-based
perception in AV settings, which is highly important but unexplored. We
consider LiDAR spoofing attacks as the threat model and set the attack goal as
spoofing obstacles close to the front of a victim AV. We find that blindly
applying LiDAR spoofing is insufficient to achieve this goal due to the machine
learning-based object detection process. Thus, we then explore the possibility
of strategically controlling the spoofed attack to fool the machine learning
model. We formulate this task as an optimization problem and design modeling
methods for the input perturbation function and the objective function. We also
identify the inherent limitations of directly solving the problem using
optimization and design an algorithm that combines optimization and global
sampling, which improves the attack success rates to around 75%. As a case
study to understand the attack impact at the AV driving decision level, we
construct and evaluate two attack scenarios that may damage road safety and
mobility. We also discuss defense directions at the AV system, sensor, and
machine learning model levels.</p>
<h1><a href="https://arxiv.org/abs/1907.06852">AirwayNet: A Voxel-Connectivity Aware Approach for Accurate Airway Segmentation Using Convolutional Neural Networks </a></h1>
<h3>Authors: Yulei Qin, Mingjian Chen, Hao Zheng, Yun Gu, Mali Shen, Jie Yang, Xiaolin Huang, Yue-Min Zhu, Guang-Zhong Yang</h3>
<h3>Categories: eess.IV cs.CV</h3>
<h3>Comments: 8 pages, 4 figures</h3>
<hr />
<p>Airway segmentation on CT scans is critical for pulmonary disease diagnosis
and endobronchial navigation. Manual extraction of airway requires strenuous
efforts due to the complicated structure and various appearance of airway. For
automatic airway extraction, convolutional neural networks (CNNs) based methods
have recently become the state-of-the-art approach. However, there still
remains a challenge for CNNs to perceive the tree-like pattern and comprehend
the connectivity of airway. To address this, we propose a voxel-connectivity
aware approach named AirwayNet for accurate airway segmentation. By
connectivity modeling, conventional binary segmentation task is transformed
into 26 tasks of connectivity prediction. Thus, our AirwayNet learns both
airway structure and relationship between neighboring voxels. To take advantage
of context knowledge, lung distance map and voxel coordinates are fed into
AirwayNet as additional semantic information. Compared to existing approaches,
AirwayNet achieved superior performance, demonstrating the effectiveness of the
network's awareness of voxel connectivity.</p>
<h1><a href="https://arxiv.org/abs/1907.07000">X-Net: Brain Stroke Lesion Segmentation Based on Depthwise Separable Convolution and Long-range Dependencies </a></h1>
<h3>Authors: Kehan Qi, Hao Yang, Cheng Li, Zaiyi Liu, Meiyun Wang, Qiegen Liu and Shanshan Wang</h3>
<h3>Categories: eess.IV cs.CV</h3>
<hr />
<p>The morbidity of brain stroke increased rapidly in the past few years. To
help specialists in lesion measurements and treatment planning, automatic
segmentation methods are critically required for clinical practices. Recently,
approaches based on deep learning and methods for contextual information
extraction have served in many image segmentation tasks. However, their
performances are limited due to the insufficient training of a large number of
parameters, which sometimes fail in capturing long-range dependencies. To
address these issues, we propose a depthwise separable convolution based X-Net
that designs a nonlocal operation namely Feature Similarity Module (FSM) to
capture long-range dependencies. The adopted depthwise convolution allows to
reduce the network size, while the developed FSM provides a more effective,
dense contextual information extraction and thus facilitates better
segmentation. The effectiveness of X-Net was evaluated on an open dataset
Anatomical Tracings of Lesions After Stroke (ATLAS) with superior performance
achieved compared to other six state-of-the-art approaches. We make our code
and models available at https://github.com/Andrewsher/X-Net.</p>
<h1><a href="https://arxiv.org/abs/1907.07008">CLCI-Net: Cross-Level fusion and Context Inference Networks for Lesion Segmentation of Chronic Stroke </a></h1>
<h3>Authors: Hao Yang, Weijian Huang, Kehan Qi, Cheng Li, Xinfeng Liu, Meiyun Wang, Hairong Zheng, Shanshan Wang</h3>
<h3>Categories: eess.IV cs.CV</h3>
<hr />
<p>Segmenting stroke lesions from T1-weighted MR images is of great value for
large-scale stroke rehabilitation neuroimaging analyses. Nevertheless, there
are great challenges with this task, such as large range of stroke lesion
scales and the tissue intensity similarity. The famous encoder-decoder
convolutional neural network, which although has made great achievements in
medical image segmentation areas, may fail to address these challenges due to
the insufficient uses of multi-scale features and context information. To
address these challenges, this paper proposes a Cross-Level fusion and Context
Inference Network (CLCI-Net) for the chronic stroke lesion segmentation from
T1-weighted MR images. Specifically, a Cross-Level feature Fusion (CLF)
strategy was developed to make full use of different scale features across
different levels; Extending Atrous Spatial Pyramid Pooling (ASPP) with CLF, we
have enriched multi-scale features to handle the different lesion sizes; In
addition, convolutional long short-term memory (ConvLSTM) is employed to infer
context information and thus capture fine structures to address the intensity
similarity issue. The proposed approach was evaluated on an open-source
dataset, the Anatomical Tracings of Lesions After Stroke (ATLAS) with the
results showing that our network outperforms five state-of-the-art methods. We
make our code and models available at https://github.com/YH0517/CLCI_Net.</p>
<h1><a href="https://arxiv.org/abs/1907.07077">Anatomically-Informed Multiple Linear Assignment Problems for White Matter Bundle Segmentation </a></h1>
<h3>Authors: Giulia Bert`o, Paolo Avesani, Franco Pestilli, Daniel Bullock, Bradley Caron and Emanuele Olivetti</h3>
<h3>Categories: eess.IV cs.CV</h3>
<hr />
<p>Segmenting white matter bundles from human tractograms is a task of interest
for several applications. Current methods for bundle segmentation consider
either only prior knowledge about the relative anatomical position of a bundle,
or only its geometrical properties. Our aim is to improve the results of
segmentation by proposing a method that takes into account information about
both the underlying anatomy and the geometry of bundles at the same time. To
achieve this goal, we extend a state-of-the-art example-based method based on
the Linear Assignment Problem (LAP) by including prior anatomical information
within the optimization process. The proposed method shows a significant
improvement with respect to the original method, in particular on small
bundles.</p>
<h1><a href="https://arxiv.org/abs/1907.07131">Boosting Resolution and Recovering Texture of micro-CT Images with Deep Learning </a></h1>
<h3>Authors: Ying Da Wang, Ryan T. Armstrong, Peyman Mostaghimi</h3>
<h3>Categories: eess.IV cs.CV cs.LG stat.ML</h3>
<h3>Comments: \keywords{Digital Rock Imaging \and Super Resolution \and Convolutional Neural Networks \and Generative Adversarial Networks}</h3>
<hr />
<p>Digital Rock Imaging is constrained by detector hardware, and a trade-off
between the image field of view (FOV) and the image resolution must be made.
This can be compensated for with super resolution (SR) techniques that take a
wide FOV, low resolution (LR) image, and super resolve a high resolution (HR),
high FOV image. The Enhanced Deep Super Resolution Generative Adversarial
Network (EDSRGAN) is trained on the Deep Learning Digital Rock Super Resolution
Dataset, a diverse compilation 12000 of raw and processed uCT images. The
network shows comparable performance of 50% to 70% reduction in relative error
over bicubic interpolation. GAN performance in recovering texture shows
superior visual similarity compared to SRCNN and other methods. Difference maps
indicate that the SRCNN section of the SRGAN network recovers large scale edge
(grain boundaries) features while the GAN network regenerates perceptually
indistinguishable high frequency texture. Network performance is generalised
with augmentation, showing high adaptability to noise and blur. HR images are
fed into the network, generating HR-SR images to extrapolate network
performance to sub-resolution features present in the HR images themselves.
Results show that under-resolution features such as dissolved minerals and thin
fractures are regenerated despite the network operating outside of trained
specifications. Comparison with Scanning Electron Microscope images shows
details are consistent with the underlying geometry of the sample. Recovery of
textures benefits the characterisation of digital rocks with a high proportion
of under-resolution micro-porous features, such as carbonate and coal samples.
Images that are normally constrained by the mineralogy of the rock (coal), by
fast transient imaging (waterflooding), or by the energy of the source
(microporosity), can be super resolved accurately for further analysis
downstream.</p>
<h1><a href="https://arxiv.org/abs/1907.06637">The Bach Doodle: Approachable music composition with machine learning at scale </a></h1>
<h3>Authors: Cheng-Zhi Anna Huang, Curtis Hawthorne, Adam Roberts, Monica Dinculescu, James Wexler, Leon Hong, Jacob Howcroft</h3>
<h3>Categories: cs.SD cs.HC cs.LG eess.AS stat.ML</h3>
<h3>Comments: Proceedings of the 18th International Society for Music Information Retrieval Conference, ISMIR 2019</h3>
<hr />
<p>To make music composition more approachable, we designed the first AI-powered
Google Doodle, the Bach Doodle, where users can create their own melody and
have it harmonized by a machine learning model Coconet (Huang et al., 2017) in
the style of Bach. For users to input melodies, we designed a simplified
sheet-music based interface. To support an interactive experience at scale, we
re-implemented Coconet in TensorFlow.js (Smilkov et al., 2019) to run in the
browser and reduced its runtime from 40s to 2s by adopting dilated depth-wise
separable convolutions and fusing operations. We also reduced the model
download size to approximately 400KB through post-training weight quantization.
We calibrated a speed test based on partial model evaluation time to determine
if the harmonization request should be performed locally or sent to remote TPU
servers. In three days, people spent 350 years worth of time playing with the
Bach Doodle, and Coconet received more than 55 million queries. Users could
choose to rate their compositions and contribute them to a public dataset,
which we are releasing with this paper. We hope that the community finds this
dataset useful for applications ranging from ethnomusicological studies, to
music education, to improving machine learning models.</p>
<h1><a href="https://arxiv.org/abs/1907.06639">Integrating the Data Augmentation Scheme with Various Classifiers for Acoustic Scene Modeling </a></h1>
<h3>Authors: Hangting Chen, Zuozhen Liu, Zongming Liu, Pengyuan Zhang, Yonghong Yan</h3>
<h3>Categories: eess.AS cs.LG cs.SD</h3>
<hr />
<p>This technical report describes the IOA team's submission for TASK1A of
DCASE2019 challenge. Our acoustic scene classification (ASC) system adopts a
data augmentation scheme employing generative adversary networks. Two major
classifiers, 1D deep convolutional neural network integrated with scalogram
features and 2D fully convolutional neural network integrated with Mel filter
bank features, are deployed in the scheme. Other approaches, such as adversary
city adaptation, temporal module based on discrete cosine transform and hybrid
architectures, have been developed for further fusion. The results of our
experiments indicates that the final fusion systems A-D could achieve an
accuracy higher than 85% on the officially provided fold 1 evaluation dataset.</p>
<h1><a href="https://arxiv.org/abs/1907.06673">Quant GANs: Deep Generation of Financial Time Series </a></h1>
<h3>Authors: Magnus Wiese, Robert Knobloch, Ralf Korn, Peter Kretschmer</h3>
<h3>Categories: q-fin.MF cs.LG q-fin.CP stat.ML</h3>
<hr />
<p>Modeling financial time series by stochastic processes is a challenging task
and a central area of research in financial mathematics. In this paper, we
break through this barrier and present Quant GANs, a data-driven model which is
inspired by the recent success of generative adversarial networks (GANs). Quant
GANs consist of a generator and discriminator function which utilize temporal
convolutional networks (TCNs) and thereby achieve to capture longer-ranging
dependencies such as the presence of volatility clusters. Furthermore, the
generator function is explicitly constructed such that the induced stochastic
process allows a transition to its risk-neutral distribution. Our numerical
results highlight that distributional properties for small and large lags are
in an excellent agreement and dependence properties such as volatility
clusters, leverage effects, and serial autocorrelations can be generated by the
generator function of Quant GANs, demonstrably in high fidelity.</p>
<h1><a href="https://arxiv.org/abs/1907.06690">A Scalable Framework for Multilevel Streaming Data Analytics using Deep Learning </a></h1>
<h3>Authors: Shihao Ge, Haruna Isah, Farhana Zulkernine and Shahzad Khan</h3>
<h3>Categories: eess.SY cs.LG cs.SY</h3>
<hr />
<p>The rapid growth of data in velocity, volume, value, variety, and veracity
has enabled exciting new opportunities and presented big challenges for
businesses of all types. Recently, there has been considerable interest in
developing systems for processing continuous data streams with the increasing
need for real-time analytics for decision support in the business, healthcare,
manufacturing, and security. The analytics of streaming data usually relies on
the output of offline analytics on static or archived data. However, businesses
and organizations like our industry partner Gnowit, strive to provide their
customers with real time market information and continuously look for a unified
analytics framework that can integrate both streaming and offline analytics in
a seamless fashion to extract knowledge from large volumes of hybrid streaming
data. We present our study on designing a multilevel streaming text data
analytics framework by comparing leading edge scalable open-source,
distributed, and in-memory technologies. We demonstrate the functionality of
the framework for a use case of multilevel text analytics using deep learning
for language understanding and sentiment analysis including data indexing and
query processing. Our framework combines Spark streaming for real time text
processing, the Long Short Term Memory (LSTM) deep learning model for higher
level sentiment analysis, and other tools for SQL-based analytical processing
to provide a scalable solution for multilevel streaming text analytics.</p>
<h1><a href="https://arxiv.org/abs/1907.06725">Mutual Reinforcement Learning </a></h1>
<h3>Authors: Sayanti Roy, Emily Kieson, Charles Abramson, Christopher Crick</h3>
<h3>Categories: cs.RO cs.HC cs.LG</h3>
<hr />
<p>Recently, collaborative robots have begun to train humans to achieve complex
tasks, and the mutual information exchange between them can lead to successful
robot-human collaborations. In this paper we demonstrate the application and
effectiveness of a new approach called \textit{mutual reinforcement learning}
(MRL), where both humans and autonomous agents act as reinforcement learners in
a skill transfer scenario over continuous communication and feedback. An
autonomous agent initially acts as an instructor who can teach a novice human
participant complex skills using the MRL strategy. While teaching skills in a
physical (block-building) ($n=34$) or simulated (Tetris) environment ($n=31$),
the expert tries to identify appropriate reward channels preferred by each
individual and adapts itself accordingly using an exploration-exploitation
strategy. These reward channel preferences can identify important behaviors of
the human participants, because they may well exercise the same behaviors in
similar situations later. In this way, skill transfer takes place between an
expert system and a novice human operator. We divided the subject population
into three groups and observed the skill transfer phenomenon, analyzing it with
Simpson"s psychometric model. 5-point Likert scales were also used to identify
the cognitive models of the human participants. We obtained a shared cognitive
model which not only improves human cognition but enhances the robot's
cognitive strategy to understand the mental model of its human partners while
building a successful robot-human collaborative framework.</p>
<h1><a href="https://arxiv.org/abs/1907.06845">The continuous Bernoulli: fixing a pervasive error in variational autoencoders </a></h1>
<h3>Authors: Gabriel Loaiza-Ganem, John P. Cunningham</h3>
<h3>Categories: stat.ML cs.LG</h3>
<hr />
<p>Variational autoencoders (VAE) have quickly become a central tool in machine
learning, applicable to a broad range of data types and latent variable models.
By far the most common first step, taken by seminal papers and by core software
libraries alike, is to model MNIST data using a deep network parameterizing a
Bernoulli likelihood. This practice contains what appears to be and what is
often set aside as a minor inconvenience: the pixel data is [0,1] valued, not
{0,1} as supported by the Bernoulli likelihood. Here we show that, far from
being a triviality or nuisance that is convenient to ignore, this error has
profound importance to VAE, both qualitative and quantitative. We introduce and
fully characterize a new [0,1]-supported, single parameter distribution: the
continuous Bernoulli, which patches this pervasive bug in VAE. This
distribution is not nitpicking; it produces meaningful performance improvements
across a range of metrics and datasets, including sharper image samples, and
suggests a broader class of performant VAE.</p>
<h1><a href="https://arxiv.org/abs/1907.06902">Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches </a></h1>
<h3>Authors: Maurizio Ferrari Dacrema, Paolo Cremonesi and Dietmar Jannach</h3>
<h3>Categories: cs.IR cs.LG cs.NE</h3>
<h3>Comments: Source code available at:</h3>
<hr />
<p>Deep learning techniques have become the method of choice for researchers
working on algorithmic aspects of recommender systems. With the strongly
increased interest in machine learning in general, it has, as a result, become
difficult to keep track of what represents the state-of-the-art at the moment,
e.g., for top-n recommendation tasks. At the same time, several recent
publications point out problems in today's research practice in applied machine
learning, e.g., in terms of the reproducibility of the results or the choice of
the baselines when proposing new models. In this work, we report the results of
a systematic analysis of algorithmic proposals for top-n recommendation tasks.
Specifically, we considered 18 algorithms that were presented at top-level
research conferences in the last years. Only 7 of them could be reproduced with
reasonable effort. For these methods, it however turned out that 6 of them can
often be outperformed with comparably simple heuristic methods, e.g., based on
nearest-neighbor or graph-based techniques. The remaining one clearly
outperformed the baselines but did not consistently outperform a well-tuned
non-neural linear ranking method. Overall, our work sheds light on a number of
potential problems in today's machine learning scholarship and calls for
improved scientific practices in this area. Source code of our experiments and
full results are available at:
https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation.</p>
<h1><a href="https://arxiv.org/abs/1907.06943">Machine learning without a feature set for detecting bursts in the EEG of preterm infants </a></h1>
<h3>Authors: John M. O'Toole and Geraldine B. Boylan</h3>
<h3>Categories: eess.SP cs.LG physics.med-ph</h3>
<hr />
<p>Deep neural networks enable learning directly on the data without the domain
knowledge needed to construct a feature set. This approach has been extremely
successful in almost all machine learning applications. We propose a new
framework that also learns directly from the data, without extracting a feature
set. We apply this framework to detecting bursts in the EEG of premature
infants. The EEG is recorded within days of birth in a cohort of infants
without significant brain injury and born &lt;30 weeks of gestation. The method
first transforms the time-domain signal to the time--frequency domain and then
trains a machine learning method, a gradient boosting machine, on each
time-slice of the time--frequency distribution. We control for oversampling the
time--frequency distribution with a significant reduction (&lt;1%) in memory and
computational complexity. The proposed method achieves similar accuracy to an
existing multi-feature approach: area under the characteristic curve of 0.98
(with 95% confidence interval of 0.96 to 0.99), with a median sensitivity of
95% and median specificity of 94%. The proposed framework presents an accurate,
simple, and computational efficient implementation as an alternative to both
the deep learning approach and to the manual generation of a feature set.</p>
<h1><a href="https://arxiv.org/abs/1907.06949">Quantum Data Fitting Algorithm for Non-sparse Matrices </a></h1>
<h3>Authors: Guangxi Li, Youle Wang, Yu Luo, Yuan Feng</h3>
<h3>Categories: quant-ph cs.LG</h3>
<h3>Comments: 5 pages</h3>
<hr />
<p>We propose a quantum data fitting algorithm for non-sparse matrices, which is
based on the Quantum Singular Value Estimation (QSVE) subroutine and a novel
efficient method for recovering the signs of eigenvalues. Our algorithm
generalizes the quantum data fitting algorithm of Wiebe, Braun, and Lloyd for
sparse and well-conditioned matrices by adding a regularization term to avoid
the over-fitting problem, which is a very important problem in machine
learning. As a result, the algorithm achieves a sparsity-independent runtime of
$O(\kappa^2\sqrt{N}\mathrm{polylog}(N)/(\epsilon\log\kappa))$ for an $N\times
N$ dimensional Hermitian matrix $\bm{F}$, where $\kappa$ denotes the condition
number of $\bm{F}$ and $\epsilon$ is the precision parameter. This amounts to a
polynomial speedup on the dimension of matrices when compared with the
classical data fitting algorithms, and a strictly less than quadratic
dependence on $\kappa$.</p>
<h1><a href="https://arxiv.org/abs/1907.06994">Estimation and Feature Selection in Mixtures of Generalized Linear Experts Models </a></h1>
<h3>Authors: Bao Tuyen Huynh and Faicel Chamroukhi</h3>
<h3>Categories: stat.ME cs.LG stat.AP stat.ML</h3>
<h3>Comments: arXiv admin note: text overlap with arXiv:1810.12161</h3>
<hr />
<p>Mixtures-of-Experts (MoE) are conditional mixture models that have shown
their performance in modeling heterogeneity in data in many statistical
learning approaches for prediction, including regression and classification, as
well as for clustering. Their estimation in high-dimensional problems is still
however challenging. We consider the problem of parameter estimation and
feature selection in MoE models with different generalized linear experts
models, and propose a regularized maximum likelihood estimation that
efficiently encourages sparse solutions for heterogeneous data with
high-dimensional predictors. The developed proximal-Newton EM algorithm
includes proximal Newton-type procedures to update the model parameter by
monotonically maximizing the objective function and allows to perform efficient
estimation and feature selection. An experimental study shows the good
performance of the algorithms in terms of recovering the actual sparse
solutions, parameter estimation, and clustering of heterogeneous regression
data, compared to the main state-of-the art competitors.</p>
<h1><a href="https://arxiv.org/abs/1907.07029">Adaptive Prior Selection for Repertoire-based Online Learning in Robotics </a></h1>
<h3>Authors: Rituraj Kaushik, Pierre Desreumaux, Jean-Baptiste Mouret</h3>
<h3>Categories: cs.RO cs.AI cs.LG cs.NE</h3>
<h3>Comments: Under review. Video link: http://tiny.cc/aprol_video</h3>
<hr />
<p>Among the data-efficient approaches for online adaptation in robotics
(meta-learning, model-based reinforcement learning, etc.), repertoire-based
learning (1) generates a large and diverse set policies in simulation that acts
as a "reservoir" for future adaptations and (2) learns to pick online the best
working policies according to the current situation (e.g., a damaged robot, a
new object, etc.). Each of these policies performs a different task, for
instance, walking in different directions; these policies are then sequenced
with a planning algorithm to achieve the given task. In this paper, we relax
the assumption of previous works that a single repertoire is enough for
adaptation. Instead, we generate repertoires for many different situations
(e.g., with a missing leg, on different floors, etc.) in simulation that act as
priors for adaptation. Our main contribution is an algorithm, APROL (Adaptive
Prior selection for Repertoire-based Online Learning) to plan the next action
by incorporating these priors when the robot has no information about the
current situation. We evaluate APROL on two simulated tasks: (1) pushing
unknown objects of various shapes and sizes with a kuka arm and (2) a goal
reaching task with a damaged hexapod robot. We compare with "Reset-free Trial
and Error" (RTE) and various single repertoire-based baselines. The results
show that APROL solves both tasks in less interaction time than the baselines.
Additionally, we demonstrate APROL on a real, damaged hexapod that quickly
learns compensatory policies to reach a goal by avoiding obstacle in the path.</p>
<h1><a href="https://arxiv.org/abs/1907.07103">Concentration of the matrix-valued minimum mean-square error in optimal Bayesian inference </a></h1>
<h3>Authors: Jean Barbier</h3>
<h3>Categories: cs.IT cs.LG eess.SP math.IT math.PR</h3>
<h3>Comments: arXiv admin note: text overlap with arXiv:1904.02808</h3>
<hr />
<p>We consider Bayesian inference of signals with vector-valued entries.
Extending concentration techniques from the mathematical physics of spin
glasses, we show that the matrix-valued minimum mean-square error concentrates
when the size of the problem increases. Such results are often crucial for
proving single-letter formulas for the mutual information when they exist. Our
proof is valid in the optimal Bayesian inference setting, meaning that it
relies on the assumption that the model and all its hyper-parameters are known.
Examples of inference and learning problems covered by our results are spiked
matrix and tensor models, the committee machine neural network with few hidden
neurons in the teacher-student scenario, or multi-layers generalized linear
models.</p>
<h1><a href="https://arxiv.org/abs/1907.07148">A Two-Stage Approach to Multivariate Linear Regression with Sparsely Mismatched Data </a></h1>
<h3>Authors: Martin Slawski, Emanuel Ben-David, Ping Li</h3>
<h3>Categories: stat.ML cs.IT cs.LG math.IT stat.ME</h3>
<hr />
<p>A tacit assumption in linear regression is that (response, predictor)-pairs
correspond to identical observational units. A series of recent works have
studied scenarios in which this assumption is violated under terms such as
<code>Unlabeled Sensing and</code>Regression with Unknown Permutation''. In this paper,
we study the setup of multiple response variables and a notion of mismatches
that generalizes permutations in order to allow for missing matches as well as
for one-to-many matches. A two-stage method is proposed under the assumption
that most pairs are correctly matched. In the first stage, the regression
parameter is estimated by handling mismatches as contaminations, and
subsequently the generalized permutation is estimated by a basic variant of
matching. The approach is both computationally convenient and equipped with
favorable statistical guarantees. Specifically, it is shown that the conditions
for permutation recovery become considerably less stringent as the number of
responses $m$ per observation increase. Particularly, for $m = \Omega(\log n)$,
the required signal-to-noise ratio does no longer depend on the sample size
$n$. Numerical results on synthetic and real data are presented to support the
main findings of our analysis.</p>
<h1><a href="https://arxiv.org/abs/1907.07167">Fast, Provably convergent IRLS Algorithm for p-norm Linear Regression </a></h1>
<h3>Authors: Deeksha Adil, Richard Peng, Sushant Sachdeva</h3>
<h3>Categories: cs.DS cs.LG cs.NA math.NA math.OC</h3>
<h3>Comments: Code for this work is available at</h3>
<hr />
<p>Linear regression in $\ell_p$-norm is a canonical optimization problem that
arises in several applications, including sparse recovery, semi-supervised
learning, and signal processing. Generic convex optimization algorithms for
solving $\ell_p$-regression are slow in practice. Iteratively Reweighted Least
Squares (IRLS) is an easy to implement family of algorithms for solving these
problems that has been studied for over 50 years. However, these algorithms
often diverge for p &gt; 3, and since the work of Osborne (1985), it has been an
open problem whether there is an IRLS algorithm that is guaranteed to converge
rapidly for p &gt; 3. We propose p-IRLS, the first IRLS algorithm that provably
converges geometrically for any $p \in [2,\infty).$ Our algorithm is simple to
implement and is guaranteed to find a $(1+\varepsilon)$-approximate solution in
$O(p^{3.5} m^{\frac{p-2}{2(p-1)}} \log \frac{m}{\varepsilon}) \le O_p(\sqrt{m}
\log \frac{m}{\varepsilon} )$ iterations. Our experiments demonstrate that it
performs even better than our theoretical bounds, beats the standard Matlab/CVX
implementation for solving these problems by 10--50x, and is the fastest among
available implementations in the high-accuracy regime.</p>
<h1><a href="https://arxiv.org/abs/1907.07178">Mediation Challenges and Socio-Technical Gaps for Explainable Deep Learning Applications </a></h1>
<h3>Authors: Rafael Brand\~ao, Joel Carbonera, Clarisse de Souza, Juliana Ferreira, Bernardo Gon\c{c}alves, Carla Leit\~ao</h3>
<h3>Categories: cs.AI cs.HC cs.LG</h3>
<h3>Comments: 39 pages</h3>
<hr />
<p>The presumed data owners' right to explanations brought about by the General
Data Protection Regulation in Europe has shed light on the social challenges of
explainable artificial intelligence (XAI). In this paper, we present a case
study with Deep Learning (DL) experts from a research and development
laboratory focused on the delivery of industrial-strength AI technologies. Our
aim was to investigate the social meaning (i.e. meaning to others) that DL
experts assign to what they do, given a richly contextualized and familiar
domain of application. Using qualitative research techniques to collect and
analyze empirical data, our study has shown that participating DL experts did
not spontaneously engage into considerations about the social meaning of
machine learning models that they build. Moreover, when explicitly stimulated
to do so, these experts expressed expectations that, with real-world DL
application, there will be available mediators to bridge the gap between
technical meanings that drive DL work, and social meanings that AI technology
users assign to it. We concluded that current research incentives and values
guiding the participants' scientific interests and conduct are at odds with
those required to face some of the scientific challenges involved in advancing
XAI, and thus responding to the alleged data owners' right to explanations or
similar societal demands emerging from current debates. As a concrete
contribution to mitigate what seems to be a more general problem, we propose
three preliminary XAI Mediation Challenges with the potential to bring together
technical and social meanings of DL applications, as well as to foster much
needed interdisciplinary collaboration among AI and the Social Sciences
researchers.</p>